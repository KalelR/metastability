@article{yetton2018quantifying, 
year = {2018}, 
title = {{Quantifying sleep architecture dynamics and individual differences using big data and Bayesian networks}}, 
author = {Yetton, Benjamin D. and McDevitt, Elizabeth A. and Cellini, Nicola and Shelton, Christian and Mednick, Sara C.}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0194604}, 
pmid = {29641599}, 
pmcid = {PMC5894981}, 
abstract = {{The pattern of sleep stages across a night (sleep architecture) is influenced by biological, behavioral, and clinical variables. However, traditional measures of sleep architecture such as stage proportions, fail to capture sleep dynamics. Here we quantify the impact of individual differences on the dynamics of sleep architecture and determine which factors or set of factors best predict the next sleep stage from current stage information. We investigated the influence of age, sex, body mass index, time of day, and sleep time on static (e.g. minutes in stage, sleep efficiency) and dynamic measures of sleep architecture (e.g. transition probabilities and stage duration distributions) using a large dataset of 3202 nights from a non-clinical population. Multi-level regressions show that sex effects duration of all Non-Rapid Eye Movement (NREM) stages, and age has a curvilinear relationship for Wake After Sleep Onset (WASO) and slow wave sleep (SWS) minutes. Bayesian network modeling reveals sleep architecture depends on time of day, total sleep time, age and sex, but not BMI. Older adults, and particularly males, have shorter bouts (more fragmentation) of Stage 2, SWS, and they transition less frequently to these stages. Additionally, we showed that the next sleep stage and its duration can be optimally predicted by the prior 2 stages and age. Our results demonstrate the potential benefit of big data and Bayesian network approaches in quantifying static and dynamic architecture of normal sleep.}}, 
pages = {e0194604}, 
number = {4}, 
volume = {13}, 
keywords = {}
}
@article{anvari2016disentangling, 
year = {2016}, 
title = {{Disentangling the stochastic behavior of complex time series}}, 
author = {Anvari, Mehrnaz and Tabar, M. Reza Rahimi and Peinke, Joachim and Lehnertz, Klaus}, 
journal = {Scientific Reports}, 
doi = {10.1038/srep35435}, 
pmid = {27759055}, 
pmcid = {PMC5069951}, 
abstract = {{Complex systems involving a large number of degrees of freedom, generally exhibit non-stationary dynamics, which can result in either continuous or discontinuous sample paths of the corresponding time series. The latter sample paths may be caused by discontinuous events – or jumps – with some distributed amplitudes, and disentangling effects caused by such jumps from effects caused by normal diffusion processes is a main problem for a detailed understanding of stochastic dynamics of complex systems. Here we introduce a non-parametric method to address this general problem. By means of a stochastic dynamical jump-diffusion modelling, we separate deterministic drift terms from different stochastic behaviors, namely diffusive and jumpy ones, and show that all of the unknown functions and coefficients of this modelling can be derived directly from measured time series. We demonstrate appli- cability of our method to empirical observations by a data-driven inference of the deterministic drift term and of the diffusive and jumpy behavior in brain dynamics from ten epilepsy patients. Particularly these different stochastic behaviors provide extra information that can be regarded valuable for diagnostic purposes.}}, 
pages = {35435}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{voss2004nonlinear, 
year = {2004}, 
title = {{NONLINEAR DYNAMICAL SYSTEM IDENTIFICATION FROM UNCERTAIN AND INDIRECT MEASUREMENTS}}, 
author = {VOSS, HENNING U. and TIMMER, JENS and KURTHS, JÜRGEN}, 
journal = {International Journal of Bifurcation and Chaos}, 
issn = {0218-1274}, 
doi = {10.1142/s0218127404010345}, 
abstract = {{We review the problem of estimating parameters and unobserved trajectory components from noisy time series measurements of continuous nonlinear dynamical systems. It is first shown that in parameter estimation techniques that do not take the measurement errors explicitly into account, like regression approaches, noisy measurements can produce inaccurate parameter estimates. Another problem is that for chaotic systems the cost functions that have to be minimized to estimate states and parameters are so complex that common optimization routines may fail. We show that the inclusion of information about the time-continuous nature of the underlying trajectories can improve parameter estimation considerably. Two approaches, which take into account both the errors-in-variables problem and the problem of complex cost functions, are described in detail: shooting approaches and recursive estimation techniques. Both are demonstrated on numerical examples.}}, 
pages = {1905--1933}, 
number = {06}, 
volume = {14}, 
keywords = {}
}
@article{tabar2019analysis, 
year = {2019}, 
title = {{Analysis and Data-Based Reconstruction of Complex Nonlinear Dynamical Systems, Using the Methods of Stochastic Processes}}, 
author = {Tabar, M. Reza Rahimi}, 
journal = {Understanding Complex Systems}, 
issn = {1860-0832}, 
doi = {10.1007/978-3-030-18472-8}, 
keywords = {}
}
@article{medeiros2016trapping, 
year = {2017}, 
title = {{Trapping Phenomenon Attenuates the Consequences of Tipping Points for Limit Cycles}}, 
author = {Medeiros, Everton S. and Caldas, Iberê L. and Baptista, Murilo S. and Feudel, Ulrike}, 
journal = {Scientific Reports}, 
doi = {10.1038/srep42351}, 
pmid = {28181582}, 
pmcid = {PMC5299408}, 
abstract = {{Nonlinear dynamical systems may be exposed to tipping points, critical thresholds at which small changes in the external inputs or in the system’s parameters abruptly shift the system to an alternative state with a contrasting dynamical behavior. While tipping in a fold bifurcation of an equilibrium is well understood, much less is known about tipping of oscillations (limit cycles) though this dynamics are the typical response of many natural systems to a periodic external forcing, like e.g. seasonal forcing in ecology and climate sciences. We provide a detailed analysis of tipping phenomena in periodically forced systems and show that, when limit cycles are considered, a transient structure, so-called channel, plays a fundamental role in the transition. Specifically, we demonstrate that trajectories crossing such channel conserve, for a characteristic time, the twisting behavior of the stable limit cycle destroyed in the fold bifurcation of cycles. As a consequence, this channel acts like a “ghost” of the limit cycle destroyed in the critical transition and instead of the expected abrupt transition we find a smooth one. This smoothness is also the reason that it is difficult to precisely determine the transition point employing the usual indicators of tipping points, like critical slowing down and flickering.}}, 
pages = {42351}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{john2022it, 
year = {2022}, 
title = {{It’s about time: Linking dynamical systems with human neuroimaging to understand the brain}}, 
author = {John, Yohan J. and Sawyer, Kayle S. and Srinivasan, Karthik and Müller, Eli J. and Munn, Brandon R. and Shine, James M.}, 
journal = {Network Neuroscience}, 
doi = {10.1162/netn\_a\_00230}, 
abstract = {{The study of dynamical systems offers a powerful framework for interpreting neuroimaging data from a range of different contexts, however, as a field, we have yet to fully embrace the power of this approach. Here, we offer a brief overview of some key terms from the dynamical systems literature, and then highlight three ways in which neuroimaging studies can begin to embrace the dynamical systems approach: by shifting from local to global descriptions of activity, by moving from static to dynamic analyses, and by transitioning from descriptive to generative models of neural activity patterns.}}, 
pages = {960--979}, 
number = {4}, 
volume = {6}, 
keywords = {}
}
@article{bittracher2018transition, 
year = {2018}, 
title = {{Transition Manifolds of Complex Metastable Systems}}, 
author = {Bittracher, Andreas and Koltai, Péter and Klus, Stefan and Banisch, Ralf and Dellnitz, Michael and Schütte, Christof}, 
journal = {Journal of Nonlinear Science}, 
issn = {0938-8974}, 
doi = {10.1007/s00332-017-9415-0}, 
pmid = {29527099}, 
pmcid = {PMC5835149}, 
eprint = {1704.08927}, 
abstract = {{We consider complex dynamical systems showing metastable behavior, but no local separation of fast and slow time scales. The article raises the question of whether such systems exhibit a low-dimensional manifold supporting its effective dynamics. For answering this question, we aim at finding nonlinear coordinates, called reaction coordinates, such that the projection of the dynamics onto these coordinates preserves the dominant time scales of the dynamics. We show that, based on a specific reducibility property, the existence of good low-dimensional reaction coordinates preserving the dominant time scales is guaranteed. Based on this theoretical framework, we develop and test a novel numerical approach for computing good reaction coordinates. The proposed algorithmic approach is fully local and thus not prone to the curse of dimension with respect to the state space of the dynamics. Hence, it is a promising method for data-based model reduction of complex dynamical systems such as molecular dynamics.}}, 
pages = {471--512}, 
number = {2}, 
volume = {28}, 
keywords = {}
}
@article{bittracher2021dimensionality, 
year = {2021}, 
title = {{Dimensionality Reduction of Complex Metastable Systems via Kernel Embeddings of Transition Manifolds}}, 
author = {Bittracher, Andreas and Klus, Stefan and Hamzi, Boumediene and Koltai, Péter and Schütte, Christof}, 
journal = {Journal of Nonlinear Science}, 
issn = {0938-8974}, 
doi = {10.1007/s00332-020-09668-z}, 
abstract = {{We present a novel kernel-based machine learning algorithm for identifying the low-dimensional geometry of the effective dynamics of high-dimensional multiscale stochastic systems. Recently, the authors developed a mathematical framework for the computation of optimal reaction coordinates of such systems that is based on learning a parameterization of a low-dimensional transition manifold in a certain function space. In this article, we enhance this approach by embedding and learning this transition manifold in a reproducing kernel Hilbert space, exploiting the favorable properties of kernel embeddings. Under mild assumptions on the kernel, the manifold structure is shown to be preserved under the embedding, and distortion bounds can be derived. This leads to a more robust and more efficient algorithm compared to the previous parameterization approaches.}}, 
pages = {3}, 
number = {1}, 
volume = {31}, 
keywords = {}
}
@article{babloyantz1986low, 
year = {1986}, 
title = {{Low-dimensional chaos in an instance of epilepsy.}}, 
author = {Babloyantz, A and Destexhe, A}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.83.10.3513}, 
pmid = {3085091}, 
pmcid = {PMC323547}, 
abstract = {{Using a time series obtained from the electroencephalogram recording of a human epileptic seizure, we show the existence of a chaotic attractor, the latter being the direct consequence of the deterministic nature of brain activity. This result is compared with other attractors seen in normal human brain dynamics. A sudden jump is observed between the dimensionalities of these brain attractors (4.05 +/- 0.05 for deep sleep) and the very low dimensionality of the epileptic state (2.05 +/- 0.09). The evaluation of the autocorrelation function and of the largest Lyapunov exponent allows us to sharpen further the main features of underlying dynamics. Possible implications in biological and medical research are briefly discussed.}}, 
pages = {3513--3517}, 
number = {10}, 
volume = {83}, 
keywords = {}
}
@article{rossi2022repository, 
year = {2002}, 
title = {{Repository for metastability}}, 
author = {Rossi}, 
journal = {GitHub}, 
url = {https://github.com/ComplexNetworks-jl/MetastableDynamics}, 
keywords = {}
}
@article{sakurai2016recruitment, 
year = {2016}, 
title = {{Recruitment of Polysynaptic Connections Underlies Functional Recovery of a Neural Circuit after Lesion}}, 
author = {Sakurai, Akira and Tamvacakis, Arianna N. and Katz, Paul S.}, 
journal = {eNeuro}, 
doi = {10.1523/eneuro.0056-16.2016}, 
pmid = {27570828}, 
pmcid = {PMC4999536}, 
abstract = {{The recruitment of additional neurons to neural circuits often occurs in accordance with changing functional demands. Here we found that synaptic recruitment plays a key role in functional recovery after neural injury. Disconnection of a brain commissure in the nudibranch mollusc, Tritonia diomedea, impairs swimming behavior by eliminating particular synapses in the central pattern generator (CPG) underlying the rhythmic swim motor pattern. However, the CPG functionally recovers within a day after the lesion. The strength of a spared inhibitory synapse within the CPG from Cerebral Neuron 2 (C2) to Ventral Swim Interneuron B (VSI) determines the level of impairment caused by the lesion, which varies among individuals. In addition to this direct synaptic connection, there are polysynaptic connections from C2 and Dorsal Swim Interneurons to VSI that provide indirect excitatory drive but play only minor roles under normal conditions. After disconnecting the pedal commissure (Pedal Nerve 6), the recruitment of polysynaptic excitation became a major source of the excitatory drive to VSI. Moreover, the amount of polysynaptic recruitment, which changed over time, differed among individuals and correlated with the degree of recovery of the swim motor pattern. Thus, functional recovery was mediated by an increase in the magnitude of polysynaptic excitatory drive, compensating for the loss of direct excitation. Since the degree of susceptibility to injury corresponds to existing individual variation in the C2 to VSI synapse, the recovery relied upon the extent to which the network reorganized to incorporate additional synapses.}}, 
pages = {ENEURO.0056--16.2016}, 
number = {4}, 
volume = {3}, 
keywords = {}
}
@article{hramov2006onoff, 
year = {2006}, 
title = {{On-off intermittency in time series of spontaneous paroxysmal activity in rats with genetic absence epilepsy}}, 
author = {Hramov, Alexander and Koronovskii, Alexey A. and Midzyanovskaya, I. S. and Sitnikova, E. and Rijn, C. M. van}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.2360505}, 
pmid = {17199389}, 
eprint = {nlin/0612050}, 
abstract = {{In the present paper we consider the on-off intermittency phenomena observed in time series of spontaneous paroxysmal activity in rats with genetic absence epilepsy. The method to register and analyze the electroencephalogram with the help of continuous wavelet transform is also suggested.}}, 
pages = {043111}, 
number = {4}, 
volume = {16}, 
keywords = {}
}
@article{freeman2003evidence, 
year = {2003}, 
title = {{Evidence from human scalp electroencephalograms of global chaotic itinerancy}}, 
author = {Freeman, Walter J.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.1596553}, 
pmid = {12946200}, 
abstract = {{My objective of this study was to find evidence of chaotic itinerancy in human brains by means of noninvasive recording of the electroencephalogram (EEG) from the scalp of normal subjects. My premise was that chaotic itinerancy occurs in sequences of cortical states marked by state transitions that appear as temporal discontinuities in neural activity patterns. I based my study on unprecedented advances in spatial and temporal resolution of the phase of oscillations in scalp EEG. The spatial resolution was enhanced by use of a high-density curvilinear array of 64 electrodes, 189 mm in length, with 3 mm spacing. The temporal resolution was advanced to the limit provided by the digitizing step, here 5 ms, by use of the Hilbert transform. The numerical derivative of the analytic phase revealed plateaus in phase that lasted on the order of 0.1 s and repeated at rates in the theta (3–7 Hz) or alpha (7–12 Hz) ranges. The plateaus were bracketed by sudden jumps in phase that usually took place within 1 to 2 digitizing steps. The jumps were commonly synchronized in each cerebral hemisphere over distances of up to 189 mm, irrespective of the orientation of the array. The jumps were usually not synchronized across the midline separating the hemisphere or across the sulcus between the frontal and parietal lobes. I believe that the widespread synchrony of the jumps in analytic phase manifest a metastable cortical state in accord with the theory of self-organized criticality. The jumps appear to be subcritical bifurcations. They reflect the aperiodic evolution of brain states through sequences of attractors that on access support the experience of remembering.}}, 
pages = {1067--1077}, 
number = {3}, 
volume = {13}, 
keywords = {}
}
@article{tsuda2009hypotheses, 
year = {2009}, 
title = {{Hypotheses on the functional roles of chaotic transitory dynamics}}, 
author = {Tsuda, Ichiro}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.3076393}, 
pmid = {19335017}, 
abstract = {{In contrast to the conventional static view of the brain, recent experimental data show that an alternative view is necessary for an appropriate interpretation of its function. Some selected problems concerning the cortical transitory dynamics are discussed. For the first time, we propose five scenarios for the appearance of chaotic itinerancy, which provides typical transitory dynamics. Second, we describe the transitory behaviors that have been observed in human and animal brains. Finally, we propose nine hypotheses on the functional roles of such dynamics, focusing on the dynamics embedded in data and the dynamical interpretation of brain activity within the framework of cerebral hermeneutics.}}, 
pages = {015113}, 
number = {1}, 
volume = {19}, 
keywords = {}
}
@incollection{rotstein2014mixedmode, 
year = {2014}, 
title = {{Mixed-Mode Oscillations in Single Neurons}}, 
author = {Rotstein, Horacio G.}, 
editor = {Jaeger, Dieter and Jung, Ranu}, 
booktitle = {Encyclopedia of Computational Neuroscience}, 
pages = {1--9}, 
series = {Encyclopedia of Computational Neuroscience}, 
publisher = {Springer New York, NY}, 
keywords = {}, 
doi = {10.1007/978-1-4614-7320-6\_31-1}
}
@article{fernandez2020sleep, 
year = {2020}, 
title = {{Sleep Spindles: Mechanisms and Functions}}, 
author = {Fernandez, Laura M. J. and Lüthi, Anita}, 
journal = {Physiological Reviews}, 
issn = {0031-9333}, 
doi = {10.1152/physrev.00042.2018}, 
pmid = {31804897}, 
abstract = {{Sleep spindles are burstlike signals in the electroencephalogram (EEG) of the sleeping mammalian brain and electrical surface correlates of neuronal oscillations in thalamus. As one of the most inheritable sleep EEG signatures, sleep spindles probably reflect the strength and malleability of thalamocortical circuits that underlie individual cognitive profiles. We review the characteristics, organization, regulation, and origins of sleep spindles and their implication in non-rapid-eye-movement sleep (NREMS) and its functions, focusing on human and rodent. Spatially, sleep spindle-related neuronal activity appears on scales ranging from small thalamic circuits to functional cortical areas, and generates a cortical state favoring intracortical plasticity while limiting cortical output. Temporally, sleep spindles are discrete events, part of a continuous power band, and elements grouped on an infraslow time scale over which NREMS alternates between continuity and fragility. We synthesize diverse and seemingly unlinked functions of sleep spindles for sleep architecture, sensory processing, synaptic plasticity, memory formation, and cognitive abilities into a unifying sleep spindle concept, according to which sleep spindles 1) generate neural conditions of large-scale functional connectivity and plasticity that outlast their appearance as discrete EEG events, 2) appear preferentially in thalamic circuits engaged in learning and attention-based experience during wakefulness, and 3) enable a selective reactivation and routing of wake-instated neuronal traces between brain areas such as hippocampus and cortex. Their fine spatiotemporal organization reflects NREMS as a physiological state coordinated over brain and body and may indicate, if not anticipate and ultimately differentiate, pathologies in sleep and neurodevelopmental, -degenerative, and -psychiatric conditions.}}, 
pages = {805--868}, 
number = {2}, 
volume = {100}, 
keywords = {}
}
@article{danisch2021makie, 
year = {2021}, 
title = {{Makie.jl: Flexible high-performance data visualization for Julia}}, 
author = {Danisch, Simon and Krumbiegel, Julius}, 
journal = {Journal of Open Source Software}, 
doi = {10.21105/joss.03349}, 
pages = {3349}, 
number = {65}, 
volume = {6}, 
keywords = {}
}
@article{lorenz1963deterministic, 
year = {1963}, 
title = {{Deterministic Nonperiodic Flow}}, 
author = {Lorenz, Edward N.}, 
journal = {Journal of the Atmospheric Sciences}, 
issn = {0022-4928}, 
doi = {10.1175/1520-0469(1963)020<0130:dnf>2.0.co;2}, 
abstract = {{Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space. For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into considerably different states. Systems with bounded solutions are shown to possess bounded numerical solutions. A simple system representing cellular convection is solved numerically. All of the solutions are found to be unstable, and almost all of them are nonperiodic. The feasibility of very-long-range weather prediction is examined in the light of these results.}}, 
pages = {130--141}, 
number = {2}, 
volume = {20}, 
keywords = {}
}
@article{curtis2015initiation, 
year = {2015}, 
title = {{Initiation, Propagation, and Termination of Partial (Focal) Seizures}}, 
author = {Curtis, Marco de and Avoli, Massimo}, 
journal = {Cold Spring Harbor Perspectives in Medicine}, 
doi = {10.1101/cshperspect.a022368}, 
pmid = {26134843}, 
pmcid = {PMC4484951}, 
abstract = {{The neurophysiological patterns that correlate with partial (focal) seizures are well defined in humans by standard electroencephalogram (EEG) and presurgical depth electrode recordings. Seizure patterns with similar features are reproduced in animal models of partial seizures and epilepsy. However, the network determinants that support interictal spikes, as well as the initiation, progression, and termination of seizures, are still elusive. Recent findings show that inhibitory networks are prominently involved at the onset of these seizures, and that extracellular changes in potassium contribute to initiate and sustain seizure progression. The end of a partial seizure correlates with an increase in network synchronization, which possibly involves both excitatory and inhibitory mechanisms.}}, 
pages = {a022368}, 
number = {7}, 
volume = {5}, 
keywords = {}
}
@article{luczak2007sequential, 
year = {2007}, 
title = {{Sequential structure of neocortical spontaneous activity in vivo}}, 
author = {Luczak, Artur and Barthó, Peter and Marguet, Stephan L. and Buzsáki, György and Harris, Kenneth D.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.0605643104}, 
pmid = {17185420}, 
pmcid = {PMC1765463}, 
abstract = {{Even in the absence of sensory stimulation, the neocortex shows complex spontaneous activity patterns, often consisting of alternating “DOWN” states of generalized neural silence and “UP” states of massive, persistent network activity. To investigate how this spontaneous activity propagates through neuronal assemblies in vivo, we simultaneously recorded populations of 50–200 cortical neurons in layer V of anesthetized and awake rats. Each neuron displayed a virtually unique spike pattern during UP states, with diversity seen amongst both putative pyramidal cells and interneurons, reflecting a complex but stereotypically organized sequential spread of activation through local cortical networks. Spike timing was most precise during the first ≈100 ms after UP state onset, and decayed as UP states progressed. A subset of UP states propagated as traveling waves, but waves passing a given point in either direction initiated similar local sequences, suggesting local networks as the substrate of sequential firing patterns. A search for repeating motifs indicated that their occurrence and structure was predictable from neurons' individual latencies to UP state onset. We suggest that these stereotyped patterns arise from the interplay of intrinsic cellular conductances and local circuit properties.}}, 
pages = {347--352}, 
number = {1}, 
volume = {104}, 
keywords = {}
}
@book{callenbook, 
year = {1991}, 
title = {{Thermodynamics and an Introduction to Thermostatistics}}, 
author = {Callen, Herbert B.}, 
isbn = {978-0-471-86256-7}, 
publisher = {Wiley}, 
keywords = {}, 
edition = {2}
}
@book{argyrisbook, 
title = {{An Exploration of Dynamical Systems and Chaos}}, 
author = {Argyris, John H. and Faust, Gunter and Haase, Maria and Friedrich, Rudolf}, 
publisher = {Springer Berlin, Heidelberg}, 
keywords = {}, 
edition = {2}, 
doi = {https://doi.org/10.1007/978-3-662-46042-9}
}
@article{abeles1995cortical, 
year = {1995}, 
title = {{Cortical activity flips among quasi-stationary states.}}, 
author = {Abeles, M and Bergman, H and Gat, I and Meilijson, I and Seidemann, E and Tishby, N and Vaadia, E}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.92.19.8616}, 
pmid = {7567985}, 
pmcid = {PMC41017}, 
abstract = {{Parallel recordings of spike trains of several single cortical neurons in behaving monkeys were analyzed as a hidden Markov process. The parallel spike trains were considered as a multivariate Poisson process whose vector firing rates change with time. As a consequence of this approach, the complete recording can be segmented into a sequence of a few statistically discriminated hidden states, whose dynamics are modeled as a first-order Markov chain. The biological validity and benefits of this approach were examined in several independent ways: (i) the statistical consistency of the segmentation and its correspondence to the behavior of the animals; (ii) direct measurement of the collective flips of activity, obtained by the model; and (iii) the relation between the segmentation and the pair-wise short-term cross-correlations between the recorded spike trains. Comparison with surrogate data was also carried out for each of the above examinations to assure their significance. Our results indicated the existence of well-separated states of activity, within which the firing rates were approximately stationary. With our present data we could reliably discriminate six to eight such states. The transitions between states were fast and were associated with concomitant changes of firing rates of several neurons. Different behavioral modes and stimuli were consistently reflected by different states of neural activity. Moreover, the pair-wise correlations between neurons varied considerably between the different states, supporting the hypothesis that these distinct states were brought about by the cooperative action of many neurons.}}, 
pages = {8616--8620}, 
number = {19}, 
volume = {92}, 
keywords = {}
}
@article{pomeau1980intermittent, 
year = {1980}, 
title = {{Intermittent transition to turbulence in dissipative dynamical systems}}, 
author = {Pomeau, Yves and Manneville, Paul}, 
journal = {Communications in Mathematical Physics}, 
issn = {0010-3616}, 
doi = {10.1007/bf01197757}, 
abstract = {{We study some simple dissipative dynamical systems exhibiting a transition from a stable periodic behavior to a chaotic one. At that transition, the inverse coherence time grows continuously from zero due to the random occurrence of widely separated bursts in the time record.}}, 
pages = {189--197}, 
number = {2}, 
volume = {74}, 
keywords = {}
}
@article{seidemann1996simultaneously, 
year = {1996}, 
title = {{Simultaneously recorded single units in the frontal cortex go through sequences of discrete and stable states in monkeys performing a delayed localization task}}, 
author = {Seidemann, E and Meilijson, I and Abeles, M and Bergman, H and Vaadia, E}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.16-02-00752.1996}, 
pages = {752--768}, 
number = {2}, 
volume = {16}, 
keywords = {}
}
@article{mashour2020conscious, 
year = {2020}, 
title = {{Conscious Processing and the Global Neuronal Workspace Hypothesis}}, 
author = {Mashour, George A. and Roelfsema, Pieter and Changeux, Jean-Pierre and Dehaene, Stanislas}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2020.01.026}, 
pmid = {32135090}, 
pmcid = {PMC8770991}, 
abstract = {{We review the central tenets and neuroanatomical basis of the global neuronal workspace (GNW) hypothesis, which attempts to account for the main scientific observations regarding the elementary mechanisms of conscious processing in the human brain. The GNW hypothesis proposes that, in the conscious state, a non-linear network ignition associated with recurrent processing amplifies and sustains a neural representation, allowing the corresponding information to be globally accessed by local processors. We examine this hypothesis in light of recent data that contrast brain activity evoked by either conscious or non-conscious contents, as well as during conscious or non-conscious states, particularly general anesthesia. We also discuss the relationship between the intertwined concepts of conscious processing, attention, and working memory.}}, 
pages = {776--798}, 
number = {5}, 
volume = {105}, 
keywords = {}
}
@article{dehaene2005ongoing, 
year = {2005}, 
title = {{Ongoing Spontaneous Activity Controls Access to Consciousness: A Neuronal Model for Inattentional Blindness}}, 
author = {Dehaene, Stanislas and Changeux, Jean-Pierre}, 
journal = {PLoS Biology}, 
issn = {1544-9173}, 
doi = {10.1371/journal.pbio.0030141}, 
pmid = {15819609}, 
pmcid = {PMC1074751}, 
abstract = {{Even in the absence of sensory inputs, cortical and thalamic neurons can show structured patterns of ongoing spontaneous activity, whose origins and functional significance are not well understood. We use computer simulations to explore the conditions under which spontaneous activity emerges from a simplified model of multiple interconnected thalamocortical columns linked by long-range, top-down excitatory axons, and to examine its interactions with stimulus-induced activation. Simulations help characterize two main states of activity. First, spontaneous gamma-band oscillations emerge at a precise threshold controlled by ascending neuromodulator systems. Second, within a spontaneously active network, we observe the sudden “ignition” of one out of many possible coherent states of high-level activity amidst cortical neurons with long-distance projections. During such an ignited state, spontaneous activity can block external sensory processing. We relate those properties to experimental observations on the neural bases of endogenous states of consciousness, and particularly the blocking of access to consciousness that occurs in the psychophysical phenomenon of “inattentional blindness,” in which normal subjects intensely engaged in mental activity fail to notice salient but irrelevant sensory stimuli. Although highly simplified, the generic properties of a minimal network may help clarify some of the basic cerebral phenomena underlying the autonomy of consciousness.}}, 
pages = {e141}, 
number = {5}, 
volume = {3}, 
keywords = {}
}
@article{rabinovich2008transientdynamics, 
year = {2008}, 
title = {{Transient Dynamics for Neural Processing}}, 
author = {Rabinovich, Misha and Huerta, Ramon and Laurent, Gilles}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.1155564}, 
pmid = {18599763}, 
pages = {48--50}, 
number = {5885}, 
volume = {321}, 
keywords = {}
}
@article{michel2017eeg, 
year = {2017}, 
title = {{EEG microstates as a tool for studying the temporal dynamics of whole-brain neuronal networks: A review}}, 
author = {Michel, Christoph M. and Koenig, Thomas}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2017.11.062}, 
pmid = {29196270}, 
abstract = {{ The present review discusses a well-established method for characterizing resting-state activity of the human brain using multichannel electroencephalography (EEG). This method involves the examination of electrical microstates in the brain, which are defined as successive short time periods during which the configuration of the scalp potential field remains semi-stable, suggesting quasi-simultaneity of activity among the nodes of large-scale networks. A few prototypic microstates, which occur in a repetitive sequence across time, can be reliably identified across participants. Researchers have proposed that these microstates represent the basic building blocks of the chain of spontaneous conscious mental processes, and that their occurrence and temporal dynamics determine the quality of mentation. Several studies have further demonstrated that disturbances of mental processes associated with neurological and psychiatric conditions manifest as changes in the temporal dynamics of specific microstates. Combined EEG-fMRI studies and EEG source imaging studies have indicated that EEG microstates are closely associated with resting-state networks as identified using fMRI. The scale-free properties of the time series of EEG microstates explain why similar networks can be observed at such different time scales. The present review will provide an overview of these EEG microstates, available methods for analysis, the functional interpretations of findings regarding these microstates, and their behavioral and clinical correlates.}}, 
pages = {577--593}, 
number = {Pt B}, 
volume = {180}, 
keywords = {}
}
@article{marder2001central, 
year = {2001}, 
title = {{Central pattern generators and the control of rhythmic movements}}, 
author = {Marder, Eve and Bucher, Dirk}, 
journal = {Current Biology}, 
issn = {0960-9822}, 
doi = {10.1016/s0960-9822(01)00581-4}, 
pmid = {11728329}, 
abstract = {{Central pattern generators are neuronal circuits that when activated can produce rhythmic motor patterns such as walking, breathing, flying, and swimming in the absence of sensory or descending inputs that carry specific timing information. General principles of the organization of these circuits and their control by higher brain centers have come from the study of smaller circuits found in invertebrates. Recent work on vertebrates highlights the importance of neuro-modulatory control pathways in enabling spinal cord and brain stem circuits to generate meaningful motor patterns. Because rhythmic motor patterns are easily quantified and studied, central pattern generators will provide important testing grounds for understanding the effects of numerous genetic mutations on behavior. Moreover, further understanding of the modulation of spinal cord circuitry used in rhythmic behaviors should facilitate the development of new treatments to enhance recovery after spinal cord damage.}}, 
pages = {R986--R996}, 
number = {23}, 
volume = {11}, 
keywords = {}
}
@article{10.1016/j.neuron.2013.01.031, 
year = {2013}, 
title = {{Making Waves: Initiation and Propagation of Corticothalamic Ca2+ Waves In Vivo}}, 
author = {Stroh, Albrecht and Adelsberger, Helmuth and Groh, Alexander and Rühlmann, Charlotta and Fischer, Sebastian and Schierloh, Anja and Deisseroth, Karl and Konnerth, Arthur}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2013.01.031}, 
pmid = {23522048}, 
abstract = {{Corticothalamic slow oscillations of neuronal activity determine internal brain states. At least in the cortex, the electrical activity is associated with large neuronal Ca2+ transients. Here we implemented an optogenetic approach to explore causal features of the generation of slow oscillation-associated Ca2+ waves in the in vivo mouse brain. We demonstrate that brief optogenetic stimulation (3–20 ms) of a local group of layer 5 cortical neurons is sufficient for the induction of global brain Ca2+ waves. These Ca2+ waves are evoked in an all-or-none manner, exhibit refractoriness during repetitive stimulation, and propagate over long distances. By local optogenetic stimulation, we demonstrate that evoked Ca2+ waves initially invade the cortex, followed by a secondary recruitment of the thalamus. Together, our results establish that synchronous activity in a small cluster of layer 5 cortical neurons can initiate a global neuronal wave of activity suited for long-range corticothalamic integration.}}, 
pages = {1136--1150}, 
number = {6}, 
volume = {77}, 
keywords = {}
}
@article{ito2008dynamics, 
year = {2007}, 
title = {{Dynamics of spontaneous transitions between global brain states}}, 
author = {Ito, Junji and Nikolaev, Andrey R. and Leeuwen, Cees van}, 
journal = {Human Brain Mapping}, 
issn = {1065-9471}, 
doi = {10.1002/hbm.20316}, 
pmid = {17315223}, 
pmcid = {PMC6871463}, 
abstract = {{Phase patterns of human scalp alpha EEG activity show spontaneous transitions between different globally phase‐synchronized states. We studied the dynamical properties of these transitions using the method of symbolic dynamics. We found greater predictability (deterministicity) and heterogeneity in the dynamics than what was expected from corresponding surrogate series in which linear correlations are retained. A possible explanation of these observations within the framework of chaotic itinerancy is discussed. Hum Brain Mapp, 2007. © 2007 Wiley‐Liss, Inc.}}, 
pages = {904--913}, 
number = {9}, 
volume = {28}, 
keywords = {}
}
@article{10.1063/1.1498155, 
year = {2002}, 
title = {{Winnerless competition between sensory neurons generates chaos: A possible mechanism for molluscan hunting behavior}}, 
author = {Varona, Pablo and Rabinovich, Mikhail I. and Selverston, Allen I. and Arshavsky, Yuri I.}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.1498155}, 
pmid = {12779595}, 
abstract = {{In the presence of prey, the marine mollusk Clione limacina exhibits search behavior, i.e., circular motions whose plane and radius change in a chaotic-like manner. We have formulated a dynamical model of the chaotic hunting behavior of Clione based on physiological in vivo and in vitro experiments. The model includes a description of the action of the cerebral hunting interneuron on the receptor neurons of the gravity sensory organ, the statocyst. A network of six receptor model neurons with Lotka–Volterra-type dynamics and nonsymmetric inhibitory interactions has no simple static attractors that correspond to winner take all phenomena. Instead, the winnerless competition induced by the hunting neuron displays hyperchaos with two positive Lyapunov exponents. The origin of the chaos is related to the interaction of two clusters of receptor neurons that are described with two heteroclinic loops in phase space. We hypothesize that the chaotic activity of the receptor neurons can drive the complex behavior of Clione observed during hunting.}}, 
pages = {672--677}, 
number = {3}, 
volume = {12}, 
keywords = {}
}
@article{10.1152/jn.00753.2003, 
year = {2004}, 
title = {{Dual Sensory-Motor Function for a Molluskan Statocyst Network}}, 
author = {Levi, R. and Varona, P. and Arshavsky, Y. I. and Rabinovich, M. I. and Selverston, A. I.}, 
journal = {Journal of Neurophysiology}, 
issn = {0022-3077}, 
doi = {10.1152/jn.00753.2003}, 
pmid = {14507988}, 
abstract = {{In mollusks, statocyst receptor cells (SRCs) interact with each other forming a neural network; their activity is determined by both the animal's orientation in the gravitational field and multimodal inputs. These two facts suggest that the function of the statocysts is not limited to sensing the animal's orientation. We studied the role of the statocysts in the organization of search motion during hunting behavior in the marine mollusk, Clione limacina. When hunting, Clione swims along a complex trajectory including numerous twists and turns confined within a definite space. Search-like behavior could be evoked pharmacologically by physostigmine; application of physostigmine to the isolated CNS produced “fictive search behavior” monitored by recordings from wing and tail nerves. Both in behavioral and in vitro experiments, we found that the statocysts are necessary for search behavior. The motor program typical of searching could not be produced after removing the statocysts. Simultaneous recordings from single SRCs and motor nerves showed that there was a correlation between the SRCs activity and search episodes. This correlation occurred even though the preparation was fixed and, therefore the sensory stimulus was constant. The excitation of individual SRCs could in some cases precede the beginning of search episodes. A biologically based model showed that, theoretically, the hunting search motor program could be generated by the statocyst receptor network due to its intrinsic dynamics. The results presented support for the idea that the statocysts are actively involved in the production of the motor program underlying search movements during hunting behavior.}}, 
pages = {336--345}, 
number = {1}, 
volume = {91}, 
keywords = {}
}
@article{10.1523/jneurosci.2249-05.2005, 
year = {2005}, 
title = {{The Role of Sensory Network Dynamics in Generating a Motor Program}}, 
author = {Levi, Rafael and Varona, Pablo and Arshavsky, Yuri I and Rabinovich, Mikhail I and Selverston, Allen I}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.2249-05.2005}, 
pmid = {16237184}, 
pmcid = {PMC6725745}, 
abstract = {{Sensory input plays a major role in controlling motor responses during most behavioral tasks. The vestibular organs in the marine mollusk Clione, the statocysts, react to the external environment and continuously adjust the tail and wing motor neurons to keep the animal oriented vertically. However, we suggested previously that during hunting behavior, the intrinsic dynamics of the statocyst network produce a spatiotemporal pattern that may control the motor system independently of environmental cues. Once the response is triggered externally, the collective activation of the statocyst neurons produces a complex sequential signal. In the behavioral context of hunting, such network dynamics may be the main determinant of an intricate spatial behavior. Here, we show that (1) during fictive hunting, the population activity of the statocyst receptors is correlated positively with wing and tail motor output suggesting causality, (2) that fictive hunting can be evoked by electrical stimulation of the statocyst network, and (3) that removal of even a few individual statocyst receptors critically changes the fictive hunting motor pattern. These results indicate that the intrinsic dynamics of a sensory network, even without its normal cues, can organize a motor program vital for the survival of the animal.}}, 
pages = {9807--9815}, 
number = {42}, 
volume = {25}, 
keywords = {}
}
@article{popa2009constracting, 
year = {2009}, 
title = {{Contrasting Activity Profile of Two Distributed Cortical Networks as a Function of Attentional Demands}}, 
author = {Popa, D and Popescu, A T and Pare, D}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4867-08.2009}, 
pmid = {19176827}, 
pmcid = {PMC2667329}, 
abstract = {{Recent human functional MRI (fMRI) studies have revealed that two widely distributed groups of cortical areas display inverse changes in activity when attentional demands increase, with one group showing higher (task-on) and the second lower (task-off) blood oxygen level-dependent (BOLD) signals. Moreover, task-on and task-off regions also exhibit slow (<0.2 Hz) inversely correlated fluctuations in BOLD signal at rest. However, the neuronal correlates of these reciprocal BOLD signal fluctuations are unknown. Here, we addressed this question using simultaneous recordings of unit activity and local field potentials (LFPs) in the cat homologues of task-on and task-off regions. In all states of vigilance, LFP power was lower in task-off than task-on regions with no difference in firing rates. Both sets of regions displayed slow (0.5-0.15 Hz) cyclical modulations in LFP power in all frequency bands but with large and variable phase differences such that task-on and task-off regions were often anticorrelated. Inversely correlated LFP power fluctuations were state-dependent in that they were much more frequent in waking and paradoxical sleep than in slow-wave sleep. Moreover, consistent with fMRI findings, when attentional demands increased, LFP power in task-on and task-off regions changed in opposite directions, further augmenting and decreasing, respectively. At odds with previous fMRI studies, however, the decreased LFP power in task-off regions was associated with increased firing rates, suggesting that the engagement of task-off regions might not be reduced but in fact enhanced during attention.}}, 
pages = {1191--1201}, 
number = {4}, 
volume = {29}, 
keywords = {}
}
@article{10.1016/j.neuron.2017.05.025, 
year = {2017}, 
title = {{Neural Manifolds for the Control of Movement}}, 
author = {Gallego, Juan A. and Perich, Matthew G. and Miller, Lee E. and Solla, Sara A.}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2017.05.025}, 
pmid = {28595054}, 
pmcid = {PMC6122849}, 
abstract = {{The analysis of neural dynamics in several brain cortices has consistently uncovered low-dimensional manifolds that capture a significant fraction of neural variability. These neural manifolds are spanned by specific patterns of correlated neural activity, the “neural modes.” We discuss a model for neural control of movement in which the time-dependent activation of these neural modes is the generator of motor behavior. This manifold-based view of motor cortex may lead to a better understanding of how the brain controls movement.}}, 
pages = {978--984}, 
number = {5}, 
volume = {94}, 
keywords = {}
}
@article{mazor2005transient, 
year = {2005}, 
rating = {5}, 
title = {{Transient Dynamics versus Fixed Points in Odor Representations by Locust Antennal Lobe Projection Neurons}}, 
author = {Mazor, Ofer and Laurent, Gilles}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2005.09.032}, 
pmid = {16301181}, 
abstract = {{Projection neurons (PNs) in the locust antennal lobe exhibit odor-specific dynamic responses. We studied a PN population, stimulated with five odorants and pulse durations between 0.3 and 10 s. Odor representations were characterized as time series of vectors of PN activity, constructed from the firing rates of all PNs in successive 50 ms time bins. Odor representations by the PN population can be described as trajectories in PN state space with three main phases: an on transient, lasting 1–2 s; a fixed point, stable for at least 8 s; and an off transient, lasting a few seconds as activity returns to baseline. Whereas all three phases are odor specific, optimal stimulus separation occurred during the transients rather than the fixed points. In addition, the PNs’ own target neurons respond least when their PN-population input stabilized at a fixed point. Steady-state measures of activity thus seem inappropriate to understand the neural code in this system.}}, 
pages = {661--673}, 
number = {4}, 
volume = {48}, 
keywords = {}
}
@article{jercog2017updown, 
year = {2017}, 
title = {{UP-DOWN cortical dynamics reflect state transitions in a bistable network}}, 
author = {Jercog, Daniel and Roxin, Alex and Barthó, Peter and Luczak, Artur and Compte, Albert and Rocha, Jaime de la}, 
journal = {eLife}, 
doi = {10.7554/elife.22425}, 
pmid = {28826485}, 
pmcid = {PMC5582872}, 
abstract = {{In the idling brain, neuronal circuits transition between periods of sustained firing (UP state) and quiescence (DOWN state), a pattern the mechanisms of which remain unclear. Here we analyzed spontaneous cortical population activity from anesthetized rats and found that UP and DOWN durations were highly variable and that population rates showed no significant decay during UP periods. We built a network rate model with excitatory (E) and inhibitory (I) populations exhibiting a novel bistable regime between a quiescent and an inhibition-stabilized state of arbitrarily low rate. Fluctuations triggered state transitions, while adaptation in E cells paradoxically caused a marginal decay of E-rate but a marked decay of I-rate in UP periods, a prediction that we validated experimentally. A spiking network implementation further predicted that DOWN-to-UP transitions must be caused by synchronous high-amplitude events. Our findings provide evidence of bistable cortical networks that exhibit non-rhythmic state transitions when the brain rests.}}, 
pages = {e22425}, 
volume = {6}, 
keywords = {}
}
@article{10.1088/1367-2630/aaf0d7, 
year = {2018}, 
title = {{Characterizing abrupt transitions in stochastic dynamics}}, 
author = {Lehnertz, Klaus and Zabawa, Lina and Tabar, M Reza Rahimi}, 
journal = {New Journal of Physics}, 
doi = {10.1088/1367-2630/aaf0d7}, 
abstract = {{Data sampled at discrete times appears as a succession of discontinuous jumps, even if the underlying trajectory is continuous. We analytically derive a criterion that allows one to check whether for a given, even noisy time series the underlying process has a continuous (diffusion) trajectory or has jump discontinuities. This enables one to detect and characterize abrupt changes (jump events) in given time series. The proposed criterion is validated numerically using synthetic continuous and discontinuous time series. We demonstrate applicability of our criterion to distinguish diffusive and jumpy behavior by a data-driven inference of higher-order conditional moments from empirical observations.}}, 
pages = {113043}, 
number = {11}, 
volume = {20}, 
keywords = {}
}
@article{jones2007natural, 
year = {2007}, 
title = {{Natural stimuli evoke dynamic sequences of states in sensory cortical ensembles}}, 
author = {Jones, Lauren M. and Fontanini, Alfredo and Sadacca, Brian F. and Miller, Paul and Katz, Donald B.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.0705546104}, 
pmid = {18000059}, 
pmcid = {PMC2141852}, 
abstract = {{Although temporal coding is a frequent topic of neurophysiology research, trial-to-trial variability in temporal codes is typically dismissed as noise and thought to play no role in sensory function. Here, we show that much of this supposed “noise” faithfully reflects stimulus-related processes carried out in coherent neural networks. Cortical neurons responded to sensory stimuli by progressing through sequences of states, identifiable only in examinations of simultaneously recorded ensembles. The specific times at which ensembles transitioned from state to state varied from trial to trial, but the state sequences were reliable and stimulus-specific. Thus, the characterization of ensemble responses in terms of state sequences captured facets of sensory processing that are missing from, and obscured in, other analyses. This work provides evidence that sensory neurons act as parts of a systems-level dynamic process, the nature of which can best be appreciated through observation of distributed ensembles.}}, 
pages = {18772--18777}, 
number = {47}, 
volume = {104}, 
keywords = {}
}
@article{ashwin2011criteria, 
year = {2011}, 
title = {{Criteria for robustness of heteroclinic cycles in neural microcircuits}}, 
author = {Ashwin, Peter and Karabacak, Özkan and Nowotny, Thomas}, 
journal = {The Journal of Mathematical Neuroscience}, 
issn = {2190-8567}, 
doi = {10.1186/2190-8567-1-13}, 
pmid = {22656192}, 
pmcid = {PMC3365877}, 
abstract = {{We introduce a test for robustness of heteroclinic cycles that appear in neural microcircuits modeled as coupled dynamical cells. Robust heteroclinic cycles (RHCs) can appear as robust attractors in Lotka-Volterra-type winnerless competition (WLC) models as well as in more general coupled and/or symmetric systems. It has been previously suggested that RHCs may be relevant to a range of neural activities, from encoding and binding to spatio-temporal sequence generation. The robustness or otherwise of such cycles depends both on the coupling structure and the internal structure of the neurons. We verify that robust heteroclinic cycles can appear in systems of three identical cells, but only if we require perturbations to preserve some invariant subspaces for the individual cells. On the other hand, heteroclinic attractors can appear robustly in systems of four or more identical cells for some symmetric coupling patterns, without restriction on the internal dynamics of the cells.}}, 
pages = {13}, 
number = {1}, 
volume = {1}, 
keywords = {}
}
@book{olivieri2005large, 
year = {2005}, 
title = {{Large Deviations and Metastability}}, 
author = {Olivieri, Enzo and Vares, Maria Eulália}, 
isbn = {978-0-521-59163-8}, 
abstract = {{The van der Waals–Maxwell theory Metastability is a relevant phenomenon for thermodynamic systems close to a first order phase transition. Examples are supercooled vapours and liquids, super-saturated vapours and solutions, as well as ferromagnets in the part of the hysteresis loop where the magnetization is opposite to the external magnetic field. A metastable state occurs when some thermodynamic parameter such as the temperature, pressure or magnetic field is changed from a value giving rise to a stable state with a unique phase, say X, to one for which at least part of the system should be in some new equilibrium phase Y. Then, in particular experimental situations, instead of undergoing the phase transition, the system goes over continuously into a ‘false’ equilibrium state with a unique phase X′, far from Y but actually close to the initial equilibrium phase X. It is this apparent equilibrium situation that is called a ‘metastable state’. Its properties are very similar to those of the stable equilibrium state; for example for a supersaturated vapour one can determine the pressure experimentally as a function of the temperature and the specific volume. We speak of the ‘metastable branch’ of the isothermal curve. The distinguishing feature of metastability is that, eventually, either via an external perturbation or via a spontaneous fluctuation, a nucleus of the new phase appears, starting an irreversible process which leads to the stable equilibrium state Y, where the phase transition has taken place.}}, 
series = {Encyclopedia of Mathematics and its Applications}, 
publisher = {Cambridge University Press}, 
address = {Cambridge}, 
keywords = {}, 
doi = {10.1017/cbo9780511543272.005}
}
@article{10.1007/bf02219225, 
year = {1997}, 
title = {{Random attractors}}, 
author = {Crauel, Hans and Debussche, Arnaud and Flandoli, Franco}, 
journal = {Journal of Dynamics and Differential Equations}, 
issn = {1040-7294}, 
doi = {10.1007/bf02219225}, 
abstract = {{In this paper, we generalize the notion of an attractor for the stochastic dynamical system introduced in [7]. We prove that the stochastic attractor satisfies most of the properties satisfied by the usual attractor in the theory of deterministic dynamical systems. We also show that our results apply to the stochastic Navier-Stokes equation, the white noise-driven Burgers equation, and a nonlinear stochastic wave equation.}}, 
pages = {307--341}, 
number = {2}, 
volume = {9}, 
keywords = {}
}
@article{10.1063/1.4959146, 
year = {2016}, 
title = {{Stochastic basins of attraction for metastable states}}, 
author = {Serdukova, Larissa and Zheng, Yayun and Duan, Jinqiao and Kurths, Jürgen}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.4959146}, 
pmid = {27475077}, 
abstract = {{Basin of attraction of a stable equilibrium point is an effective concept for stability analysis in deterministic systems; however, it does not contain information on the external perturbations that may affect it. Here we introduce the concept of stochastic basin of attraction (SBA) by incorporating a suitable probabilistic notion of basin. We define criteria for the size of the SBA based on the escape probability, which is one of the deterministic quantities that carry dynamical information and can be used to quantify dynamical behavior of the corresponding stochastic basin of attraction. SBA is an efficient tool to describe the metastable phenomena complementing the known exit time, escape probability, or relaxation time. Moreover, the geometric structure of SBA gives additional insight into the system's dynamical behavior, which is important for theoretical and practical reasons. This concept can be used not only in models with small noise intensity but also with noise whose amplitude is proportional or in general is a function of an order parameter. As an application of our main results, we analyze a three potential well system perturbed by two types of noise: Brownian motion and non-Gaussian α-stable Lévy motion. Our main conclusions are that the thermal fluctuations stabilize the metastable system with an asymmetric three-well potential but have the opposite effect for a symmetric one. For Lévy noise with larger jumps and lower jump frequencies ( α = 0.5) metastability is enhanced for both symmetric and asymmetric potentials.}}, 
pages = {073117}, 
number = {7}, 
volume = {26}, 
keywords = {}
}
@article{nowotny2007dynamical, 
year = {2007}, 
title = {{Dynamical Origin of Independent Spiking and Bursting Activity in Neural Microcircuits}}, 
author = {Nowotny, Thomas and Rabinovich, Mikhail I}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.98.128106}, 
pmid = {17501162}, 
abstract = {{The relationship between spiking and bursting dynamics is a key question in neuroscience, particularly in understanding the origins of different neural coding strategies and the mechanisms of motor command generation and neural circuit coordination. Experiments indicate that spiking and bursting dynamics can be independent. We hypothesize that different mechanisms for spike and burst generation, intrinsic neuron dynamics for spiking and a modulational network instability for bursting, are the origin of this independence. We tested the hypothesis in a detailed dynamical analysis of a minimal inhibitory neural microcircuit (motif) of three reciprocally connected Hodgkin-Huxley neurons. We reduced this high-dimensional dynamical system to a rate model and showed that both systems have identical bifurcations from tonic spiking to burst generation, which, therefore, does not depend on the details of spiking activity.}}, 
pages = {128106}, 
number = {12}, 
volume = {98}, 
keywords = {}
}
@article{10.3389/fncom.2011.00024, 
year = {2011}, 
title = {{Robust Transient Dynamics and Brain Functions}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {Frontiers in Computational Neuroscience}, 
doi = {10.3389/fncom.2011.00024}, 
pmid = {21716642}, 
pmcid = {PMC3116137}, 
abstract = {{In the last few decades several concepts of dynamical systems theory (DST) have guided psychologists, cognitive scientists, and neuroscientists to rethink about sensory motor behavior and embodied cognition. A critical step in the progress of DST application to the brain (supported by modern methods of brain imaging and multi-electrode recording techniques) has been the transfer of its initial success in motor behavior to mental function, i.e., perception, emotion, and cognition. Open questions from research in genetics, ecology, brain sciences, etc., have changed DST itself and lead to the discovery of a new dynamical phenomenon, i.e., reproducible and robust transients that are at the same time sensitive to informational signals. The goal of this review is to describe a new mathematical framework – heteroclinic sequential dynamics – to understand self-organized activity in the brain that can explain certain aspects of robust itinerant behavior. Specifically, we discuss a hierarchy of coarse-grain models of mental dynamics in the form of kinetic equations of modes. These modes compete for resources at three levels: (i) within the same modality, (ii) among different modalities from the same family (like perception), and (iii) among modalities from different families (like emotion and cognition). The analysis of the conditions for robustness, i.e., the structural stability of transient (sequential) dynamics, give us the possibility to explain phenomena like the finite capacity of our sequential working memory – a vital cognitive function –, and to find specific dynamical signatures – different kinds of instabilities – of several brain functions and mental diseases.}}, 
pages = {24}, 
volume = {5}, 
keywords = {}
}
@article{10.1001/jamapsychiatry.2017.0273, 
year = {2017}, 
title = {{Consciousness as Sequential Dynamics, Robustness, and Mental Disorders}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {JAMA Psychiatry}, 
issn = {2168-622X}, 
doi = {10.1001/jamapsychiatry.2017.0273}, 
pmid = {28564683}, 
pages = {771}, 
number = {8}, 
volume = {74}, 
keywords = {}
}
@article{ishii1986breakdown, 
year = {1986}, 
title = {{Breakdown of chaos symmetry and intermittency in the double-well potential system}}, 
author = {Ishii, Hiroaki and Fujisaka, Hirokazu and Inoue, Masayoshi}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(86)90590-6}, 
abstract = {{The chaos-chaos transition in a one-particle system in the symmetric double-well potential under an external periodic field is studied from the viewpoint of the breakdown of the chaos symmetry and the development of the intermittency characteristics. It is found that the similarity exponent introduced to analyze the intermittency characteristics satisfies a scaling law near the transition point.}}, 
pages = {257--263}, 
number = {6}, 
volume = {116}, 
keywords = {}
}
@article{grebogi1983crises, 
year = {1983}, 
title = {{Crises, sudden changes in chaotic attractors, and transient chaos}}, 
author = {Grebogi, Celso and Ott, Edward and Yorke, James A.}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/0167-2789(83)90126-4}, 
abstract = {{The occurrence of sudden qualitative changes of chaotic dynamics as a parameter is varied is discussed and illustrated. It is shown that such changes may result from the collision of an unstable periodic orbit and a coexisting chaotic attractor. We call such collisions crises. Phenomena associated with crises include sudden changes in the size of chaotic attractors, sudden appearances of chaotic attractors (a possible route to chaos), and sudden destructions of chaotic attractors and their basins. This paper presents examples illustrating that crisis events are prevalent in many circumstances and systems, and that, just past a crisis, certain characteristic statistical behavior (whose type depends on the type of crisis) occurs. In particular the phenomenon of chaotic transients is investigated. The examples discussed illustrate crises in progressively higher dimension and include the one-dimensional quadratic map, the (two-dimensional) Hénon map, systems of ordinary differential equations in three dimensions and a three-dimensional map. In the case of our study of the three-dimensional map a new route to chaos is proposed which is possible only in invertible maps or flows of dimension at least three or four, respectively. Based on the examples presented the following conjecture is proposed: almost all sudden changes in the size of chaotic attractors and almost all sudden destruction or creations of chaotic attractors and their basins are due to crises.}}, 
pages = {181--200}, 
number = {1-3}, 
volume = {7}, 
keywords = {}
}
@article{10.1103/physreve.56.2592, 
year = {1997}, 
title = {{Symmetry between laminar and burst phases for on-off intermittency}}, 
author = {Čenys, A. and Anagnostopoulos, A. N. and Bleris, G. L.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.56.2592}, 
abstract = {{It is demonstrated both analytically and numerically that a symmetry exists between laminar and burst phases of on-off intermittency. The symmetry is a specific feature of on-off intermittency. It does not exist for the other types of regular Pomeau-Manneville and crisis-induced intermittency. A diffusional model, which incorporates reflecting barriers representing noise and nonlinearity, predicts the same scaling for the laminar and the burst lengths near the blowout bifurcation point. The symmetry of the scaling properties is demonstrated numerically for two systems exhibiting on-off intermittency, namely, the discrete three-dimensional Hénon map and the unidirectionally coupled Rössler oscillators.}}, 
pages = {2592--2596}, 
number = {3}, 
volume = {56}, 
keywords = {}
}
@article{ashwin2001influence, 
year = {2001}, 
rating = {4}, 
title = {{Influence of noise on scalings for in-out intermittency}}, 
author = {Ashwin, Peter and Covas, Eurico and Tavakol, Reza}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.64.066204}, 
pmid = {11736265}, 
eprint = {nlin/0105033}, 
abstract = {{We study the effects of noise on a recently discovered form of intermittency, referred to as in-out intermittency. This type of intermittency, which reduces to on-off in systems with a skew product structure, has been found in the dynamics of maps, (ODE) and (PDE) simulations that have symmetries. It shows itself in the form of trajectories that spend a long time near a symmetric state interspersed with short bursts away from symmetry. In contrast to on-off intermittency, there are clearly distinct mechanisms of approach towards and away from the symmetric state, and this needs to be taken into account in order to properly model the long time statistics. We do this by using a diffusion-type equation with a delay integral boundary condition. This model is validated by considering the statistics of a two-dimensional map with and without the addition of noise.}}, 
pages = {066204}, 
number = {6}, 
volume = {64}, 
keywords = {}
}
@article{platt1993onoff, 
year = {1993}, 
title = {{On-off intermittency: A mechanism for bursting}}, 
author = {Platt, N and Spiegel, E A and Tresser, C}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.70.279}, 
pmid = {10054072}, 
abstract = {{On-off intermittency is an aperiodic switching between static, or laminar, behavior and chaotic bursts of oscillation. It can be generated by systems having an unstable invariant (or quasi-invariant) manifold, within which is found a suitable attractor. We clarify the roles of such attractors in producing intermittency, provide examples, and relate them to previous work.}}, 
pages = {279--282}, 
number = {3}, 
volume = {70}, 
keywords = {}
}
@article{ashwin1999transverse, 
year = {1999}, 
title = {{Transverse instability for non-normal parameters}}, 
author = {Ashwin, Peter and Covas, Eurico and Tavakol, Reza}, 
journal = {Nonlinearity}, 
issn = {0951-7715}, 
doi = {10.1088/0951-7715/12/3/009}, 
eprint = {chao-dyn/9802013}, 
abstract = {{We consider the behaviour of attractors near invariant subspaces on varying a parameter that does not preserve the dynamics in the invariant subspace but is otherwise generic, in a smooth dynamical system. We refer to such a parameter as ``non-normal''. If there is chaos in the invariant subspace that is not structurally stable, this has the effect of ``blurring out'' blowout bifurcations over a range of parameter values that we show can have positive measure in parameter space. Associated with such blowout bifurcations are bifurcations to attractors displaying a new type of intermittency that is phenomenologically similar to on-off intermittency, but where the intersection of the attractor by the invariant subspace is larger than a minimal attractor. The presence of distinct repelling and attracting invariant sets leads us to refer to this as ``in-out'' intermittency. Such behaviour cannot appear in systems where the transverse dynamics is a skew product over the system on the invariant subspace. We characterise in-out intermittency in terms of its structure in phase space and in terms of invariants of the dynamics obtained from a Markov model of the attractor. This model predicts a scaling of the length of laminar phases that is similar to that for on-off intermittency but which has some differences.}}, 
pages = {563--577}, 
number = {3}, 
volume = {12}, 
keywords = {}
}
@article{10.1016/j.neuroimage.2017.03.045, 
year = {2017}, 
title = {{Functional connectivity dynamically evolves on multiple time-scales over a static structural connectome: Models and mechanisms}}, 
author = {Cabral, Joana and Kringelbach, Morten L. and Deco, Gustavo}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2017.03.045}, 
pmid = {28343985}, 
abstract = {{ Over the last decade, we have observed a revolution in brain structural and functional Connectomics. On one hand, we have an ever-more detailed characterization of the brain's white matter structural connectome. On the other, we have a repertoire of consistent functional networks that form and dissipate over time during rest. Despite the evident spatial similarities between structural and functional connectivity, understanding how different time-evolving functional networks spontaneously emerge from a single structural network requires analyzing the problem from the perspective of complex network dynamics and dynamical system's theory. In that direction, bottom-up computational models are useful tools to test theoretical scenarios and depict the mechanisms at the genesis of resting-state activity. Here, we provide an overview of the different mechanistic scenarios proposed over the last decade via computational models. Importantly, we highlight the need of incorporating additional model constraints considering the properties observed at finer temporal scales with MEG and the dynamical properties of FC in order to refresh the list of candidate scenarios.}}, 
pages = {84--96}, 
volume = {160}, 
keywords = {}
}
@article{hangi1990reaction, 
year = {1990}, 
title = {{Reaction-rate theory: fifty years after Kramers}}, 
author = {Hänggi, Peter and Talkner, Peter and Borkovec, Michal}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.62.251}, 
abstract = {{The calculation of rate coefficients is a discipline of nonlinear science of importance to much of physics, chemistry, engineering, and biology. Fifty years after Kramers' seminal paper on thermally activated barrier crossing, the authors report, extend, and interpret much of our current understanding relating to theories of noise-activated escape, for which many of the notable contributions are originating from the communities both of physics and of physical chemistry. Theoretical as well as numerical approaches are discussed for single- and many-dimensional metastable systems (including fields) in gases and condensed phases. The role of many-dimensional transition-state theory is contrasted with Kramers' reaction-rate theory for moderate-to-strong friction; the authors emphasize the physical situation and the close connection between unimolecular rate theory and Kramers' work for weakly damped systems. The rate theory accounting for memory friction is presented, together with a unifying theoretical approach which covers the whole regime of weak-to-moderate-to-strong friction on the same basis (turnover theory). The peculiarities of noise-activated escape in a variety of physically different metastable potential configurations is elucidated in terms of the mean-first-passage-time technique. Moreover, the role and the complexity of escape in driven systems exhibiting possibly multiple, metastable stationary nonequilibrium states is identified. At lower temperatures, quantum tunneling effects start to dominate the rate mechanism. The early quantum approaches as well as the latest quantum versions of Kramers' theory are discussed, thereby providing a description of dissipative escape events at all temperatures. In addition, an attempt is made to discuss prominent experimental work as it relates to Kramers' reaction-rate theory and to indicate the most important areas for future research in theory and experiment.}}, 
pages = {251--341}, 
number = {2}, 
volume = {62}, 
keywords = {}
}
@article{10.1063/1.5012134, 
year = {2018}, 
title = {{Riddled basins of attraction in systems exhibiting extreme events}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science}, 
issn = {1054-1500}, 
doi = {10.1063/1.5012134}, 
pmid = {29604637}, 
eprint = {1711.02160}, 
abstract = {{Using a system of two FitzHugh-Nagumo units, we demonstrate the occurrence of riddled basins of attraction in delay-coupled systems as the coupling between the units is increased. We characterize riddled basins using the uncertainty exponent which is a measure of the dimensions of the basin boundary. Additionally, we show that the phase space can be partitioned into pure and mixed regions, where initial conditions in the pure regions certainly avoid the generation of extreme events, while initial conditions in the mixed region may or may not exhibit such events. This implies that any tiny perturbation of initial conditions in the mixed region could yield the emergence of extreme events because the latter state possesses a riddled basin of attraction.}}, 
pages = {033610}, 
number = {3}, 
volume = {28}, 
keywords = {}
}
@article{yorke1979metastable, 
year = {1979}, 
title = {{Metastable chaos: The transition to sustained chaotic behavior in the Lorenz model}}, 
author = {Yorke, James A. and Yorke, Ellen D.}, 
journal = {Journal of Statistical Physics}, 
issn = {0022-4715}, 
doi = {10.1007/bf01011469}, 
abstract = {{The system of equations introduced by Lorenz to model turbulent convective flow is studied here for Rayleigh numbersr somewhat smaller than the critical value required for sustained chaotic behavior. In this regime the system is found to exhibit transient chaotic behavior. Some statistical properties of this transient chaos are examined numerically. A mean decay time from chaos to steady flow is found and its dependence uponr is studied both numerically and (very close to the criticalr) analytically.}}, 
pages = {263--277}, 
number = {3}, 
volume = {21}, 
keywords = {}
}
@article{pomeau1979intermittency, 
year = {1979}, 
title = {{Intermittency and the Lorenz model}}, 
author = {Manneville, P. and Pomeau, Y.}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(79)90255-x}, 
abstract = {{The Lorenz system is shown to display intermittency at the transition from the first limit cycle to the second strange attractor.}}, 
pages = {1--2}, 
number = {1-2}, 
volume = {75}, 
keywords = {}
}
@article{10.1016/s0960-0779(97)00047-7, 
year = {1998}, 
title = {{Practical stability of chaotic attractors}}, 
author = {Kapitaniak, T. and Brindley, J.}, 
journal = {Chaos, Solitons \& Fractals}, 
issn = {0960-0779}, 
doi = {10.1016/s0960-0779(97)00047-7}, 
abstract = {{In this paper we introduce the concept of practical stability and practical stability in finite time for chaotic attractors. The connection between practical and asymptotic stability is discussed.}}, 
pages = {43--50}, 
number = {1-2}, 
volume = {9}, 
keywords = {}
}
@article{10.1103/revmodphys.78.1213, 
year = {2006}, 
title = {{Dynamical principles in neuroscience}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo and Selverston, Allen I. and Abarbanel, Henry D. I.}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.78.1213}, 
abstract = {{Dynamical modeling of neural systems and brain functions has a history of success over the last half century. This includes, for example, the explanation and prediction of some features of neural rhythmic behaviors. Many interesting dynamical models of learning and memory based on physiological experiments have been suggested over the last two decades. Dynamical models even of consciousness now exist. Usually these models and results are based on traditional approaches and paradigms of nonlinear dynamics including dynamical chaos. Neural systems are, however, an unusual subject for nonlinear dynamics for several reasons: (i) Even the simplest neural network, with only a few neurons and synaptic connections, has an enormous number of variables and control parameters. These make neural systems adaptive and flexible, and are critical to their biological function. (ii) In contrast to traditional physical systems described by well-known basic principles, first principles governing the dynamics of neural systems are unknown. (iii) Many different neural systems exhibit similar dynamics despite having different architectures and different levels of complexity. (iv) The network architecture and connection strengths are usually not known in detail and therefore the dynamical analysis must, in some sense, be probabilistic. (v) Since nervous systems are able to organize behavior based on sensory inputs, the dynamical modeling of these systems has to explain the transformation of temporal information into combinatorial or combinatorial-temporal codes, and vice versa, for memory and recognition. In this review these problems are discussed in the context of addressing the stimulating questions: What can neuroscience learn from nonlinear dynamics, and what can nonlinear dynamics learn from neuroscience?}}, 
pages = {1213--1265}, 
number = {4}, 
volume = {78}, 
keywords = {}
}
@article{10.1126/science.aat6412, 
year = {2018}, 
title = {{Transient phenomena in ecology}}, 
author = {Hastings, Alan and Abbott, Karen C. and Cuddington, Kim and Francis, Tessa and Gellner, Gabriel and Lai, Ying-Cheng and Morozov, Andrew and Petrovskii, Sergei and Scranton, Katherine and Zeeman, Mary Lou}, 
journal = {Science}, 
issn = {0036-8075}, 
doi = {10.1126/science.aat6412}, 
pmid = {30190378}, 
abstract = {{The importance of transient dynamics in ecological systems and in the models that describe them has become increasingly recognized. However, previous work has typically treated each instance of these dynamics separately. We review both empirical examples and model systems, and outline a classification of transient dynamics based on ideas and concepts from dynamical systems theory. This classification provides ways to understand the likelihood of transients for particular systems, and to guide investigations to determine the timing of sudden switches in dynamics and other characteristics of transients. Implications for both management and underlying ecological theories emerge.}}, 
number = {6406}, 
volume = {361}, 
keywords = {}
}
@article{schuller2020kramer, 
year = {2020}, 
title = {{Kramers’ escape rate problem within a non-Markovian description}}, 
author = {Schüller, Benjamin and Meistrenko, Alex and Hees, Hendrik van and Xu, Zhe and Greiner, Carsten}, 
journal = {Annals of Physics}, 
issn = {0003-4916}, 
doi = {10.1016/j.aop.2019.168045}, 
eprint = {1905.09652}, 
abstract = {{We compare the thermal escape rates of a Brownian particle, initially trapped into one of the two wells of an asymmetric double-well potential, for thermal Markovian and non-Markovian noise. The Markovian treatment of this problem goes originally back to the studies of Kramers in 1940 and is therefore often referred to as “Kramers’ escape rate problem”. We solve the generalized Langevin equation for the trajectories of the particles numerically and analytically for both limiting cases, Markovian and non-Markovian thermal noise. We compute the escape rate and work out the fundamental differences arising from finite correlation times of the thermal noise.}}, 
pages = {168045}, 
volume = {412}, 
keywords = {}
}
@article{10.1017/s0305004100064732, 
year = {1988}, 
title = {{Structurally stable heteroclinic cycles}}, 
author = {Guckenheimer, John and Holmes, Philip}, 
journal = {Mathematical Proceedings of the Cambridge Philosophical Society}, 
issn = {0305-0041}, 
doi = {10.1017/s0305004100064732}, 
abstract = {{This paper describes a previously undocumented phenomenon in dynamical systems theory; namely, the occurrence of heteroclinic cycles that are structurally stable within the space of Cr vector fields equivariant with respect to a symmetry group. In the space X(M) of Cr vector fields on a manifold M, there is a residual set of vector fields having no trajectories joining saddle points with stable manifolds of the same dimension. Such heteroclinic connections are a structurally unstable phenomenon [4]. However, in the space XG(M) ⊂ X(M) of vector fields equivariant with respect to a symmetry group G, the situation can be quite different. We give an example of an open set U of topologically equivalent vector fields in the space of vector fields on ℝ3 equivariant with respect to a particular finite subgroup G ⊂ O(3) such that each X ∈ U has a heteroclinic cycle that is an attractor. The heteroclinic cycles consist of three equilibrium points and three trajectories joining them.}}, 
pages = {189--192}, 
number = {1}, 
volume = {103}, 
keywords = {}
}
@article{hanggi1986escape, 
year = {1986}, 
title = {{Escape from a metastable state}}, 
author = {Hanggi, Peter}, 
journal = {Journal of Statistical Physics}, 
issn = {0022-4715}, 
doi = {10.1007/bf01010843}, 
abstract = {{Many important processes in science involve the escape of a particle over a barrier. In this review, we report, extend, and interpret various theories of noise-activated escape. We discuss the connection between many-body transition state theory and Kramers' original diffusive Brownian motion approach (both in one-and multidimensional potential fields) and emphasize the physical situation inherent in Kramers' rate for weak friction. A rate theory accounting for memory friction is presented together with a set of criteria which test its validity. The complications and peculiarities of noise-activated escape in driven systems exhibiting multiple, locally stable stationary nonequilibrium states are identified and illustrated. At lower temperatures, quantum tunneling effects begin to play an increasingly important role. Early approaches and more recent developments of the quantum version of Kramers approach are discussed, thereby providing a description for dissipative escape at all temperatures.}}, 
pages = {105--148}, 
number = {1-2}, 
volume = {42}, 
keywords = {}
}
@article{10.1103/revmodphys.90.031001, 
year = {2018}, 
title = {{Colloquium: Criticality and dynamical scaling in living systems}}, 
author = {Muñoz, Miguel A.}, 
journal = {Reviews of Modern Physics}, 
issn = {0034-6861}, 
doi = {10.1103/revmodphys.90.031001}, 
eprint = {1712.04499}, 
abstract = {{A celebrated and controversial hypothesis suggests that some biological systems—parts, aspects, or groups of them—may extract important functional benefits from operating at the edge of instability, halfway between order and disorder, i.e., in the vicinity of the critical point of a phase transition. Criticality has been argued to provide biological systems with an optimal balance between robustness against perturbations and flexibility to adapt to changing conditions as well as to confer on them optimal computational capabilities, large dynamical repertoires, unparalleled sensitivity to stimuli, etc. Criticality, with its concomitant scale invariance, can be conjectured to emerge in living systems as the result of adaptive and evolutionary processes that, for reasons to be fully elucidated, select for it as a template upon which further layers of complexity can rest. This hypothesis is suggestive as it proposes that criticality could constitute a general and common organizing strategy in biology stemming from the physics of phase transitions. However, despite its implications, this is still in its infancy state as a well-founded theory and, as such, it has elicited some skepticism. From the experimental side, the advent of high-throughput technologies has created new prospects in the exploration of biological systems, and empirical evidence in favor of criticality has proliferated, with examples ranging from endogenous brain activity and gene-expression patterns to flocks of birds and insect-colony foraging, to name but a few. Some pieces of evidence are quite remarkable, while in some other cases empirical data are limited, incomplete, or not fully convincing. More stringent experimental setups and theoretical analyses are certainly needed to fully clarify the picture. In any case, the time seems ripe for bridging the gap between this theoretical conjecture and its empirical validation. Given the profound implications of shedding light on this issue, it is both pertinent and timely to review the state of the art and to discuss future strategies and perspectives.}}, 
pages = {031001}, 
number = {3}, 
volume = {90}, 
keywords = {}
}
@article{brinkman2022metastable, 
year = {2022}, 
title = {{Metastable dynamics of neural circuits and networks}}, 
author = {Brinkman, B. A. W. and Yan, H. and Maffei, A. and Park, I. M. and Fontanini, A. and Wang, J. and Camera, G. La}, 
journal = {Applied Physics Reviews}, 
issn = {1931-9401}, 
doi = {10.1063/5.0062603}, 
pmid = {35284030}, 
pmcid = {PMC8900181}, 
eprint = {2110.03025}, 
abstract = {{Cortical neurons emit seemingly erratic trains of action potentials or “spikes,” and neural network dynamics emerge from the coordinated spiking activity within neural circuits. These rich dynamics manifest themselves in a variety of patterns, which emerge spontaneously or in response to incoming activity produced by sensory inputs. In this Review, we focus on neural dynamics that is best understood as a sequence of repeated activations of a number of discrete hidden states. These transiently occupied states are termed “metastable” and have been linked to important sensory and cognitive functions. In the rodent gustatory cortex, for instance, metastable dynamics have been associated with stimulus coding, with states of expectation, and with decision making. In frontal, parietal, and motor areas of macaques, metastable activity has been related to behavioral performance, choice behavior, task difficulty, and attention. In this article, we review the experimental evidence for neural metastable dynamics together with theoretical approaches to the study of metastable activity in neural circuits. These approaches include (i) a theoretical framework based on non-equilibrium statistical physics for network dynamics; (ii) statistical approaches to extract information about metastable states from a variety of neural signals; and (iii) recent neural network approaches, informed by experimental results, to model the emergence of metastable dynamics. By discussing these topics, we aim to provide a cohesive view of how transitions between different states of activity may provide the neural underpinnings for essential functions such as perception, memory, expectation, or decision making, and more generally, how the study of metastable neural activity may advance our understanding of neural circuit function in health and disease.}}, 
pages = {011313}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{10.1016/j.cub.2015.11.062, 
year = {2016}, 
title = {{Local Slow Waves in Superficial Layers of Primary Cortical Areas during REM Sleep}}, 
author = {Funk, Chadd M. and Honjoh, Sakiko and Rodriguez, Alexander V. and Cirelli, Chiara and Tononi, Giulio}, 
journal = {Current Biology}, 
issn = {0960-9822}, 
doi = {10.1016/j.cub.2015.11.062}, 
pmid = {26804554}, 
pmcid = {PMC4747819}, 
abstract = {{Sleep is traditionally constituted of two global behavioral states, non-rapid eye movement (NREM) and rapid eye movement (REM), characterized by quiescence and reduced responsiveness to sensory stimuli [1]. NREM sleep is distinguished by slow waves and spindles throughout the cerebral cortex and REM sleep by an “activated,” low-voltage fast electroencephalogram (EEG) paradoxically similar to that of wake, accompanied by rapid eye movements and muscle atonia. However, recent evidence has shown that cortical activity patterns during wake and NREM sleep are not as global as previously thought. Local slow waves can appear in various cortical regions in both awake humans [2] and rodents [3–5]. Intracranial recordings in humans [6] and rodents [4, 7] have shown that NREM sleep slow waves most often involve only a subset of brain regions that varies from wave to wave rather than occurring near synchronously across all cortical areas. Moreover, some cortical areas can transiently “wake up” [8] in an otherwise sleeping brain. Yet until now, cortical activity during REM sleep was thought to be homogenously wake-like. We show here, using local laminar recordings in freely moving mice, that slow waves occur regularly during REM sleep, but only in primary sensory and motor areas and mostly in layer 4, the main target of relay thalamic inputs, and layer 3. This finding may help explain why, during REM sleep, we remain disconnected from the environment even though the bulk of the cortex shows wake-like, paradoxical activation.}}, 
pages = {396--403}, 
number = {3}, 
volume = {26}, 
keywords = {}
}
@article{undefined, 
year = {2021}, 
title = {{Asymmetric Adaptivity induces Recurrent Synchronization in Complex Networks}}, 
author = {Thiele, Max and Berner, Rico and Tass, Peter A and Schöll, Eckehard and Yanchuk, Serhiy}, 
journal = {arXiv}, 
eprint = {2112.08697}, 
abstract = {{Rhythmic activities that alternate between coherent and incoherent phases are ubiquitous in chemical, ecological, climate, or neural systems. Despite their importance, general mechanisms for their emergence are little understood. In order to fill this gap, we present a framework for describing the emergence of recurrent synchronization in complex networks with adaptive interactions. This phenomenon is manifested at the macroscopic level by temporal episodes of coherent and incoherent dynamics that alternate recurrently. At the same time, the dynamics of the individual nodes do not change qualitatively. We identify asymmetric adaptation rules and temporal separation between the adaptation and the dynamics of individual nodes as key ingredients for the emergence of recurrent synchronization. Our results suggest that asymmetric adaptation might play a fundamental role for pattern generators, e.g., in neuronal systems.}}, 
keywords = {}
}
@article{10.1016/j.neuron.2009.07.018, 
year = {2009}, 
title = {{Generating Coherent Patterns of Activity from Chaotic Neural Networks}}, 
author = {Sussillo, David and Abbott, L.F.}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2009.07.018}, 
pmid = {19709635}, 
pmcid = {PMC2756108}, 
abstract = {{Neural circuits display complex activity patterns both spontaneously and when responding to a stimulus or generating a motor output. How are these two forms of activity related? We develop a procedure called FORCE learning for modifying synaptic strengths either external to or within a model neural network to change chaotic spontaneous activity into a wide variety of desired activity patterns. FORCE learning works even though the networks we train are spontaneously chaotic and we leave feedback loops intact and unclamped during learning. Using this approach, we construct networks that produce a wide variety of complex output patterns, input-output transformations that require memory, multiple outputs that can be switched by control inputs, and motor patterns matching human motion capture data. Our results reproduce data on premovement activity in motor and premotor cortex, and suggest that synaptic plasticity may be a more rapid and powerful modulator of network activity than generally appreciated.}}, 
pages = {544--557}, 
number = {4}, 
volume = {63}, 
keywords = {}
}
@article{10.1186/s13408-015-0033-6, 
year = {2016}, 
title = {{Mathematical Frameworks for Oscillatory Network Dynamics in Neuroscience}}, 
author = {Ashwin, Peter and Coombes, Stephen and Nicks, Rachel}, 
journal = {Journal of Mathematical Neuroscience}, 
doi = {10.1186/s13408-015-0033-6}, 
pmid = {26739133}, 
pmcid = {PMC4703605}, 
eprint = {1506.05828}, 
abstract = {{The tools of weakly coupled phase oscillator theory have had a profound impact on the neuroscience community, providing insight into a variety of network behaviours ranging from central pattern generation to synchronisation, as well as predicting novel network states such as chimeras. However, there are many instances where this theory is expected to break down, say in the presence of strong coupling, or must be carefully interpreted, as in the presence of stochastic forcing. There are also surprises in the dynamical complexity of the attractors that can robustly appear—for example, heteroclinic network attractors. In this review we present a set of mathematical tools that are suitable for addressing the dynamics of oscillatory neural networks, broadening from a standard phase oscillator perspective to provide a practical framework for further successful applications of mathematics to understanding network dynamics in neuroscience.}}, 
pages = {2}, 
number = {1}, 
volume = {6}, 
keywords = {}
}
@article{10.1523/jneurosci.1895-20.2021, 
year = {2021}, 
title = {{State-Dependent Regulation of Cortical Processing Speed via Gain Modulation}}, 
author = {Wyrick, David and Mazzucato, Luca}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.1895-20.2021}, 
pmid = {33858943}, 
abstract = {{To thrive in dynamic environments, animals must be capable of rapidly and flexibly adapting behavioral responses to a changing context and internal state. Examples of behavioral flexibility include faster stimulus responses when attentive and slower responses when distracted. Contextual or state-dependent modulations may occur early in the cortical hierarchy and may be implemented via top-down projections from corticocortical or neuromodulatory pathways. However, the computational mechanisms mediating the effects of such projections are not known. Here, we introduce a theoretical framework to classify the effects of cell type-specific top-down perturbations on the information processing speed of cortical circuits. Our theory demonstrates that perturbation effects on stimulus processing can be predicted by intrinsic gain modulation, which controls the timescale of the circuit dynamics. Our theory leads to counterintuitive effects, such as improved performance with increased input variance. We tested the model predictions using large-scale electrophysiological recordings from the visual hierarchy in freely running mice, where we found that a decrease in single-cell intrinsic gain during locomotion led to an acceleration of visual processing. Our results establish a novel theory of cell type-specific perturbations, applicable to top-down modulation as well as optogenetic and pharmacological manipulations. Our theory links connectivity, dynamics, and information processing via gain modulation.SIGNIFICANCE STATEMENT To thrive in dynamic environments, animals adapt their behavior to changing circumstances and different internal states. Examples of behavioral flexibility include faster responses to sensory stimuli when attentive and slower responses when distracted. Previous work suggested that contextual modulations may be implemented via top-down inputs to sensory cortex coming from higher brain areas or neuromodulatory pathways. Here, we introduce a theory explaining how the speed at which sensory cortex processes incoming information is adjusted by changes in these top-down projections, which control the timescale of neural activity. We tested our model predictions in freely running mice, revealing that locomotion accelerates visual processing. Our theory is applicable to internal modulation as well as optogenetic and pharmacological manipulations and links circuit connectivity, dynamics, and information processing.}}, 
pages = {3988--4005}, 
number = {18}, 
volume = {41}, 
keywords = {}
}
@article{10.1101/2021.10.11.463861, 
year = {2021}, 
title = {{A reservoir of timescales in random neural networks}}, 
author = {Stern, Merav and Istrate, Nicolae and Mazzucato, Luca}, 
journal = {bioRxiv}, 
doi = {10.1101/2021.10.11.463861}, 
abstract = {{The temporal activity of many biological systems, including neural circuits, exhibits fluctuations simultaneously varying over a large range of timescales. The mechanisms leading to this temporal heterogeneity are yet unknown. Here we show that random neural networks endowed with a distribution of self-couplings, representing functional neural clusters of different sizes, generate multiple timescales activity spanning several orders of magnitude. When driven by a time-dependent broadband input, slow and fast neural clusters preferentially entrain slow and fast spectral components of the input, respectively, suggesting a potential mechanism for spectral demixing in cortical circuits. occur.}}, 
pages = {2021.10.11.463861}, 
keywords = {}
}
@article{10.1038/nn.3616, 
year = {2014}, 
title = {{Temporal structure of motor variability is dynamically regulated and predicts motor learning ability}}, 
author = {Wu, Howard G and Miyamoto, Yohsuke R and Castro, Luis Nicolas Gonzalez and Ölveczky, Bence P and Smith, Maurice A}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/nn.3616}, 
pmid = {24413700}, 
pmcid = {PMC4442489}, 
abstract = {{Here the authors report that higher levels of task-relevant motor variability predict faster learning both across individuals and across tasks in two different paradigms and that training can reshape the temporal structure of motor variability, aligning it with the trained task to improve learning. These results support the importance of action exploration, a key idea from reinforcement learning theory. Individual differences in motor learning ability are widely acknowledged, yet little is known about the factors that underlie them. Here we explore whether movement-to-movement variability in motor output, a ubiquitous if often unwanted characteristic of motor performance, predicts motor learning ability. Surprisingly, we found that higher levels of task-relevant motor variability predicted faster learning both across individuals and across tasks in two different paradigms, one relying on reward-based learning to shape specific arm movement trajectories and the other relying on error-based learning to adapt movements in novel physical environments. We proceeded to show that training can reshape the temporal structure of motor variability, aligning it with the trained task to improve learning. These results provide experimental support for the importance of action exploration, a key idea from reinforcement learning theory, showing that motor variability facilitates motor learning in humans and that our nervous systems actively regulate it to improve learning.}}, 
pages = {312--321}, 
number = {2}, 
volume = {17}, 
keywords = {}
}
@article{10.1371/journal.pcbi.0020165, 
year = {2007}, 
title = {{Computational Aspects of Feedback in Neural Circuits}}, 
author = {Maass, Wolfgang and Joshi, Prashant and Sontag, Eduardo D}, 
journal = {PLoS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.0020165}, 
pmid = {17238280}, 
pmcid = {PMC1779299}, 
abstract = {{It has previously been shown that generic cortical microcircuit models can perform complex real-time computations on continuous input streams, provided that these computations can be carried out with a rapidly fading memory. We investigate the computational capability of such circuits in the more realistic case where not only readout neurons, but in addition a few neurons within the circuit, have been trained for specific tasks. This is essentially equivalent to the case where the output of trained readout neurons is fed back into the circuit. We show that this new model overcomes the limitation of a rapidly fading memory. In fact, we prove that in the idealized case without noise it can carry out any conceivable digital or analog computation on time-varying inputs. But even with noise, the resulting computational model can perform a large class of biologically relevant real-time computations that require a nonfading memory. We demonstrate these computational implications of feedback both theoretically, and through computer simulations of detailed cortical microcircuit models that are subject to noise and have complex inherent dynamics. We show that the application of simple learning procedures (such as linear regression or perceptron learning) to a few neurons enables such circuits to represent time over behaviorally relevant long time spans, to integrate evidence from incoming spike trains over longer periods of time, and to process new information contained in such spike trains in diverse ways according to the current internal state of the circuit. In particular we show that such generic cortical microcircuits with feedback provide a new model for working memory that is consistent with a large set of biological constraints. Although this article examines primarily the computational role of feedback in circuits of neurons, the mathematical principles on which its analysis is based apply to a variety of dynamical systems. Hence they may also throw new light on the computational role of feedback in other complex biological dynamical systems, such as, for example, genetic regulatory networks.}}, 
pages = {e165}, 
number = {1}, 
volume = {3}, 
keywords = {}
}
@article{10.1063/1.2965095, 
year = {2008}, 
title = {{The Brain: What is Critical About It?}}, 
author = {Chialvo, Dante R. and Balenzuela, Pablo and Fraiman, Daniel}, 
journal = {AIP Conference Proceedings}, 
issn = {0094-243X}, 
doi = {10.1063/1.2965095}, 
eprint = {0804.0032}, 
abstract = {{We review the recent proposal that the most fascinating brain properties are related to the fact that it always stays close to a second order phase transition. In such conditions, the collective of neuronal groups can reliably generate robust and flexible behavior, because it is known that at the critical point there is the largest abundance of metastable states to choose from. Here we review the motivation, arguments and recent results, as well as further implications of this view of the functioning brain.}}, 
pages = {28--45}, 
number = {1}, 
volume = {1028}, 
keywords = {}
}
@article{ashwin2005when, 
year = {2005}, 
title = {{When instability makes sense}}, 
author = {Ashwin, Peter and Timme, Marc}, 
journal = {Nature}, 
issn = {0028-0836}, 
doi = {10.1038/436036b}, 
pmid = {16001052}, 
abstract = {{Mathematical models that use instabilities to describe changes of weather patterns or spacecraft trajectories are well established. Could such principles apply to the sense of smell, and to other aspects of neural computation?}}, 
pages = {36--37}, 
number = {7047}, 
volume = {436}, 
keywords = {}
}
@article{10.1146/annurev-neuro-062111-150351, 
year = {2012}, 
title = {{Attractor Dynamics of Spatially Correlated Neural Activity in the Limbic System}}, 
author = {Knierim, James J. and Zhang, Kechen}, 
journal = {Annual Review of Neuroscience}, 
issn = {0147-006x}, 
doi = {10.1146/annurev-neuro-062111-150351}, 
pmid = {22462545}, 
abstract = {{Attractor networks are a popular computational construct used to model different brain systems. These networks allow elegant computations that are thought to represent a number of aspects of brain function. Although there is good reason to believe that the brain displays attractor dynamics, it has proven difficult to test experimentally whether any particular attractor architecture resides in any particular brain circuit. We review models and experimental evidence for three systems in the rat brain that are presumed to be components of the rat's navigational and memory system. Head-direction cells have been modeled as a ring attractor, grid cells as a plane attractor, and place cells both as a plane attractor and as a point attractor. Whereas the models have proven to be extremely useful conceptual tools, the experimental evidence in their favor, although intriguing, is still mostly circumstantial.}}, 
pages = {267--285}, 
number = {1}, 
volume = {35}, 
keywords = {}
}
@article{10.1371/journal.pcbi.1003641, 
year = {2014}, 
title = {{A Signature of Attractor Dynamics in the CA3 Region of the Hippocampus}}, 
author = {Rennó-Costa, César and Lisman, John E. and Verschure, Paul F. M. J.}, 
journal = {PLoS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1003641}, 
pmid = {24854425}, 
pmcid = {PMC4031055}, 
abstract = {{The notion of attractor networks is the leading hypothesis for how associative memories are stored and recalled. A defining anatomical feature of such networks is excitatory recurrent connections. These “attract” the firing pattern of the network to a stored pattern, even when the external input is incomplete (pattern completion). The CA3 region of the hippocampus has been postulated to be such an attractor network; however, the experimental evidence has been ambiguous, leading to the suggestion that CA3 is not an attractor network. In order to resolve this controversy and to better understand how CA3 functions, we simulated CA3 and its input structures. In our simulation, we could reproduce critical experimental results and establish the criteria for identifying attractor properties. Notably, under conditions in which there is continuous input, the output should be “attracted” to a stored pattern. However, contrary to previous expectations, as a pattern is gradually “morphed” from one stored pattern to another, a sharp transition between output patterns is not expected. The observed firing patterns of CA3 meet these criteria and can be quantitatively accounted for by our model. Notably, as morphing proceeds, the activity pattern in the dentate gyrus changes; in contrast, the activity pattern in the downstream CA3 network is attracted to a stored pattern and thus undergoes little change. We furthermore show that other aspects of the observed firing patterns can be explained by learning that occurs during behavioral testing. The CA3 thus displays both the learning and recall signatures of an attractor network. These observations, taken together with existing anatomical and behavioral evidence, make the strong case that CA3 constructs associative memories based on attractor dynamics.}}, 
pages = {e1003641}, 
number = {5}, 
volume = {10}, 
keywords = {}
}
@article{datseris2020drwatson, 
year = {2020}, 
title = {{DrWatson: the perfect sidekick for your scientific inquiries}}, 
author = {Datseris, George and Isensee, Jonas and Pech, Sebastian and Gál, Tamás}, 
journal = {Journal of Open Source Software}, 
doi = {10.21105/joss.02673}, 
pages = {2673}, 
number = {54}, 
volume = {5}, 
keywords = {}
}
@article{rackauckas2016differential, 
year = {2016}, 
title = {{DifferentialEquations.jl – A Performant and Feature-Rich Ecosystem for Solving Differential Equations in Julia}}, 
author = {Rackauckas, Christopher and Nie, Qing}, 
journal = {Journal of Open Research Software}, 
issn = {2049-9647}, 
doi = {10.5334/jors.151}, 
abstract = {{DifferentialEquations.jl is a package for solving differential equations in Julia. It covers discrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations), ordinary differential equations, stochastic differential equations, algebraic differential equations, delay differential equations, hybrid differential equations, jump diffusions, and (stochastic) partial differential equations. Through extensive use of multiple dispatch, metaprogramming, plot recipes, foreign function interfaces (FFI), and call-overloading, DifferentialEquations.jl offers a unified user interface to solve and analyze various forms of differential equations while not sacrificing features or performance. Many modern features are integrated into the solvers, such as allowing arbitrary user-defined number systems for high-precision and arithmetic with physical units, built-in multithreading and parallelism, and symbolic calculation of Jacobians. Integrated into the package is an algorithm testing and benchmarking suite to both ensure accuracy and serve as an easy way for researchers to develop and distribute their own methods. Together, these features build a highly extendable suite which is feature-rich and highly performant.Funding statement: This work was partially supported by NIH grants P50GM76516 and R01GM107264 and NSF grants DMS1562176 and DMS1161621. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1321846, the National Academies of Science, Engineering, and Medicine via the Ford Foundation, and the National Institutes of Health Award T32 EB009418. Its contents are solely the responsibility of the authors and do not necessarily represent the official views of the NIH.}}, 
pages = {15}, 
number = {1}, 
volume = {5}, 
keywords = {}
}
@article{undefined, 
year = {2022}, 
title = {{Neural mechanisms underlying the temporal organization of naturalistic animal behavior}}, 
author = {Mazzucato, Luca}, 
journal = {arXiv}, 
eprint = {2203.02151}, 
abstract = {{Naturalistic animal behavior exhibits a strikingly complex organization in the temporal domain, whose variability stems from at least three sources: hierarchical, contextual, and stochastic. What are the neural mechanisms and computational principles generating such complex temporal features? In this review, we provide a critical assessment of the existing behavioral and neurophysiological evidence for these sources of temporal variability in naturalistic behavior. We crystallize recent studies which converge on an emergent mechanistic theory of temporal variability based on attractor neural networks and metastable dynamics, arising from the coordinated interactions between mesoscopic neural circuits. We highlight the crucial role played by structural heterogeneities and by noise arising in mesoscopic circuits. We assess the shortcomings and missing links in the current theoretical and experimental literature and propose new directions of investigations to fill these gaps.}}, 
keywords = {}
}
@article{boaretto2021discriminating, 
year = {2021}, 
title = {{Discriminating chaotic and stochastic time series using permutation entropy and artificial neural networks}}, 
author = {Boaretto, B. R. R. and Budzinski, R. C. and Rossi, K. L. and Prado, T. L. and Lopes, S. R. and Masoller, C.}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-021-95231-z}, 
pmid = {34349134}, 
pmcid = {PMC8338970}, 
abstract = {{Extracting relevant properties of empirical signals generated by nonlinear, stochastic, and high-dimensional systems is a challenge of complex systems research. Open questions are how to differentiate chaotic signals from stochastic ones, and how to quantify nonlinear and/or high-order temporal correlations. Here we propose a new technique to reliably address both problems. Our approach follows two steps: first, we train an artificial neural network (ANN) with flicker (colored) noise to predict the value of the parameter, α, that determines the strength of the correlation of the noise. To predict α the ANN input features are a set of probabilities that are extracted from the time series by using symbolic ordinal analysis. Then, we input to the trained ANN the probabilities extracted from the time series of interest, and analyze the ANN output. We find that the α value returned by the ANN is informative of the temporal correlations present in the time series. To distinguish between stochastic and chaotic signals, we exploit the fact that the difference between the permutation entropy (PE) of a given time series and the PE of flicker noise with the same α parameter is small when the time series is stochastic, but it is large when the time series is chaotic. We validate our technique by analysing synthetic and empirical time series whose nature is well established. We also demonstrate the robustness of our approach with respect to the length of the time series and to the level of noise. We expect that our algorithm, which is freely available, will be very useful to the community.}}, 
pages = {15789}, 
number = {1}, 
volume = {11}, 
keywords = {}
}
@article{Cabral.2022, 
year = {2022}, 
keywords = {Metastability}, 
title = {{Synchronization in the connectome: Metastable oscillatory modes emerge from interactions in the brain spacetime network}}, 
author = {Cabral, Joana and Castaldo, Francesca and Vohryzek, Jakub and Litvak, Vladimir and Bick, Christian and Lambiotte, Renaud and Friston, Karl and Kringelbach, Morten L. and Deco, Gustavo}, 
journal = {bioRxiv}, 
doi = {10.1101/2022.01.06.475196}, 
abstract = {{A rich repertoire of oscillatory signals is detected from human brains with electro- and magnetoencephalography (EEG/MEG). However, the principles underwriting coherent oscillations and their link with neural activity remain unclear. Here, we hypothesise that the emergence of transient brain rhythms is a signature of weakly stable synchronization between spatially distributed brain areas, occurring at network-specific collective frequencies due to non-negligible conduction times. We test this hypothesis using a phenomenological network model to simulate interactions between neural mass potentials (resonating at 40Hz) in the structural connectome. Crucially, we identify a critical regime where metastable oscillatory modes emerge spontaneously in the delta (0.5-4Hz), theta (4-8Hz), alpha (8-13Hz) and beta (13-30Hz) frequency bands from weak synchronization of subsystems, closely approximating the MEG power spectra from 89 healthy individuals. Grounded in the physics of delay-coupled oscillators, these numerical analyses demonstrate the role of the spatiotemporal connectome in structuring brain activity in the frequency domain.}}, 
pages = {2022.01.06.475196}
}
@article{fonollosa2015learning, 
year = {2015}, 
title = {{Learning of Chunking Sequences in Cognition and Behavior}}, 
author = {Fonollosa, Jordi and Neftci, Emre and Rabinovich, Mikhail}, 
journal = {PLOS Computational Biology}, 
issn = {1553-734X}, 
doi = {10.1371/journal.pcbi.1004592}, 
pmid = {26584306}, 
pmcid = {PMC4652905}, 
abstract = {{We often learn and recall long sequences in smaller segments, such as a phone number 858 534 22 30 memorized as four segments. Behavioral experiments suggest that humans and some animals employ this strategy of breaking down cognitive or behavioral sequences into chunks in a wide variety of tasks, but the dynamical principles of how this is achieved remains unknown. Here, we study the temporal dynamics of chunking for learning cognitive sequences in a chunking representation using a dynamical model of competing modes arranged to evoke hierarchical Winnerless Competition (WLC) dynamics. Sequential memory is represented as trajectories along a chain of metastable fixed points at each level of the hierarchy, and bistable Hebbian dynamics enables the learning of such trajectories in an unsupervised fashion. Using computer simulations, we demonstrate the learning of a chunking representation of sequences and their robust recall. During learning, the dynamics associates a set of modes to each information-carrying item in the sequence and encodes their relative order. During recall, hierarchical WLC guarantees the robustness of the sequence order when the sequence is not too long. The resulting patterns of activities share several features observed in behavioral experiments, such as the pauses between boundaries of chunks, their size and their duration. Failures in learning chunking sequences provide new insights into the dynamical causes of neurological disorders such as Parkinson’s disease and Schizophrenia.}}, 
pages = {e1004592}, 
number = {11}, 
volume = {11}, 
keywords = {}
}
@article{Ashwin.1998, 
year = {1998}, 
title = {{On the unfolding of a blowout bifurcation}}, 
author = {Ashwin, Peter and Aston, Philip J. and Nicol, Matthew}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/s0167-2789(97)80006-1}, 
abstract = {{Suppose a chaotic attractor A in an invariant subspace loses stability on varying a parameter. At the point of loss of stability, the most positive Lyapunov exponent of the natural measure on A crosses zero at what has been called a ‘blowout’ bifurcation.We introduce the notion of an essential basin of an attractor A. This is the set of points x such that accumulation points of the sequence of measures 1n∑n − 1k = 0δfk(x) are supported on A. We characterise supercritical and subcritical scenarios according to whether the Lebesgue measure of the essential basin of A is positive or zero.We study a drift-diffusion model and a model class of piecewise linear mappings of the plane. In the supercritical case, we find examples where a Lyapunov exponent of the branch of attractors may be positive (‘hyperchaos’) or negative, depending purely on the dynamics far from the invariant subspace. For the mappings we find asymptotically linear scaling of Lyapunov exponents, average distance from the subspace and basin size on varying a parameter. We conjecture that these are general characteristics of blowout bifurcations.}}, 
pages = {81--95}, 
number = {1-4}, 
volume = {111}, 
keywords = {}
}
@article{hindmarshmodel1984, 
year = {1984}, 
title = {{A model of neuronal bursting using three coupled first order differential equations}}, 
author = {Hindmarsh, J. L. and Rose, R. M.}, 
journal = {Proceedings of the Royal Society of London. Series B. Biological Sciences}, 
issn = {0080-4649}, 
doi = {10.1098/rspb.1984.0024}, 
pmid = {6144106}, 
abstract = {{We describe a modification to our recent model of the action potential which introduces two additional equilibrium points. By using stability analysis we show that one of these equilibrium points is a saddle point from which there are two separatrices which divide the phase plane into two regions. In one region all phase paths approach a limit cycle and in the other all phase paths approach a stable equilibrium point. A consequence of this is that a short depolarizing current pulse will change an initially silent model neuron into one that fires repetitively. Addition of a third equation limits this firing to either an isolated burst or a depolarizing afterpotential. When steady depolarizing current was applied to this model it resulted in periodic bursting. The equations, which were initially developed to explain isolated triggered bursts, therefore provide one of the simplest models of the more general phenomenon of oscillatory burst discharge.}}, 
pages = {87--102}, 
number = {1222}, 
volume = {221}, 
keywords = {}
}
@article{saha2017extreme, 
year = {2017}, 
title = {{Extreme events in FitzHugh-Nagumo oscillators coupled with two time delays}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {Physical Review E}, 
issn = {2470-0045}, 
doi = {10.1103/physreve.95.062219}, 
pmid = {28709240}, 
eprint = {1703.08300}, 
abstract = {{We study two identical FitzHugh-Nagumo oscillators which are coupled with one or two different time delays. If only a single-delay coupling is used, the length of the delay determines whether the synchronization manifold is transversally stable or unstable, exhibiting mixed-mode or chaotic oscillations in which the small amplitude oscillations are always in phase but the large amplitude oscillations are in phase or out of phase, respectively. For two delays we find an intricate dynamics which comprises an irregular alteration of small amplitude oscillations, in-phase and out-of-phase large amplitude oscillations, also called extreme events. This transient chaotic dynamics is sandwiched between a bubbling transition and a blowout bifurcation.}}, 
pages = {062219}, 
number = {6}, 
volume = {95}, 
keywords = {}
}
@article{heagy1994characterization, 
year = {1994}, 
title = {{Characterization of on-off intermittency}}, 
author = {Heagy, J. F. and Platt, N. and Hammel, S. M.}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.49.1140}, 
pmid = {9961322}, 
abstract = {{The recently reported behavior known as ‘‘on-off intermittency’’ [N. Platt, E. A. Spiegel, and C. Tresser, Phys. Rev. Lett. 70, 279 (1993)] is investigated in a class of one-dimensional maps that are multiplicatively coupled to either random or chaotic signals. Specific attention is paid to the conditions for the onset of intermittent behavior, the distribution of laminar phases, and the mean laminar phase as a function of the coupling strength. An exact expression is obtained for the distribution of laminar phases in the case of uniformly distributed random driving. A universal asymptotic -3/2 power-law distribution is proven to hold for a large class of random driving cases. Power-law scaling of the mean laminar phase as a function of coupling strength near onset is predicted for random driving, with a critical exponent of -1. Numerical studies with chaotically driven maps reveal similar behavior to random driving cases and suggest the need for a systematic study of ‘‘chaotic walks.’’}}, 
pages = {1140--1150}, 
number = {2}, 
volume = {49}, 
keywords = {}
}
@article{saha2018characteristics, 
year = {2018}, 
title = {{Characteristics of in-out intermittency in delay-coupled FitzHugh–Nagumo oscillators}}, 
author = {Saha, Arindam and Feudel, Ulrike}, 
journal = {The European Physical Journal Special Topics}, 
issn = {1951-6355}, 
doi = {10.1140/epjst/e2018-800085-0}, 
eprint = {1805.02159}, 
abstract = {{We analyze a pair of delay-coupled FitzHugh–Nagumo oscillators exhibiting in-out intermittency as a part of the generating mechanism of extreme events. We study in detail the characteristics of in-out intermittency and identify the invariant subsets involved – a saddle fixed point and a saddle periodic orbit – neither of which are chaotic as in the previously reported cases of in-out intermittency. Based on the analysis of a periodic attractor possessing in-out dynamics, we can characterize the approach to the invariant synchronization manifold and the spiralling out to the saddle periodic orbit with subsequent ejection from the manifold. Due to the striking similarities, this analysis of in-out dynamics also explains in-out intermittency}}, 
pages = {1205--1219}, 
number = {10-11}, 
volume = {227}, 
keywords = {}
}
@article{Blackbeard.2014, 
year = {2014}, 
title = {{From synchronisation to persistent optical turbulence in laser arrays}}, 
author = {Blackbeard, Nicholas and Wieczorek, Sebastian and Erzgräber, Hartmut and Dutta, Partha Sharathi}, 
journal = {Physica D: Nonlinear Phenomena}, 
issn = {0167-2789}, 
doi = {10.1016/j.physd.2014.07.007}, 
abstract = {{We define and study synchronisation in a linear array of nearest-neighbour coupled lasers. Our focus is on possible synchronisation types and the stability of their corresponding synchronisation manifolds with dependence on the coupling strength, the laser frequency detuning, the amount of shear (amplitude–phase coupling) in a single laser, and the array size. We classify, and give analytical conditions for the existence of complete synchronisation solutions, where all the lasers emit light with the same intensity and frequency. Furthermore, we derive stability criteria for two special cases where all the lasers oscillate (i) in-phase with each other and (ii) in anti-phase with their nearest neighbour(s). We then explain transitions from complete synchronisation, to partial synchronisation (where only a subset of the lasers synchronises), to persistent optical turbulence (where no lasers synchronise and each laser is chaotic) in terms of bifurcations including blowouts of chaotic attractors. Finally, we quantify properties of optical turbulence using Lyapunov spectrum and dimension, which highlights differences in chaos generated by nearest-neighbour and globally coupled oscillators.}}, 
pages = {43--58}, 
volume = {286}, 
keywords = {}
}
@article{ott1994blowout, 
year = {1994}, 
title = {{Blowout bifurcations: the occurrence of riddled basins and on-off intermittency}}, 
author = {Ott, Edward and Sommerer, John C.}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(94)90114-7}, 
abstract = {{We consider situations where a nonlinear dynamical system possesses a smooth invariant manifold. For parameter values p less than a critical value pc, the invariant manifold has within it a chaotic attractor of the system. As p increases through pc a blowout bifurcation takes place, in which the former attraction to the manifold changes to repulsion, and the chaotic set in the manifold ceases to be an attractor of the system. Depending on the dynamics away from the manifold, blowout bifurcations can be either hysteretic or nonhysteretic, and they are correspondingly accompanied either by riddled basins (in which the basin is a “fat fractal”) or by an extreme form of temporally intermittent bursting recently called on-off intermittency. The role of the dynamics away from the manifold in determining the hysteretic or supercritical nature of the bifurcation is explicitly illustrated with a numerical example.}}, 
pages = {39--47}, 
number = {1}, 
volume = {188}, 
keywords = {}
}
@article{ashwin1994bubbling, 
year = {1994}, 
title = {{Bubbling of attractors and synchronisation of chaotic oscillators}}, 
author = {Ashwin, Peter and Buescu, Jorge and Stewart, Ian}, 
journal = {Physics Letters A}, 
issn = {0375-9601}, 
doi = {10.1016/0375-9601(94)90947-4}, 
abstract = {{We present a system of two coupled identical chaotic electronic circuits that exhibit a blowout bifurcation resulting in loss of stability of the synchronised state. We introduce the concept of bubbling of an attractor, a new type of intermittency that is triggered by low levels of noise, and demonstrate numerical and experimental examples of this behaviour. In particular we observe bubbling near the synchronised state of two coupled chaotic oscillators. We give a theoretical description of the behaviour associated with locally riddled basins, emphasising the role of invariant measures. In general these are non-unique for a given chaotic attractor, which gives rise to a spectrum of Lyapunov exponents. The behaviour of the attractor depends on the whole spectrum. In particular, bubbling is associated with the loss of stability of an attractor in a dynamically invariant subspace, and is typical in such systems.}}, 
pages = {126--139}, 
number = {2}, 
volume = {193}, 
keywords = {}
}
@book{strogatz2002nonlinear, 
year = {2002}, 
title = {{Nonlinear Dynamics and Chaos}}, 
author = {Strogatz}, 
series = {Studies in nonlinearity}, 
publisher = {Westview}, 
keywords = {}, 
doi = {10.1201/9781420033830-8}
}
@article{tsuda2015chaotic, 
year = {2015}, 
title = {{Chaotic itinerancy and its roles in cognitive neurodynamics}}, 
author = {Tsuda, Ichiro}, 
journal = {Current Opinion in Neurobiology}, 
issn = {0959-4388}, 
doi = {10.1016/j.conb.2014.08.011}, 
pmid = {25217808}, 
abstract = {{Chaotic itinerancy is an autonomously excited trajectory through high-dimensional state space of cortical neural activity that causes the appearance of a temporal sequence of quasi-attractors. A quasi-attractor is a local region of weakly convergent flows that represent ordered activity, yet connected to divergent flows representing disordered, chaotic activity between the regions. In a cognitive neurodynamic aspect, quasi-attractors represent perceptions, thoughts and memories, chaotic trajectories between them with intelligent searches, such as history-dependent trial-and-error via exploration, and itinerancy with history-dependent sequences in thinking, speaking and writing.}}, 
pages = {67--71}, 
volume = {31}, 
keywords = {}
}
@article{rabinovich2014chunking, 
year = {2014}, 
title = {{Chunking dynamics: heteroclinics in mind}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo and Tristan, Irma and Afraimovich, Valentin S.}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2014.00022}, 
pmid = {24672469}, 
pmcid = {PMC3954027}, 
abstract = {{Recent results of imaging technologies and non-linear dynamics make possible to relate the structure and dynamics of functional brain networks to different mental tasks and to build theoretical models for the description and prediction of cognitive activity. Such models are non-linear dynamical descriptions of the interaction of the core components—brain modes—participating in a specific mental function. The dynamical images of different mental processes depend on their temporal features. The dynamics of many cognitive functions are transient. They are often observed as a chain of sequentially changing metastable states. A stable heteroclinic channel (SHC) consisting of a chain of saddles—metastable states—connected by unstable separatrices is a mathematical image for robust transients. In this paper we focus on hierarchical chunking dynamics that can represent several forms of transient cognitive activity. Chunking is a dynamical phenomenon that nature uses to perform information processing of long sequences by dividing them in shorter information items. Chunking, for example, makes more efficient the use of short-term memory by breaking up long strings of information (like in language where one can see the separation of a novel on chapters, paragraphs, sentences, and finally words). Chunking is important in many processes of perception, learning, and cognition in humans and animals. Based on anatomical information about the hierarchical organization of functional brain networks, we propose a cognitive network architecture that hierarchically chunks and super-chunks switching sequences of metastable states produced by winnerless competitive heteroclinic dynamics.}}, 
pages = {22}, 
volume = {8}, 
keywords = {}
}
@article{rabinovich2001dynamical, 
year = {2001}, 
title = {{Dynamical Encoding by Networks of Competing Neuron Groups: Winnerless Competition}}, 
author = {Rabinovich, M. and Volkovskii, A. and Lecanda, P. and Huerta, R. and Abarbanel, H. D. I. and Laurent, G.}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.87.068102}, 
pmid = {11497865}, 
abstract = {{Following studies of olfactory processing in insects and fish, we investigate neural networks whose dynamics in phase space is represented by orbits near the heteroclinic connections between saddle regions (fixed points or limit cycles). These networks encode input information as trajectories along the heteroclinic connections. If there are N neurons in the network, the capacity is approximately e(N-1)!, i.e., much larger than that of most traditional network structures. We show that a small winnerless competition network composed of FitzHugh-Nagumo spiking neurons efficiently transforms input information into a spatiotemporal output.}}, 
pages = {068102}, 
number = {6}, 
volume = {87}, 
keywords = {}
}
@article{Pascanu.2011, 
year = {2011}, 
title = {{A neurodynamical model for working memory}}, 
author = {Pascanu, Razvan and Jaeger, Herbert}, 
journal = {Neural Networks}, 
issn = {0893-6080}, 
doi = {10.1016/j.neunet.2010.10.003}, 
pmid = {21036537}, 
abstract = {{Neurodynamical models of working memory (WM) should provide mechanisms for storing, maintaining, retrieving, and deleting information. Many models address only a subset of these aspects. Here we present a rather simple WM model in which all of these performance modes are trained into a recurrent neural network (RNN) of the echo state network (ESN) type. The model is demonstrated on a bracket level parsing task with a stream of rich and noisy graphical script input. In terms of nonlinear dynamics, memory states correspond, intuitively, to attractors in an input-driven system. As a supplementary contribution, the article proposes a rigorous formal framework to describe such attractors, generalizing from the standard definition of attractors in autonomous (input-free) dynamical systems.}}, 
pages = {199--207}, 
number = {2}, 
volume = {24}, 
keywords = {}
}
@article{sasaki2007metastability, 
year = {2007}, 
title = {{Metastability of Active CA3 Networks}}, 
author = {Sasaki, T and Matsuki, N and Ikegaya, Y}, 
journal = {Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4514-06.2007}, 
pmid = {17234584}, 
abstract = {{The brain is spontaneously active even in the absence of external input. This ongoing background activity impacts neural information processing. We used functional multineuron calcium imaging (fMCI) to analyze the net structure of spontaneous CA3 network activity in hippocampal slice cultures loaded with Oregon Green 488 BAPTA-1 using a spinning disk confocal microscope (10-30 frames/s). Principal component analysis revealed that network states, defined by active cell ensembles, were stable but heterogenous and discrete. These states were stabilized through synaptic activity and maintained against external perturbations. A few discrete states emerged during our observation period of up to 30 min. Networks tended to stay in a single state for tens of seconds and then suddenly jump to a new state. After a state transition, the old state was rarely, if ever, revisited by the network during our observation period. This temporal profile of state transitions could not be simulated by a hidden Markov model, indicating that the state dynamics is nonrandomly organized. Within each state, the pattern of network activity tended to stabilize in a specific configuration. Neither maintenance nor transition of the network states required NMDA receptor activity. These findings suggest that the network states are metastable, rather than multistable, and might be governed by local attractor-like dynamics. The fMCI data analyzed here are available at http://hippocampus.jp/data/}}, 
pages = {517--528}, 
number = {3}, 
volume = {27}, 
keywords = {}
}
@article{alderson2020metastable, 
year = {2020}, 
title = {{Metastable neural dynamics underlies cognitive performance across multiple behavioural paradigms}}, 
author = {Alderson, Thomas H. and Bokde, Arun L. W. and Kelso, J. A. Scott and Maguire, Liam and Coyle, Damien}, 
journal = {Human Brain Mapping}, 
issn = {1065-9471}, 
doi = {10.1002/hbm.25009}, 
pmid = {32301561}, 
pmcid = {PMC7375112}, 
abstract = {{Despite resting state networks being associated with a variety of cognitive abilities, it remains unclear how these local areas act in concert to express particular cognitive operations. Theoretical and empirical accounts indicate that large‐scale resting state networks reconcile dual tendencies towards integration and segregation by operating in a metastable regime of their coordination dynamics. Metastability may confer important behavioural qualities by binding distributed local areas into large‐scale neurocognitive networks. We tested this hypothesis by analysing fMRI data in a large cohort of healthy individuals (N = 566) and comparing the metastability of the brain's large‐scale resting network architecture at rest and during the performance of several tasks. Metastability was estimated using a well‐defined collective variable capturing the level of 'phase‐locking' between large‐scale networks over time. Task‐based reasoning was principally characterised by high metastability in cognitive control networks and low metastability in sensory processing areas. Although metastability between resting state networks increased during task performance, cognitive ability was more closely linked to spontaneous activity. High metastability in the intrinsic connectivity of cognitive control networks was linked to novel problem solving or fluid intelligence, but was less important in tasks relying on previous experience or crystallised intelligence. Crucially, subjects with resting architectures similar or 'pre‐configured' to a task‐general arrangement demonstrated superior cognitive performance. Taken together, our findings support a key linkage between the spontaneous metastability of large‐scale networks in the cerebral cortex and cognition.}}, 
pages = {3212--3234}, 
number = {12}, 
volume = {41}, 
keywords = {}
}
@article{vandeville2010eeg, 
year = {2010}, 
title = {{EEG microstate sequences in healthy humans at rest reveal scale-free dynamics}}, 
author = {Ville, Dimitri Van De and Britz, Juliane and Michel, Christoph M.}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1007841107}, 
pmid = {20921381}, 
abstract = {{Recent findings identified electroencephalography (EEG) microstates as the electrophysiological correlates of fMRI resting-state networks. Microstates are defined as short periods (100 ms) during which the EEG scalp topography remains quasi-stable; that is, the global topography is fixed but strength might vary and polarity invert. Microstates represent the subsecond coherent activation within global functional brain networks. Surprisingly, these rapidly changing EEG microstates correlate significantly with activity in fMRI resting-state networks after convolution with the hemodynamic response function that constitutes a strong temporal smoothing filter. We postulate here that microstate sequences should reveal scale-free, self-similar dynamics to explain this remarkable effect and thus that microstate time series show dependencies over long time ranges. To that aim, we deploy wavelet-based fractal analysis that allows determining scale-free behavior. We find strong statistical evidence that microstate sequences are scale free over six dyadic scales covering the 256-ms to 16-s range. The degree of long-range dependency is maintained when shuffling the local microstate labels but becomes indistinguishable from white noise when equalizing microstate durations, which indicates that temporal dynamics are their key characteristic. These results advance the understanding of temporal dynamics of brain-scale neuronal network models such as the global workspace model. Whereas microstates can be considered the “atoms of thoughts,” the shortest constituting elements of cognition, they carry a dynamic signature that is reminiscent at characteristic timescales up to multiple seconds. The scale-free dynamics of the microstates might be the basis for the rapid reorganization and adaptation of the functional networks of the brain.}}, 
pages = {18179--18184}, 
number = {42}, 
volume = {107}, 
keywords = {}
}
@article{muller2016rotating, 
year = {2016}, 
title = {{Rotating waves during human sleep spindles organize global patterns of activity that repeat precisely through the night}}, 
author = {Muller, Lyle and Piantoni, Giovanni and Koller, Dominik and Cash, Sydney S and Halgren, Eric and Sejnowski, Terrence J}, 
journal = {eLife}, 
doi = {10.7554/elife.17267}, 
pmid = {27855061}, 
pmcid = {PMC5114016}, 
abstract = {{During sleep, the thalamus generates a characteristic pattern of transient, 11-15 Hz sleep spindle oscillations, which synchronize the cortex through large-scale thalamocortical loops. Spindles have been increasingly demonstrated to be critical for sleep-dependent consolidation of memory, but the specific neural mechanism for this process remains unclear. We show here that cortical spindles are spatiotemporally organized into circular wave-like patterns, organizing neuronal activity over tens of milliseconds, within the timescale for storing memories in large-scale networks across the cortex via spike-time dependent plasticity. These circular patterns repeat over hours of sleep with millisecond temporal precision, allowing reinforcement of the activity patterns through hundreds of reverberations. These results provide a novel mechanistic account for how global sleep oscillations and synaptic plasticity could strengthen networks distributed across the cortex to store coherent and integrated memories. DOI: http://dx.doi.org/10.7554/eLife.17267.001}}, 
pages = {e17267}, 
volume = {5}, 
keywords = {}
}
@article{hellyer2015cognitive, 
year = {2015}, 
title = {{Cognitive Flexibility through Metastable Neural Dynamics Is Disrupted by Damage to the Structural Connectome}}, 
author = {Hellyer, Peter J. and Scott, Gregory and Shanahan, Murray and Sharp, David J. and Leech, Robert}, 
journal = {The Journal of Neuroscience}, 
issn = {0270-6474}, 
doi = {10.1523/jneurosci.4648-14.2015}, 
pmid = {26085630}, 
pmcid = {PMC4469735}, 
abstract = {{Current theory proposes that healthy neural dynamics operate in a metastable regime, where brain regions interact to simultaneously maximize integration and segregation. Metastability may confer important behavioral properties, such as cognitive flexibility. It is increasingly recognized that neural dynamics are constrained by the underlying structural connections between brain regions. An important challenge is, therefore, to relate structural connectivity, neural dynamics, and behavior. Traumatic brain injury (TBI) is a pre-eminent structural disconnection disorder whereby traumatic axonal injury damages large-scale connectivity, producing characteristic cognitive impairments, including slowed information processing speed and reduced cognitive flexibility, that may be a result of disrupted metastable dynamics. Therefore, TBI provides an experimental and theoretical model to examine how metastable dynamics relate to structural connectivity and cognition. Here, we use complementary empirical and computational approaches to investigate how metastability arises from the healthy structural connectome and relates to cognitive performance. We found reduced metastability in large-scale neural dynamics after TBI, measured with resting-state functional MRI. This reduction in metastability was associated with damage to the connectome, measured using diffusion MRI. Furthermore, decreased metastability was associated with reduced cognitive flexibility and information processing. A computational model, defined by empirically derived connectivity data, demonstrates how behaviorally relevant changes in neural dynamics result from structural disconnection. Our findings suggest how metastable dynamics are important for normal brain function and contingent on the structure of the human connectome.}}, 
pages = {9050--9063}, 
number = {24}, 
volume = {35}, 
keywords = {}
}
@article{rabinovich2018discrete, 
year = {2018}, 
title = {{Discrete Sequential Information Coding: Heteroclinic Cognitive Dynamics}}, 
author = {Rabinovich, Mikhail I. and Varona, Pablo}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2018.00073}, 
pmid = {30245621}, 
pmcid = {PMC6137616}, 
abstract = {{Discrete sequential information coding is a key mechanism that transforms complex cognitive brain activity into a low-dimensional dynamical process based on the sequential switching among finite numbers of patterns. The storage size of the corresponding process is large because of the permutation capacity as a function of control signals in ensembles of these patterns. Extracting low-dimensional functional dynamics from multiple large-scale neural populations is a central problem both in neuro- and cognitive- sciences. Experimental results in the last decade represent a solid base for the creation of low-dimensional models of different cognitive functions and allow moving toward a dynamical theory of consciousness. We discuss here a methodology to build simple kinetic equations that can be the mathematical skeleton of this theory. Models of the corresponding discrete information processing can be designed using the following dynamical principles: (i) clusterization of the neural activity in space and time and formation of information patterns; (ii) robustness of the sequential dynamics based on heteroclinic chains of metastable clusters; and (iii) sensitivity of such sequential dynamics to intrinsic and external informational signals. We analyze sequential discrete coding based on winnerless competition low-frequency dynamics. Under such dynamics, entrainment, and heteroclinic coordination leads to a large variety of coding regimes that are invariant in time.}}, 
pages = {73}, 
volume = {12}, 
keywords = {}
}
@article{deco2015rethinking, 
year = {2015}, 
title = {{Rethinking segregation and integration: contributions of whole-brain modelling}}, 
author = {Deco, Gustavo and Tononi, Giulio and Boly, Melanie and Kringelbach, Morten L.}, 
journal = {Nature Reviews Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/nrn3963}, 
pmid = {26081790}, 
abstract = {{The brain balances the segregation and integration of incoming information to facilitate flexible cognition and behaviour. In this Opinion article, Deco and colleagues argue that whole-brain computational modelling based on neuroimaging data can provide insights into these segregation and integration processes. The brain regulates information flow by balancing the segregation and integration of incoming stimuli to facilitate flexible cognition and behaviour. The topological features of brain networks — in particular, network communities and hubs — support this segregation and integration but do not provide information about how external inputs are processed dynamically (that is, over time). Experiments in which the consequences of selective inputs on brain activity are controlled and traced with great precision could provide such information. However, such strategies have thus far had limited success. By contrast, recent whole-brain computational modelling approaches have enabled us to start assessing the effect of input perturbations on brain dynamics in silico.}}, 
pages = {430--439}, 
number = {7}, 
volume = {16}, 
keywords = {}
}
@article{tognoli2014enlarging, 
year = {2014}, 
title = {{Enlarging the scope: grasping brain complexity}}, 
author = {Tognoli, Emmanuelle and Kelso, J. A. Scott}, 
journal = {Frontiers in Systems Neuroscience}, 
issn = {1662-5137}, 
doi = {10.3389/fnsys.2014.00122}, 
pmid = {25009476}, 
pmcid = {PMC4070173}, 
eprint = {1310.7277}, 
abstract = {{To further advance our understanding of the brain, new concepts and theories are needed. In particular, the ability of the brain to create information flows must be reconciled with its propensity for synchronization and mass action. The theoretical and empirical framework of Coordination Dynamics, a key aspect of which is metastability, are presented as a starting point to study the interplay of integrative and segregative tendencies that are expressed in space and time during the normal course of brain and behavioral function. Some recent shifts in perspective are emphasized, that may ultimately lead to a better understanding of brain complexity.}}, 
pages = {122}, 
volume = {8}, 
keywords = {}
}
@article{lehmann1987eeg, 
year = {1987}, 
title = {{EEG alpha map series: brain micro-states by space-oriented adaptive segmentation}}, 
author = {Lehmann, D. and Ozaki, H. and Pal, I.}, 
journal = {Electroencephalography and Clinical Neurophysiology}, 
issn = {0013-4694}, 
doi = {10.1016/0013-4694(87)90025-3}, 
pmid = {2441961}, 
abstract = {{The spontaneous EEG, viewed as a series of momentary scalp field maps, shows stable map configurations (of periodically reversed polarity) for varying durations, and discontinuous changes of the configurations. For adaptive segmentation of map series into spatially stationary epochs, the maps at the times of maximal map relief are selected and spatially described by the 3wo locations of maximal and minimal (extreme) potentials; a segment ends if over time an extreme leaves its pre-set spatial window. Over 6 objects, the resting alpha EEG showed 210 msec mean segment duration; segments longer than 323 msec covered 50\% of the total time; the most prominent segment class (1.5\% of all classes) covered 20\% of total time (prominence varied strongly over classes; not all possible classes occured). Spectral power and phase of averages of adaptive and pre-determined segments demonstrated the adequacy of the strategy, and the homegeneity of adaptive segment classes by their reduced within-class variance. It is suggested that different segment classes manifest different brain functional states exerting different effects on information processing. The spatially stationary segments might be basic building blocks of brain information processing, possibly operationalizing consciousness time and offering a common phenomenology for spontaneous activity and event-related potentials. The functional significance of segments might be modes or steps of information processing or performance, tested, e.g., as reaction time.}}, 
pages = {271--288}, 
number = {3}, 
volume = {67}, 
keywords = {}
}
@article{afraimovich2010longrange, 
year = {2010}, 
title = {{Long-range Interactions, Stochasticity and Fractional Dynamics, Dedicated to George M. Zaslavsky (1935–2008)}}, 
author = {Afraimovich, Valentin S. and Muezzinoglu, Mehmet K. and Rabinovich, Mikhail I.}, 
journal = {Nonlinear Physical Science}, 
issn = {1867-8440}, 
doi = {10.1007/978-3-642-12343-6\_4}, 
abstract = {{Experimental neuroscience is often based on the implicit premise that the neural mechanisms underlying perception, emotion and cognition are well approximated by steady-state measurements of neuron activity or snapshot of images. We will unfold a new paradigm in the study of brain mental dynamics departing from the stable transient activity neural networks, as supported by experiments. Transients have two main features: (1) they are resistant to noise, and reliable even in the face of small variations in initial condition, (2) the transients are input-specific, and thus convey information about what caused them in the first place. This new dynamical view manifests a rigorous explanation of how perception, cognition, emotion, and other mental processes evolve as a sequence of metastable states in the brain and suggests the new approaches to the diagnostics of mental diseases. The mathematical image of robust and sensitive transients is a stable heteroclinic channel that is possibly the only dynamical object that satisfies all required conditions. We discuss the ideas that lead to the creation of a quantitative theory of mental human activity. For the convenience of the reader we put all mathematical details into Appendices.}}, 
pages = {133--175}, 
keywords = {}
}
@article{cordovapalomera2017disrupted, 
year = {2017}, 
title = {{Disrupted global metastability and static and dynamic brain connectivity across individuals in the Alzheimer's disease continuum.}}, 
author = {Córdova-Palomera, Aldo and Kaufmann, Tobias and Persson, Karin and Alnæs, Dag and Doan, Nhat Trung and Moberget, Torgeir and Lund, Martina Jonette and Barca, Maria Lage and Engvig, Andreas and Brækhus, Anne and Engedal, Knut and Andreassen, Ole A and Selbæk, Geir and Westlye, Lars T}, 
journal = {Scientific reports}, 
doi = {10.1038/srep40268}, 
pmid = {28074926}, 
pmcid = {PMC5225495}, 
abstract = {{As findings on the neuropathological and behavioral components of Alzheimer's disease (AD) continue to accrue, converging evidence suggests that macroscale brain functional disruptions may mediate their association. Recent developments on theoretical neuroscience indicate that instantaneous patterns of brain connectivity and metastability may be a key mechanism in neural communication underlying cognitive performance. However, the potential significance of these patterns across the AD spectrum remains virtually unexplored. We assessed the clinical sensitivity of static and dynamic functional brain disruptions across the AD spectrum using resting-state fMRI in a sample consisting of AD patients (n = 80) and subjects with either mild (n = 44) or subjective (n = 26) cognitive impairment (MCI, SCI). Spatial maps constituting the nodes in the functional brain network and their associated time-series were estimated using spatial group independent component analysis and dual regression, and whole-brain oscillatory activity was analyzed both globally (metastability) and locally (static and dynamic connectivity). Instantaneous phase metrics showed functional coupling alterations in AD compared to MCI and SCI, both static (putamen, dorsal and default-mode) and dynamic (temporal, frontal-superior and default-mode), along with decreased global metastability. The results suggest that brains of AD patients display altered oscillatory patterns, in agreement with theoretical premises on cognitive dynamics.}}, 
pages = {40268}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@book{gunton1983introduction, 
year = {1983}, 
title = {{Introduction to the Theory of Metastable and Unstable States}}, 
author = {Gunton, J. D. and Droz, M.}, 
isbn = {978-3-540-12306-4}, 
url = {https://www.springer.com/de/book/9783540123064}, 
abstract = {{Introduction to the Theory of Metastable and Unstable States...}}, 
urldate = {2021-05-25}, 
series = {Lecture Notes in Physics}, 
publisher = {Springer-Verlag}, 
address = {Berlin Heidelberg}, 
language = {en}, 
keywords = {}, 
doi = {10.1007/bfb0035331}
}
@article{sewell1980stability, 
year = {1980}, 
title = {{Stability, equilibrium and metastability in statistical mechanics}}, 
author = {Sewell, Geoffrey L.}, 
journal = {Physics Reports}, 
doi = {10.1016/0370-1573(80)90167-2}, 
url = {https://linkinghub.elsevier.com/retrieve/pii/0370157380901672}, 
abstract = {{We survey a body of work, containing some new material, concerning the characterisation of equilibrium and metastable states of large assemblies of particles in terms of a variety of stability conditions. The theory is formulated in the thermodynamic limit and is based on the premise that the former states are those that are stable against all dynamical and thermodynamical perturbations, whereas the latter ones are endowed with only limited stability, sufficing to guarantee their long lifetimes and good thermodynamical behaviour. The Kubo-Martin-Schwinger (KMS) fluctuation-dissipation conditions play a central role in the developments stemming from this viewpoint, since it turns out that these conditions represent stability against localised disturbances of both the dynamical and thermo-dynamical kinds. Consequently, the stability arguments invoked here lead us to the following principal conclusions: (1) The equilibrium states are those that minimise the free energy density of the system and also satisfy the KMS conditions. This substantiates Gibbs's hypothesis that these states correspond to the standard ensembles. (2) Metastable states are of two kinds, that we term “ideal” and “normal”. Those of the former type satisfy the KMS conditions but minimise only the restriction of the free energy density to some reduced state space: those of the latter type are characterised by a still lower grade of stability. (3) The conditions on the forces under which ideal metastable states can exist are very restrictive, and thus the normal ones generally correspond to those observed in nature.}}, 
pages = {307--342}, 
number = {5}, 
volume = {57}, 
language = {en}, 
keywords = {}
}
@article{fingelkurts2008brainmind, 
year = {2008}, 
title = {{Brain-Mind Operational Architectonics Imaging: Technical and Methodological Aspects}}, 
author = {Fingelkurts, Andrew A and Fingelkurts, Alexander A}, 
journal = {The Open Neuroimaging Journal}, 
issn = {1874-4400}, 
doi = {10.2174/1874440000802010073}, 
pmid = {19526071}, 
pmcid = {PMC2695620}, 
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2695620/}, 
abstract = {{This review paper deals with methodological and technical foundations of the Operational Architectonics framework of brain and mind functioning. This theory provides a framework for mapping and understanding important aspects of the brain mechanisms that constitute perception, cognition, and eventually consciousness. The methods utilized within Operational Architectonics framework allow analyzing with an incredible detail the operational behavior of local neuronal assemblies and their joint activity in the form of unified and metastable operational modules, which constitute the whole hierarchy of brain operations, operations of cognition and phenomenal consciousness.}}, 
shorttitle = {Brain-Mind Operational Architectonics Imaging}, 
pages = {73--93}, 
volume = {2}, 
keywords = {}
}
@article{alderson2018metastable, 
year = {2018}, 
title = {{Metastable neural dynamics in Alzheimer’s disease are disrupted by lesions to the structural connectome}}, 
author = {Alderson, Thomas H. and Bokde, Arun L.W. and Kelso, J.A. Scott and Maguire, Liam and Coyle, Damien}, 
journal = {NeuroImage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2018.08.033}, 
pmid = {30130642}, 
pmcid = {PMC6374703}, 
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6374703/}, 
abstract = {{Current theory suggests brain regions interact to reconcile the competing demands of integration and segregation by leveraging metastable dynamics. An
emerging consensus recognises the importance of metastability in healthy neural
dynamics where the transition between network states over time is dependent upon
the structural connectivity between brain regions. In Alzheimer’s disease
(AD) - the most common form of dementia - these couplings are progressively
weakened, metastability of neural dynamics are reduced and cognitive ability is
impaired. Accordingly, we use a joint empirical and computational approach to
reveal how behaviourally relevant changes in neural metastability are contingent
on the structural integrity of the anatomical connectome. We estimate the
metastability of fMRI BOLD signal in subjects from across the AD spectrum and in
healthy controls and demonstrate the dissociable effects of structural
disconnection on synchrony versus metastability. In addition, we reveal the
critical role of metastability in general cognition by demonstrating the link
between an individuals cognitive performance and their metastable neural
dynamic. Finally, using whole-brain computer modelling, we demonstrate how a
healthy neural dynamic is conditioned upon the topological integrity of the
structural con- nectome. Overall, the results of our joint computational and
empirical analysis suggest an important causal relationship between metastable
neural dynamics, cognition, and the structural efficiency of the anatomical
connectome.}}, 
pages = {438--455}, 
volume = {183}, 
keywords = {}
}
@article{gili2018metastable, 
year = {2018}, 
keywords = {brain networks,Electrophysiology,functional MRI,metastable state brain dynamics,multiscale modeling,Timing and Time perception}, 
title = {{Metastable States of Multiscale Brain Networks Are Keys to Crack the Timing Problem}}, 
author = {Gili, Tommaso and Ciullo, Valentina and Spalletta, Gianfranco}, 
journal = {Frontiers in Computational Neuroscience}, 
issn = {1662-5188}, 
doi = {10.3389/fncom.2018.00075}, 
pmid = {30254581}, 
pmcid = {PMC6141745}, 
url = {https://www.frontiersin.org/articles/10.3389/fncom.2018.00075/full}, 
abstract = {{The dynamic nature of the environment where we live in and the need to interact with it, predicting events in our context, provided strong evolutionary pressures for the brain functioning to process temporal information and generate timed responses. As a result of these pressures, the human brain is able to process temporal information and generate temporal patterns. Despite the clear importance of temporal processing to cognition, learning, communication and sensory, motor and emotional processing, even the most basic mechanisms of how animals discriminate simple intervals or generate timed responses are still under debate. The lesson we learned from the last decade of research in neuroscience is that functional and structural brain connectivity matter. Specifically, it has been accepted that the organization of the brain in interacting segregated networks enables its function. In this paper we delineate the route to a promising approach for investigating timing mechanisms. We illustrate how novel insight into timing mechanisms can come by investigating brain functioning as a multi-layer dynamical network whose clustered dynamics is bound to report the presence of metastable states. We anticipate that metastable dynamics underlie the real-time coordination necessary for the brain’s dynamic functioning associated with time perception. This new point of view will help further clarifying mechanisms of neuropsychiatric disorders.}}, 
pages = {75}, 
volume = {12}, 
language = {English}, 
note = {Publisher: Frontiers}
}
@article{Kelso, 
title = {{TOWARD A COMPLEMENTARY NEUROSCIENCE: METASTABLE COORDINATION DYNAMICS OF THE BRAIN}}, 
author = {Kelso, J A Scott and Tognoli, Emmanuelle}, 
abstract = {{Metastability has been proposed as a new principle of behavioral and brain function and may point the way to a truly complementary neuroscience. From elementary coordination dynamics we show explicitly that metastability is a result of a symmetry breaking caused by the subtle interplay of two forces: the tendency of the components to couple together and the tendency of the components to express their intrinsic independent behavior. The metastable regime reconciles the well-known tendencies of specialized brain regions to express their autonomy (segregation) and the tendencies for those regions to work together as a synergy (integration). Integration \textbackslashtextasciitilde segregation is just one of the complementary pairs (denoted by the tilde (\textbackslashtextasciitilde) symbol) to emerge from the science of coordination dynamics. We discuss metastability in the brain by describing the favorable conditions existing for its emergence and by deriving some predictions for its empirical characterization in neurophysiological recordings.}}, 
pages = {23}, 
language = {en}, 
keywords = {}
}
@book{Kozma.2016, 
year = {2016}, 
title = {{Cognitive Phase Transitions in the Cerebral Cortex - Enhancing the Neuron Doctrine by Modeling Neural Fields}}, 
author = {Kozma, Robert and Freeman, Walter J.}, 
isbn = {978-3-319-24404-4}, 
url = {https://www.springer.com/gp/book/9783319244044}, 
abstract = {{This intriguing book was born out of the many discussions the authors had in the past 10 years about the role of scale-free structure and dynamics in producing intelligent behavior in brains. The microscopic dynamics of neural networks is well described by the prevailing paradigm based in a narrow interpretation of the neuron doctrine. This book broadens the doctrine by incorporating the dynamics of neural fields, as first revealed by modeling with differential equations (K-sets). The book broadens that approach by application of random graph theory (neuropercolation). The book concludes with diverse commentaries that exemplify the wide range of mathematical/conceptual approaches to neural fields. This book is intended for researchers, postdocs, and graduate students, who see the limitations of network theory and seek a beachhead from which to embark on mesoscopic and macroscopic neurodynamics.}}, 
urldate = {2021-05-25}, 
series = {Studies in Systems, Decision and Control}, 
publisher = {Springer International Publishing}, 
language = {en}, 
keywords = {}, 
doi = {10.1007/978-3-319-24406-8}
}
@book{Singleton.2021, 
year = {2021}, 
title = {{LSD flattens the brain′s energy landscape: evidence from receptor-informed network control theory}}, 
author = {Singleton, S. and Luppi, Andrea and Carhart-Harris, Robin and Cruzat, Josephine and Roseman, Leor and Deco, Gustavo and Kringelbach, Morten and Stamatakis, Emmanuel and Kuceyeski, Amy}, 
abstract = {{Psychedelics like lysergic acid diethylamide (LSD) offer a powerful window into the function of the human brain and mind, by temporarily altering subjective experience through their neurochemical effects. The RElaxed Beliefs Under Psychedelics (REBUS) model postulates that 5-HT2a receptor agonism allows the brain to explore its dynamic landscape more readily, as suggested by more diverse (entropic) brain activity. Formally, this effect is theorized to correspond to a reduction in the energy required to transition between different brain-states, i.e. a “flattening of the energy landscape.” However, this hypothesis remains thus far untested. Here, we leverage network control theory to map the brain’s energy landscape, by quantifying the energy required to transition between recurrent brain states. In accordance with the REBUS model, we show that LSD reduces the energy required for brain-state transitions, and, furthermore, that this reduction in energy correlates with more frequent state transitions and increased entropy of brain-state dynamics. Through network control analysis that incorporates the spatial distribution of 5-HT2a receptors, we demonstrate the specific role of this receptor in flattening the brain’s energy landscape. Also, in accordance with REBUS, we show that the occupancy of bottom-up states is increased by LSD. In addition to validating fundamental predictions of the REBUS model of psychedelic action, this work highlights the potential of receptor-informed network control theory to provide mechanistic insights into pharmacological modulation of brain dynamics. 
Significance Statement
We present a multi-modal framework for quantifying the effects of a psychedelic drug (LSD) on brain dynamics by combining functional magnetic resonance imaging (fMRI), diffusion MRI (dMRI), positron emission tomography (PET) and network control theory. Our findings provide support for a fundamental theory of the mechanism of action of psychedelics by showing that LSD flattens the brain’s energy landscape, allowing for more facile and frequent state transitions and more temporally diverse brain activity. We also demonstrate that the spatial distribution of serotonin 2a receptors - the main target of LSD - is key for generating these effects. This approach could be used to understand how drugs act on different receptors in the brain to influence brain function.}}, 
shorttitle = {LSD flattens the brain′s energy landscape}, 
series = {bioRxiv}, 
keywords = {}, 
doi = {10.1101/2021.05.14.444193}
}
@article{makela1997metastable, 
year = {1997}, 
title = {{Metastable states in classical and quantum systems}}, 
author = {Makela, Mark and Parmley, Samantha and Yu, Roger}, 
journal = {American Journal of Physics}, 
issn = {0002-9505}, 
doi = {10.1119/1.18622}, 
url = {http://aapt.scitation.org/doi/10.1119/1.18622}, 
pages = {653--657}, 
number = {7}, 
volume = {65}, 
language = {en}, 
keywords = {}
}
@book{Kardar.2007, 
year = {2007}, 
title = {{Statistical Physics of Particles}}, 
author = {Kardar, Mehran}, 
isbn = {978-0-521-87342-0}, 
url = {https://www.cambridge.org/core/books/statistical-physics-of-particles/3CC2F33BD9F8DC56758DBDDB5B870558}, 
abstract = {{Statistical physics has its origins in attempts to describe the thermal properties of matter in terms of its constituent particles, and has played a fundamental role in the development of quantum mechanics. Based on lectures taught by Professor Kardar at MIT, this textbook introduces the central concepts and tools of statistical physics. It contains a chapter on probability and related issues such as the central limit theorem and information theory, and covers interacting particles, with an extensive description of the van der Waals equation and its derivation by mean field approximation. It also contains an integrated set of problems, with solutions to selected problems at the end of the book and a complete set of solutions is available to lecturers on a password protected website at www.cambridge.org/9780521873420. A companion volume, Statistical Physics of Fields, discusses non-mean field aspects of scaling and critical phenomena, through the perspective of renormalization group.}}, 
urldate = {2021-05-19}, 
publisher = {Cambridge University Press}, 
address = {Cambridge}, 
keywords = {}, 
doi = {10.1017/cbo9780511815898}
}
@incollection{Hollander.2009, 
year = {2009}, 
keywords = {Free Particle,Glauber Dynamic,Ising Model,Metastable Behavior,Simple Random Walk}, 
title = {{Three Lectures on Metastability Under Stochastic Dynamics}}, 
author = {Hollander, Frank den}, 
editor = {["Biskup and \{Bovier, Marek and\} and \{Hollander, Anton and den\} and \{Ioffe, Frank and\} and \{Martinelli, Dima and\} and \{Netočný, Fabio and\} and \{Toninelli, Karel and\} and \{Kotecký, Fabio and\} and Roman"]}, 
booktitle = {Methods of Contemporary Mathematical Statistical Physics}, 
isbn = {978-3-540-92796-9}, 
url = {https://doi.org/10.1007/978-3-540-92796-9\_5}, 
abstract = {{Metastability is a phenomenon where a physical, chemical or biological system, under the influence of a noisy dynamics, moves between different regions of its state space on different time scales. On short time scales the system is in a quasi-equilibrium within a single region, while on long time scales it undergoes rapid transitions between quasiequilibria in different regions (see Fig. 1).Examples of metastability can be found in: biology: folding of proteins; climatology: effects of global warming; economics: crashes of financial markets; materials science: anomalous relaxation in disordered media; physics: freezing of supercooled liquids. The task of mathematics is to formulate microscopic models of the relevant underlying dynamics, to prove the occurrence of metastable behavior in these models on macroscopic space-time scales, and to identify the key mechanisms behind the experimentally observed universality in the metastable behavior of whole classes of systems. This is a challenging program!}}, 
urldate = {2021-05-19}, 
pages = {223--246}, 
series = {Lecture Notes in Mathematics}, 
publisher = {Springer}, 
address = {Berlin, Heidelberg}, 
language = {en}, 
doi = {10.1007/978-3-540-92796-9\_5}
}
@article{Negrello.2008, 
year = {2008}, 
title = {{Attractor Landscapes and Active Tracking: The Neurodynamics of Embodied Action}}, 
author = {Negrello, Mario and Pasemann, Frank}, 
journal = {Adaptive Behavior}, 
issn = {1059-7123}, 
doi = {10.1177/1059712308090200}, 
url = {http://journals.sagepub.com/doi/10.1177/1059712308090200}, 
abstract = {{Behavior is the product of three intertwining dynamics: of the world, of the body and of internal control structures. Neurodynamics focuses on the dynamics of neural control, while observing interfaces with the world and the body. From this perspective, we present a dynamical analysis of embodied recurrent neural networks evolved to control a cybernetic device that solves a problem in active tracking. For competent action selection, agents must rely on the attractor landscapes of the evolved networks. Insights into how the networks achieve this are given in terms of the network's dynamical substrate, which highlights the role of the network's inherent attractors as they change as a function of the input parameters (sensors). We introduce some terminological extensions to neurodynamics to allow for a more precise formulation of how attractor changes influence behavior generation: in particular, attractor landscapes, which are the space of all attractors accessible through coherent parametrizations of the network (input stimuli), and the meta-transient, which resolves behavior by approaching attractors as they shape-shift. We apply these concepts to the analysis of interesting behaviors of the tracking device, such as temporal contextual dependency, chaotic transitory regimes in moments of ambiguity, and implicit mapping of environmental asymmetricities in the response of the device. Finally, we discuss the relevance of the concepts introduced in terms of autonomy, learning, and modularity.}}, 
shorttitle = {Attractor Landscapes and Active Tracking}, 
pages = {196--216}, 
number = {2-3}, 
volume = {16}, 
language = {en}, 
keywords = {}
}
@misc{Kelso.1995, 
year = {1995}, 
author = {Kelso, Scott}, 
title = {{Dynamic Patterns | The MIT Press}}, 
url = {https://mitpress.mit.edu/books/dynamic-patterns}, 
abstract = {{foreword by Hermann Haken For the past twenty years Scott Kelso's research has focused on extending the physical concepts of self- organization and the mathematical tools of nonlinear dynamics to understand how human beings (and human brains) perceive, intend, learn, control, and coordinate complex behaviors. In this book Kelso proposes a new, general framework within which to connect brain, mind, and behavior.Kelso's prescription for mental life breaks dramatically with the classical computational approach that is still the operative framework for many newer psychological and neurophysiological studies. His core thesis is that the creation and evolution of patterned behavior at all levels—from neurons to mind—is governed by the generic processes of self-organization. Both human brain and behavior are shown to exhibit features of pattern-forming dynamical systems, including multistability, abrupt phase transitions, crises, and intermittency.Dynamic Patterns brings together different aspects of this approach to the study of human behavior, using simple experimental examples and illustrations to convey essential concepts, strategies, and methods, with a minimum of mathematics.Kelso begins with a general account of dynamic pattern formation. He then takes up behavior, focusing initially on identifying pattern-forming instabilities in human sensorimotor coordination. Moving back and forth between theory and experiment, he establishes the notion that the same pattern-forming mechanisms apply regardless of the component parts involved (parts of the body, parts of the nervous system, parts of society) and the medium through which the parts are coupled. Finally, employing the latest techniques to observe spatiotemporal patterns of brain activity, Kelso shows that the human brain is fundamentally a pattern forming dynamical system, poised on the brink of instability. Self-organization thus underlies the cooperative action of neurons that produces human behavior in all its forms.}}, 
urldate = {2021-05-19}, 
publisher = {The MIT Press}, 
language = {en}, 
note = {Publisher: The MIT Press}, 
keywords = {}
}
@incollection{bovier2009metastability, 
year = {2009}, 
keywords = {Dirichlet Problem,Invariant Measure,Markov Chain,Markov Process,Small Eigenvalue}, 
title = {{Metastability}}, 
author = {Bovier, Anton}, 
editor = {["Biskup and \{Bovier, Marek and\} and \{Hollander, Anton and den\} and \{Ioffe, Frank and\} and \{Martinelli, Dima and\} and \{Netočný, Fabio and\} and \{Toninelli, Karel and\} and \{Kotecký, Fabio and\} and Roman"]}, 
booktitle = {Methods of Contemporary Mathematical Statistical Physics}, 
isbn = {978-3-540-92796-9}, 
url = {https://doi.org/10.1007/978-3-540-92796-9\_4}, 
abstract = {{In these lectures we will discuss Markov processes with a particular interest for a phenomenon called metastability. Basically this refers to the existence of two or more time-scales over which the system shows very different behaviour: on the short time scale, the systems reaches quickly a “pseudo-equilibrium” and remains effectively in a restricted subset of the available phase space; the particular pseudo-equilibrium that is reached will depend on the initial conditions. However, when observed on the longer time scale, one will occasionally observe transitions from one such pseudo-equilibrium to another one. In many cases (as we will see) there exists one particular time scale for each such pseudo-equilibrium; in other cases of interest, several, or even many, such distinct pseudo-equilibria exist having the same time scale of exit. Mathematically speaking, our interest is to derive the (statistical) properties of the process on these long time scales from the given description of the process on the microscopic time scale. In principle, our aim should be an effective model for the motion at the long time scale on a coarse grained state space; in fact, disregarding fast motion leads us naturally to consider a reduced state space that may be labeled in some way by the quasi-equilibria.The type of situation we sketched above occurs in many situations in nature. The classical example is of course the phenomenon of metastability in phase transitions: if a (sufficiently pure) container of water is cooled below freezing temperature, it may remain in the liquid state for a rather long period of time, but at some moment the entire container freezes extremely rapidly. In reality, this moment is of course mostly triggered by some slight external perturbation. Another example of the same phenomenon occurs in the dynamics of large bio-molecules, such as proteins. Such molecules frequently have several possible spatial conformations, transitions between which occur sporadically on often very long time scales. Another classical example is metastability in chemical reactions. Here reactants oscillate between several possible chemical compositions, sometimes nicely distinguished by different colours. This example was instrumental in the development of stochastic models for metastability by Eyring, Kramers and others [21, 30]. Today, metastable effects are invoked to explain a variety of diverse phenomena such as changes in global climate systems both on earth (ice-ages) and on Mars (liquid water presence), structural transitions on eco- and oeco systems, to name just a few examples.}}, 
urldate = {2021-05-19}, 
pages = {177--221}, 
series = {Lecture Notes in Mathematics}, 
publisher = {Springer}, 
address = {Berlin, Heidelberg}, 
language = {en}, 
doi = {10.1007/978-3-540-92796-9\_4}
}
@article{naik2017metastability, 
year = {2017}, 
title = {{Metastability in Senescence}}, 
author = {Naik, Shruti and Banerjee, Arpan and Bapi, Raju S. and Deco, Gustavo and Roy, Dipanjan}, 
journal = {Trends in Cognitive Sciences}, 
issn = {1364-6613}, 
doi = {10.1016/j.tics.2017.04.007}, 
pmid = {28499740}, 
url = {https://www.sciencedirect.com/science/article/abs/pii/S1364661317300797}, 
abstract = {{The brain during healthy aging exhibits gradual deterioration of structure but maintains a high level of cognitive ability. These structural changes a…}}, 
pages = {509--521}, 
number = {7}, 
volume = {21}, 
language = {en}, 
note = {Publisher: Elsevier Current Trends}, 
keywords = {}
}
@article{Kahana.2006, 
year = {2006}, 
keywords = {Brain,Cognition,Electroencephalography,Humans,Magnetoencephalography,Oscillometry,Space Perception,Speech}, 
title = {{The cognitive correlates of human brain oscillations}}, 
author = {Kahana, Michael J.}, 
journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience}, 
issn = {1529-2401}, 
doi = {10.1523/jneurosci.3737-05c.2006}, 
pmid = {16467513}, 
pmcid = {PMC6793637}, 
pages = {1669--1672}, 
number = {6}, 
volume = {26}, 
language = {eng}
}
@book{Gerstner.2002, 
year = {2002}, 
title = {{Spiking neuron models: single neurons, populations, plasticity}}, 
author = {Gerstner, Wulfram and Kistler, Werner M}, 
isbn = {978-0-511-81570-6}, 
url = {https://www.cambridge.org/core/product/identifier/9780511815706/type/book}, 
publisher = {Cambridge University Press}, 
keywords = {}, 
doi = {10.1017/cbo9780511815706}
}
@article{friston2000transients, 
year = {2000}, 
title = {{The labile brain. II. Transients, complexity and selection.}}, 
author = {Friston, K J}, 
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences}, 
issn = {0962-8436}, 
doi = {10.1098/rstb.2000.0561}, 
pmid = {10724458}, 
pmcid = {PMC1692732}, 
url = {http://dx.doi.org/10.1098/rstb.2000.0561}, 
abstract = {{The successive expression of neuronal transients is related to dynamic correlations and, as shown in this paper, to dynamic instability. Dynamic instability is a form of complexity, typical of neuronal systems, which may be crucial for adaptive brain function from two perspectives. The first is from the point of view of neuronal selection and self-organizing systems: if selective mechanisms underpin the emergence of adaptive neuronal responses then dynamic instability is, itself, necessarily adaptive. This is because dynamic instability is the source of diversity on which selection acts and is therefore subject to selective pressure. In short, the emergence of order, through selection, depends almost paradoxically on the instabilities that characterize the diversity of brain dynamics. The second perspective is provided by information theory.}}, 
pages = {237--252}, 
number = {1394}, 
volume = {355}, 
keywords = {}
}
@article{fingelkurts2006timing, 
year = {2006}, 
title = {{Timing in cognition and EEG brain dynamics: discreteness versus continuity.}}, 
author = {Fingelkurts, Andrew A and Fingelkurts, Alexander A}, 
journal = {Cognitive Processing}, 
issn = {1612-4782}, 
doi = {10.1007/s10339-006-0035-0}, 
pmid = {16832687}, 
url = {http://dx.doi.org/10.1007/s10339-006-0035-0}, 
abstract = {{This article provides an overview of recent developments in solving the timing problem (discreteness vs. continuity) in cognitive neuroscience. Both theoretical and empirical studies have been considered, with an emphasis on the framework of operational architectonics (OA) of brain functioning (Fingelkurts and Fingelkurts in Brain Mind 2:291-29, 2001; Neurosci Biobehav Rev 28:827-836, 2005). This framework explores the temporal structure of information flow and interarea interactions within the network of functional neuronal populations by examining topographic sharp transition processes in the scalp EEG, on the millisecond scale. We conclude, based on the OA framework, that brain functioning is best conceptualized in terms of continuity-discreteness unity which is also the characteristic property of cognition. At the end we emphasize where one might productively proceed for the future research.}}, 
pages = {135--162}, 
number = {3}, 
volume = {7}, 
keywords = {}
}
@article{deco2016metastability, 
year = {2016}, 
keywords = {Communication through coherence,Metastability,Synchronisation,Whole-brain-modelling}, 
title = {{Metastability and Coherence: Extending the Communication through Coherence Hypothesis Using A Whole-Brain Computational Perspective}}, 
author = {Deco, Gustavo and Kringelbach, Morten L.}, 
journal = {Trends in Neurosciences}, 
doi = {10.1016/j.tins.2016.01.001}, 
pmid = {26833259}, 
url = {http://dx.doi.org/10.1016/j.tins.2016.01.001}, 
abstract = {{Understanding the mechanisms for communication in the brain remains one of the most challenging scientific questions. The communication through coherence (CTC) hypothesis was originally proposed 10 years ago, stating that two groups of neurons communicate most effectively when their excitability fluctuations are coordinated in time (i.e., coherent), and this control by cortical coherence is a fundamental brain mechanism for large-scale, distant communication. In light of new evidence from whole-brain computational modelling of multimodal neuroimaging data, we link CTC to the concept of metastability, which refers to a rich exploration of the functional repertoire made possible by the underlying structural whole-brain connectivity.}}, 
pages = {125--135}, 
number = {3}, 
volume = {39}
}
@article{hudson2017metastability, 
year = {2017}, 
keywords = {Attractor dynamics,Attractor networks,Isoflurane,Metastability,Rats,Sprague-Dawley}, 
title = {{Metastability of neuronal dynamics during general anesthesia: Time for a change in our assumptions?}}, 
author = {Hudson, Andrew E.}, 
journal = {Frontiers in Neural Circuits}, 
doi = {10.3389/fncir.2017.00058}, 
pmid = {28890688}, 
pmcid = {PMC5574877}, 
url = {http://dx.doi.org/10.3389/fncir.2017.00058}, 
abstract = {{There is strong evidence that anesthetics have stereotypical effects on brain state, so that a given anesthetic appears to have a signature in the electroencephalogram (EEG), which may vary with dose. This can be usefully interpreted as the anesthetic determining an attractor in the phase space of the brain. How brain activity shifts between these attractors in time remains understudied, as most studies implicitly assume a one-to-one relationship between drug dose and attractor features by assuming stationarity over the analysis interval and analyzing data segments of several minutes in length. Yet data in rats anesthetized with isoflurane suggests that, at anesthetic levels consistent with surgical anesthesia, brain activity alternates between multiple attractors, often spending on the order of 10 min in one activity pattern before shifting to another. Moreover, the probability of these jumps between attractors changes with anesthetic concentration. This suggests the hypothesis that brain state is metastable during anesthesia: though it appears at equilibrium on short timescales (on the order of seconds to a few minutes), longer intervals show shifting behavior. Compelling evidence for metastability in rats anesthetized with isoflurane is reviewed, but so far only suggestive hints of metastability in brain states exist with other anesthetics or in other species. Explicit testing of metastability during anesthesia will require experiments with longer acquisition intervals and carefully designed analytic approaches; some of the implications of these constraints are reviewed for typical spectral analysis approaches. If metastability exists during anesthesia, it implies degeneracy in the relationship between brain state and effect site concentration, as there is not a one-to-one mapping between the two. This degeneracy could explain some of the reported difficulty in using brain activity monitors to titrate drug dose to prevent awareness during anesthesia and should force a rethinking of the notion of depth of anesthesia as a single dimension. Finally, explicit incorporation of knowledge of the dynamics of the brain during anesthesia could offer better depth of anesthesia monitoring.}}, 
pages = {58}, 
volume = {11}
}
@article{werner2007metastability, 
year = {2007}, 
keywords = {Coordination dynamics,Dynamic core hypothesis,Global workspace,Metastability,Nonlinear dynamics,Phase transitions,Self-organized criticality}, 
title = {{Metastability, criticality and phase transitions in brain and its models}}, 
author = {Werner, Gerhard}, 
journal = {BioSystems}, 
doi = {10.1016/j.biosystems.2006.12.001}, 
pmid = {17316974}, 
url = {http://dx.doi.org/10.1016/j.biosystems.2006.12.001}, 
abstract = {{This survey of experimental findings and theoretical insights of the past 25 years places the brain firmly into the conceptual framework of nonlinear dynamics, operating at the brink of criticality, which is achieved and maintained by self-organization. It is here the basis for proposing that the application of the twin concepts of scaling and universality of the theory of non-equilibrium phase transitions can serve as an informative approach for elucidating the nature of underlying neural-mechanisms, with emphasis on the dynamics of recursively reentrant activity flow in intracortical and cortico-subcortical neuronal loops. © 2006 Elsevier Ireland Ltd. All rights reserved.}}, 
pages = {496--508}, 
number = {2}, 
volume = {90}
}
@article{Friston.2000, 
year = {2000}, 
title = {{The labile brain. I. Neuronal transients and nonlinear coupling.}}, 
author = {Friston, K J}, 
journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences}, 
issn = {0962-8436}, 
doi = {10.1098/rstb.2000.0560}, 
pmid = {10724457}, 
pmcid = {PMC1692735}, 
url = {http://dx.doi.org/10.1098/rstb.2000.0560}, 
abstract = {{In this, the first of three papers, the nature of, and motivation for, neuronal transients is described in relation to characterizing brain dynamics. This paper deals with some basic aspects of neuronal dynamics, interactions, coupling and implicit neuronal codes. The second paper develops neuronal transients and nonlinear coupling in the context of dynamic instability and complexity, and suggests that instability or lability is necessary for adaptive self-organization. The final paper addresses the role of neuronal transients through information theory and the emergence of spatio-temporal receptive fields and functional specialization. By considering the brain as an ensemble of connected dynamic systems one can show that a sufficient description of neuronal dynamics comprises neuronal activity at a particular time and its recent history This history constitutes a neuronal transient. As such, transients represent a fundamental metric of neuronal interactions and, implicitly, a code employed in the functional integration of brain systems. The nature of transients, expressed conjointly in distinct neuronal populations, reflects the underlying coupling among populations. This coupling may be synchronous (and possibly oscillatory) or asynchronous. A critical distinction between synchronous and asynchronous coupling is that the former is essentially linear and the latter is nonlinear. The nonlinear nature of asynchronous coupling enables the rich, context-sensitive interactions that characterize real brain dynamics, suggesting that it plays a role in functional integration that may be as important as synchronous interactions. The distinction between linear and nonlinear coupling has fundamental implications for the analysis and characterization of neuronal interactions, most of which are predicated on linear (synchronous) coupling (e.g. cross-correlograms and coherence). Using neuromagnetic data it is shown that nonlinear (asynchronous) coupling is, in fact, more abundant and can be more significant than synchronous coupling.}}, 
pages = {215--236}, 
number = {1394}, 
volume = {355}, 
keywords = {}
}
@article{jirsa1994theoretical, 
year = {1994}, 
title = {{A theoretical model of phase transitions in the human brain.}}, 
author = {Jirsa, V K and Friedrich, R and Haken, H and Kelso, J A}, 
journal = {Biological Cybernetics}, 
issn = {0340-1200}, 
doi = {10.1007/bf00198909}, 
pmid = {8054384}, 
url = {http://dx.doi.org/10.1007/\%7BBF00198909\%7D}, 
abstract = {{An experiment using a multisensor SQUID (superconducting quantum interference device) array was performed by Kelso and colleagues (1992) which combined information from three different sources: perception, motor response, and brain signals. When an acoustic stimulus frequency is changed systematically, a spontaneous transition in coordination occurs at a critical frequency in both motor behavior and brain signals. Qualitatively analogous transitions are known for physical and biological systems such as changes in the coordination of human hand movements (Kelso 1981, 1984). In this paper we develop a theoretical model based on methods from the interdisciplinary field of synergetics (Haken 1983, 1987) and nonlinear oscillator theory that reproduces the main experimental features very well and suggests a formulation of a fundamental biophysical coupling.}}, 
pages = {27--35}, 
number = {1}, 
volume = {71}, 
keywords = {}
}
@article{aguilera2016extended, 
year = {2016}, 
keywords = {Criticality,Embodied cognition,Evolutionary robotics,Metastability,Neural assemblies,Sensorimotor coupling,Synaptic plasticity}, 
title = {{Extended neural metastability in an embodied model of sensorimotor coupling}}, 
author = {Aguilera, Miguel and Bedia, Manuel G. and Barandiaran, Xabier E.}, 
journal = {Frontiers in Systems Neuroscience}, 
doi = {10.3389/fnsys.2016.00076}, 
pmid = {27721746}, 
pmcid = {PMC5033977}, 
url = {http://dx.doi.org/10.3389/fnsys.2016.00076}, 
abstract = {{The hypothesis that brain organization is based on mechanisms of metastable synchronization in neural assemblies has been popularized during the last decades of neuroscientific research. Nevertheless, the role of body and environment for understanding the functioning of metastable assemblies is frequently dismissed. The main goal of this paper is to investigate the contribution of sensorimotor coupling to neural and behavioral metastability using a minimal computational model of plastic neural ensembles embedded in a robotic agent in a behavioral preference task. Our hypothesis is that, under some conditions, the metastability of the system is not restricted to the brain but extends to the system composed by the interaction of brain, body and environment. We test this idea, comparing an agent in continuous interaction with its environment in a task demanding behavioral flexibility with an equivalent model from the point of view of “internalist neuroscience.” A statistical characterization of our model and tools from information theory allow us to show how (1) the bidirectional coupling between agent and environment brings the system closer to a regime of criticality and triggers the emergence of additional metastable states which are not found in the brain in isolation but extended to the whole system of sensorimotor interaction, (2) the synaptic plasticity of the agent is fundamental to sustain open structures in the neural controller of the agent flexibly engaging and disengaging different behavioral patterns that sustain sensorimotor metastable states, and (3) these extended metastable states emerge when the agent generates an asymmetrical circular loop of causal interaction with its environment, in which the agent responds to variability of the environment at fast timescales while acting over the environment at slow timescales, suggesting the constitution of the agent as an autonomous entity actively modulating its sensorimotor coupling with the world. We conclude with a reflection about how our results contribute in a more general way to current progress in neuroscientific research.}}, 
pages = {76}, 
number = {SEP}, 
volume = {10}
}
@article{fries2015rhythms, 
year = {2015}, 
keywords = {Phase synchronization}, 
title = {{Rhythms for Cognition: Communication through Coherence.}}, 
author = {Fries, Pascal}, 
journal = {Neuron}, 
doi = {10.1016/j.neuron.2015.09.034}, 
pmid = {26447583}, 
pmcid = {PMC4605134}, 
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315008235}, 
abstract = {{I propose that synchronization affects communication between neuronal groups. Gamma-band (30-90 Hz) synchronization modulates excitation rapidly enough that it escapes the following inhibition and activates postsynaptic neurons effectively. Synchronization also ensures that a presynaptic activation pattern arrives at postsynaptic neurons in a temporally coordinated manner. At a postsynaptic neuron, multiple presynaptic groups converge, e.g., representing different stimuli. If a stimulus is selected by attention, its neuronal representation shows stronger and higher-frequency gamma-band synchronization. Thereby, the attended stimulus representation selectively entrains postsynaptic neurons. The entrainment creates sequences of short excitation and longer inhibition that are coordinated between pre- and postsynaptic groups to transmit the attended representation and shut out competing inputs. The predominantly bottom-up-directed gamma-band influences are controlled by predominantly top-down-directed alpha-beta-band (8-20 Hz) influences. Attention itself samples stimuli at a 7-8 Hz theta rhythm. Thus, several rhythms and their interplay render neuronal communication effective, precise, and selective. Copyright ̧opyright 2015 Elsevier Inc. All rights reserved.}}, 
pages = {220--235}, 
number = {1}, 
volume = {88}
}
@article{swadlow2001impact, 
year = {2001}, 
title = {{The impact of 'bursting' thalamic impulses at a neocortical synapse.}}, 
author = {Swadlow, H A and Gusev, A G}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/86054}, 
pmid = {11276231}, 
url = {http://dx.doi.org/10.1038/86054}, 
abstract = {{Considerable effort has gone into understanding the mechanisms underlying high-frequency 'bursting' of thalamocortical impulses, their sensory information content and their involvement in perception. However, little is known about the influence of such impulses on their cortical targets. Here we follow bursting thalamic impulses to their terminus at the thalamocortical synapse of the awake rabbit, and examine their influence on a class of somatosensory cortical neurons. We show that thalamic bursts potently activate cortical circuits. Initial impulses of each burst have a greatly enhanced ability to elicit cortical action potentials, and later impulses in the burst further raise the probability of eliciting spikes. In some cases, multiple cortical spikes result from a single burst. Moreover, we show that the interval preceding each burst is crucial for generating the enhanced cortical response. The powerful activation of neocortex by thalamocortical bursts is fully consistent with an involvement of these impulses in perceptual/attentional processes.}}, 
pages = {402--408}, 
number = {4}, 
volume = {4}, 
keywords = {}
}
@article{bressler2016coordination, 
year = {2016}, 
title = {{Coordination dynamics in cognitive neuroscience.}}, 
author = {Bressler, Steven L and Kelso, J A Scott}, 
journal = {Frontiers in Neuroscience}, 
issn = {1662-4548}, 
doi = {10.3389/fnins.2016.00397}, 
pmid = {27695395}, 
pmcid = {PMC5023665}, 
url = {http://dx.doi.org/10.3389/fnins.2016.00397}, 
abstract = {{Many researchers and clinicians in cognitive neuroscience hold to a modular view of cognitive function in which the cerebral cortex operates by the activation of areas with circumscribed elementary cognitive functions. Yet an ongoing paradigm shift to a dynamic network perspective is underway. This new viewpoint treats cortical function as arising from the coordination dynamics within and between cortical regions. Cortical coordination dynamics arises due to the unidirectional influences imposed on a cortical area by inputs from other areas that project to it, combined with the projection reciprocity that characterizes cortical connectivity and gives rise to reentrant processing. As a result, cortical dynamics exhibits both segregative and integrative tendencies and gives rise to both cooperative and competitive relations within and between cortical areas that are hypothesized to underlie the emergence of cognition in brains.}}, 
pages = {397}, 
volume = {10}, 
keywords = {}
}
@article{Fries.2005, 
year = {2005}, 
title = {{A mechanism for cognitive dynamics: neuronal communication through neuronal coherence.}}, 
author = {Fries, Pascal}, 
journal = {Trends in Cognitive Sciences}, 
issn = {1364-6613}, 
doi = {10.1016/j.tics.2005.08.011}, 
pmid = {16150631}, 
url = {http://dx.doi.org/10.1016/j.tics.2005.08.011}, 
abstract = {{At any one moment, many neuronal groups in our brain are active. Microelectrode recordings have characterized the activation of single neurons and fMRI has unveiled brain-wide activation patterns. Now it is time to understand how the many active neuronal groups interact with each other and how their communication is flexibly modulated to bring about our cognitive dynamics. I hypothesize that neuronal communication is mechanistically subserved by neuronal coherence. Activated neuronal groups oscillate and thereby undergo rhythmic excitability fluctuations that produce temporal windows for communication. Only coherently oscillating neuronal groups can interact effectively, because their communication windows for input and for output are open at the same times. Thus, a flexible pattern of coherence defines a flexible communication structure, which subserves our cognitive flexibility.}}, 
pages = {474--480}, 
number = {10}, 
volume = {9}, 
keywords = {}
}
@incollection{fox2015bursting, 
year = {2015}, 
title = {{Bursting in neurons and small networks}}, 
author = {Fox, David M and Rotstein, Horacio G and Nadim, Farzan}, 
editor = {["Jaeger and \{Jung, Dieter and\} and Ranu"]}, 
booktitle = {Encyclopedia of computational neuroscience}, 
isbn = {978-1-4614-6674-1}, 
url = {http://link.springer.com/10.1007/978-1-4614-6675-8\_454}, 
pages = {455--469}, 
publisher = {Springer New York}, 
address = {New York, NY}, 
keywords = {}, 
doi = {10.1007/978-1-4614-6675-8\_454}
}
@article{lacamera2019cortical, 
year = {2019}, 
rating = {5}, 
title = {{Cortical computations via metastable activity}}, 
author = {Camera, Giancarlo La and Fontanini, Alfredo and Mazzucato, Luca}, 
journal = {Current Opinion in Neurobiology}, 
doi = {10.1016/j.conb.2019.06.007}, 
pmid = {31326722}, 
url = {http://dx.doi.org/10.1016/j.conb.2019.06.007}, 
abstract = {{Metastable brain dynamics are characterized by abrupt, jump-like modulations so that the neural activity in single trials appears to unfold as a sequence of discrete, quasi-stationary ‘states'. Evidence that cortical neural activity unfolds as a sequence of metastable states is accumulating at fast pace. Metastable activity occurs both in response to an external stimulus and during ongoing, self-generated activity. These spontaneous metastable states are increasingly found to subserve internal representations that are not locked to external triggers, including states of deliberations, attention and expectation. Moreover, decoding stimuli or decisions via metastable states can be carried out trial-by-trial. Focusing on metastability will allow us to shift our perspective on neural coding from traditional concepts based on trial-averaging to models based on dynamic ensemble representations. Recent theoretical work has started to characterize the mechanistic origin and potential roles of metastable representations. In this article we review recent findings on metastable activity, how it may arise in biologically realistic models, and its potential role for representing internal states as well as relevant task variables.}}, 
pages = {37--45}, 
volume = {58}, 
note = {\_eprint: 1906.07777}, 
keywords = {}
}
@article{bezanson2017julia, 
year = {2017}, 
title = {{Julia: A fresh approach to numerical computing}}, 
author = {Bezanson, Jeff and Edelman, Alan and Karpinski, Stefan and Shah, Viral B}, 
journal = {SIAM Review}, 
issn = {0036-1445}, 
doi = {10.1137/141000671}, 
url = {http://epubs.siam.org/doi/10.1137/141000671}, 
abstract = {{The Julia programming language is gaining enormous popularity. Julia was designed to be easy and fast. Most importantly, Julia shatters deeply established notions widely held in the applied community: 1. High-level, dynamic code has to be slow by some sort of law of nature 2. It is sensible to prototype in one language and then recode in another language 3. There are parts of a system for the programmer, and other parts best left untouched as they are built by the experts. Julia began with a deep understanding of the needs of the scientic programmer and the needs of the computer in mind. Bridging cultures that have often been distant, Julia combines expertise from computer science and computational science creating a new approach to scientic computing. This note introduces the programmer to the language and the underlying design theory. It invites the reader to rethink the fundamental foundations of numerical computing systems. In particular, there is the fascinating dance between specialization and abstraction. Specialization allows for custom treatment. We can pick just the right algorithm for the right circumstance and this can happen at runtime based on argument types (code selection via multiple dispatch). Abstraction recognizes what remains the same after dierences are stripped away and ignored as irrelevant. The recognition of abstraction allows for code reuse (generic programming). A simple idea that yields incredible power. The Julia design facilitates this interplay in many explicit and subtle ways for machine performance and, most importantly, human convenience.}}, 
pages = {65--98}, 
number = {1}, 
volume = {59}, 
keywords = {}
}
@article{cavanna2018dynamic, 
year = {2018}, 
keywords = {Brain dynamics,Consciousness,Dynamic core,fMRI,Metastability,Neuroimaging}, 
title = {{Dynamic functional connectivity and brain metastability during altered states of consciousness}}, 
author = {Cavanna, Federico and Vilas, Martina G. and Palmucci, Matías and Tagliazucchi, Enzo}, 
journal = {NeuroImage}, 
doi = {10.1016/j.neuroimage.2017.09.065}, 
pmid = {28986208}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2017.09.065}, 
abstract = {{The scientific study of human consciousness has greatly benefited from the development of non-invasive brain imaging methods. The quest to identify the neural correlates of consciousness combined psychophysical experimentation with neuroimaging tools such as functional magnetic resonance imaging (fMRI) to map the changes in neural activity associated with conscious vs. unconscious percepts. Different neuroimaging methods have also been applied to characterize spontaneous brain activity fluctuations during altered states of consciousness, and to develop quantitative metrics for the level of consciousness. Most of these studies, however, have not explored the dynamic nature of the whole-brain imaging data provided by fMRI. A series of empirical and computational studies strongly suggests that the temporal fluctuations observed in this data present a non-trivial structure, and that this structure is compatible with the exploration of a discrete repertoire of states. In this review we focus on how dynamic neuroimaging can be used to address theoretical accounts of consciousness based on the hypothesis of a dynamic core, i.e. a constantly evolving and transiently stable set of coordinated neurons that constitute an integrated and differentiated physical substrate for each conscious experience. We review work exploring the possibility that metastability in brain dynamics leads to a repertoire of dynamic core states, and discuss how it might be modified during altered states of consciousness. This discussion prompts us to review neuroimaging studies aimed to map the dynamic exploration of the repertoire of states as a function of consciousness. Complementary studies of the dynamic core hypothesis using perturbative methods are also discussed. Finally, we propose that a link between metastability in brain dynamics and the level of consciousness could pave the way towards a mechanistic understanding of altered states of consciousness using tools from dynamical systems theory and statistical physics.}}, 
pages = {383--395}, 
number = {Pt B}, 
volume = {180}
}
@article{mazzucato2015dynamics, 
year = {2015}, 
keywords = {Gustatory cortex,Hidden markov models,Network dynamics,Ongoing activity,Spiking network models}, 
title = {{Dynamics of multistable states during ongoing and evoked cortical activity}}, 
author = {Mazzucato, Luca and Fontanini, Alfredo and Camera, Giancarlo La}, 
journal = {Journal of Neuroscience}, 
doi = {10.1523/jneurosci.4819-14.2015}, 
pmid = {26019337}, 
pmcid = {PMC4444543}, 
eprint = {1508.00165}, 
url = {http://dx.doi.org/10.1523/\%7BJNEUROSCI\%7D.4819-14.2015}, 
abstract = {{Single-trial analyses of ensemble activity in alert animals demonstrate that cortical circuits dynamics evolve through temporal sequences of metastable states. Metastability has been studied for its potential role in sensory coding, memory, and decision-making. Yet, very little is known about the network mechanisms responsible for its genesis. It is often assumed that the onset of state sequences is triggered by an external stimulus. Here we show that state sequences can be observed also in the absence of overt sensory stimulation. Analysis of multielectrode recordings from the gustatory cortex of alert rats revealed ongoing sequences of states, where single neurons spontaneously attain several firing rates across different states. This single-neuron multistability represents a challenge to existing spiking network models, where typically each neuron is at most bistable. We present a recurrent spiking network model that accounts for both the spontaneous generation of state sequences and the multistability in single-neuron firing rates. Each state results from the activation of neural clusters with potentiated intracluster connections, with the firing rate in each cluster depending on the number of active clusters. Simulations show that the model's ensemble activity hops among the different states, reproducing the ongoing dynamics observed in the data. When probed with external stimuli, the model predicts the quenching of single-neuron multistability into bistability and the reduction of trial-by-trial variability. Both predictions were confirmed in the data. Together, these results provide a theoretical framework that captures both ongoing and evoked network dynamics in a single mechanistic model.}}, 
pages = {8214--8231}, 
number = {21}, 
volume = {35}, 
note = {\_eprint: 1508.00165}
}
@article{hammer1994experimental, 
year = {1994}, 
title = {{Experimental observation of on-off intermittency.}}, 
author = {Hammer, P W and Platt, N and Hammel, S M and Heagy, J F and Lee, B D}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.73.1095}, 
pmid = {10057623}, 
url = {http://dx.doi.org/10.1103/\%7BPhysRevLett\%7D.73.1095}, 
abstract = {{We observe on-off intermittency in a nonlinear electronic circuit tuned near a Hopf bifurcation point. The circuit is driven randomly through the bifurcation point, resulting in intermittent switching between a fixed point (laminar phase) and a limit cycle. The distribution of lengths of laminar phases exhibits -3/2 power law scaling for shorter phases, and an exponential drop for longer phases, due to noise in the system. These results agree with a theoretically predicted distribution. In addition, the crossover from power law to exponential decay obeys the predicted scaling law.}}, 
pages = {1095--1098}, 
number = {8}, 
volume = {73}, 
keywords = {}
}
@article{Hansen.2015, 
year = {2015}, 
title = {{Functional connectivity dynamics: modeling the switching behavior of the resting state.}}, 
author = {Hansen, Enrique C A and Battaglia, Demian and Spiegler, Andreas and Deco, Gustavo and Jirsa, Viktor K}, 
journal = {Neuroimage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2014.11.001}, 
pmid = {25462790}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2014.11.001}, 
abstract = {{Functional connectivity (FC) sheds light on the interactions between different brain regions. Besides basic research, it is clinically relevant for applications in Alzheimer's disease, schizophrenia, presurgical planning, epilepsy, and traumatic brain injury. Simulations of whole-brain mean-field computational models with realistic connectivity determined by tractography studies enable us to reproduce with accuracy aspects of average FC in the resting state. Most computational studies, however, did not address the prominent non-stationarity in resting state FC, which may result in large intra- and inter-subject variability and thus preclude an accurate individual predictability. Here we show that this non-stationarity reveals a rich structure, characterized by rapid transitions switching between a few discrete FC states. We also show that computational models optimized to fit time-averaged FC do not reproduce these spontaneous state transitions and, thus, are not qualitatively superior to simplified linear stochastic models, which account for the effects of structure alone. We then demonstrate that a slight enhancement of the non-linearity of the network nodes is sufficient to broaden the repertoire of possible network behaviors, leading to modes of fluctuations, reminiscent of some of the most frequently observed Resting State Networks. Because of the noise-driven exploration of this repertoire, the dynamics of FC qualitatively change now and display non-stationary switching similar to empirical resting state recordings (Functional Connectivity Dynamics (FCD)). Thus FCD bear promise to serve as a better biomarker of resting state neural activity and of its pathologic alterations. Copyright ̧opyright 2014 The Authors. Published by Elsevier Inc. All rights reserved.}}, 
pages = {525--535}, 
volume = {105}, 
keywords = {}
}
@article{lee2017linking, 
year = {2017}, 
title = {{Linking functional connectivity and dynamic properties of resting-state networks}}, 
author = {Lee, Won Hee and Frangou, Sophia}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-017-16789-1}, 
pmid = {29192157}, 
pmcid = {PMC5709368}, 
url = {http://dx.doi.org/10.1038/s41598-017-16789-1}, 
abstract = {{Spontaneous brain activity is organized into resting-state networks (RSNs) involved in internally-guided, higher-order mental functions (default mode, central executive and salience networks) and externally-driven, specialized sensory and motor processing (auditory, visual and sensorimotor networks). RSNs are characterized by their functional connectivity in terms of within-network cohesion and between-network integration, and by their dynamic properties in terms of synchrony and metastability. We examined the relationship between functional connectivity and dynamic network features using fMRI data and an anatomically constrained Kuramoto model. Extrapolating from simulated data, synchrony and metastability across the RSNs emerged at coupling strengths of 5 ≤ k ≤ 12. In the empirical RSNs, higher metastability and synchrony were respectively associated with greater cohesion and lower integration. Consistent with their dual role in supporting both sustained and diverse mental operations, higher-order RSNs had lower metastability and synchrony. Sensory and motor RSNs showed greater cohesion and metastability, likely to respectively reflect their functional specialization and their greater capacity for altering network states in response to multiple and diverse external demands. Our findings suggest that functional and dynamic RSN properties are closely linked and expand our understanding of the neural architectures that support optimal brain function.}}, 
pages = {16610}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{bhowmik2013metastability, 
year = {2013}, 
title = {{Metastability and Inter-Band Frequency Modulation in Networks of Oscillating Spiking Neuron Populations}}, 
author = {Bhowmik, David and Shanahan, Murray}, 
journal = {PLoS ONE}, 
doi = {10.1371/journal.pone.0062234}, 
pmid = {23614040}, 
pmcid = {PMC3628585}, 
url = {http://dx.doi.org/10.1371/journal.pone.0062234}, 
abstract = {{Groups of neurons firing synchronously are hypothesized to underlie many cognitive functions such as attention, associative learning, memory, and sensory selection. Recent theories suggest that transient periods of synchronization and desynchronization provide a mechanism for dynamically integrating and forming coalitions of functionally related neural areas, and that at these times conditions are optimal for information transfer. Oscillating neural populations display a great amount of spectral complexity, with several rhythms temporally coexisting in different structures and interacting with each other. This paper explores inter-band frequency modulation between neural oscillators using models of quadratic integrate-and-fire neurons and Hodgkin-Huxley neurons. We vary the structural connectivity in a network of neural oscillators, assess the spectral complexity, and correlate the inter-band frequency modulation. We contrast this correlation against measures of metastable coalition entropy and synchrony. Our results show that oscillations in different neural populations modulate each other so as to change frequency, and that the interaction of these fluctuating frequencies in the network as a whole is able to drive different neural populations towards episodes of synchrony. Further to this, we locate an area in the connectivity space in which the system directs itself in this way so as to explore a large repertoire of synchronous coalitions. We suggest that such dynamics facilitate versatile exploration, integration, and communication between functionally related neural areas, and thereby supports sophisticated cognitive processing in the brain. © 2013 Bhowmik, Shanahan.}}, 
pages = {e62234}, 
number = {4}, 
volume = {8}, 
keywords = {}
}
@article{graben2019metastable, 
year = {2019}, 
keywords = {BOLD fMRI,brain hierarchical atlas,diffusion tensor imaging,metastability,recurrence structure analysis,resting state}, 
title = {{Metastable Resting State Brain Dynamics}}, 
author = {Graben, Peter beim and Jimenez-Marin, Antonio and Diez, Ibai and Cortes, Jesus M. and Desroches, Mathieu and Rodrigues, Serafim}, 
journal = {Frontiers in Computational Neuroscience}, 
doi = {10.3389/fncom.2019.00062}, 
pmid = {31551744}, 
pmcid = {PMC6743347}, 
url = {http://dx.doi.org/10.3389/fncom.2019.00062}, 
abstract = {{Metastability refers to the fact that the state of a dynamical system spends a large amount of time in a restricted region of its available phase space before a transition takes place, bringing the system into another state from where it might recur into the previous one. beim Graben and Hutt (2013) suggested to use the recurrence plot (RP) technique introduced by Eckmann et al. (1987) for the segmentation of system's trajectories into metastable states using recurrence grammars. Here, we apply this recurrence structure analysis (RSA) for the first time to resting-state brain dynamics obtained from functional magnetic resonance imaging (fMRI). Brain regions are defined according to the brain hierarchical atlas (BHA) developed by Diez et al. (2015), and as a consequence, regions present high-connectivity in both structure (obtained from diffusion tensor imaging) and function (from the blood-level dependent-oxygenation—BOLD—signal). Remarkably, regions observed by Diez et al. were completely time-invariant. Here, in order to compare this static picture with the metastable systems dynamics obtained from the RSA segmentation, we determine the number of metastable states as a measure of complexity for all subjects and for region numbers varying from 3 to 100. We find RSA convergence toward an optimal segmentation of 40 metastable states for normalized BOLD signals, averaged over BHA modules. Next, we build a bistable dynamics at population level by pooling 30 subjects after Hausdorff clustering. In link with this finding, we reflect on the different modeling frameworks that can allow for such scenarios: heteroclinic dynamics, dynamics with riddled basins of attraction, multiple-timescale dynamics. Finally, we characterize the metastable states both functionally and structurally, using templates for resting state networks (RSNs) and the automated anatomical labeling (AAL) atlas, respectively.}}, 
pages = {62}, 
volume = {13}
}
@article{kelso2012multistability, 
year = {2012}, 
keywords = {Complementarity,Coordination dynamics,Instability,Metastability,Multistability,Transitions}, 
title = {{Multistability and metastability: Understanding dynamic coordination in the brain}}, 
author = {Kelso, J. A. Scott}, 
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences}, 
doi = {10.1098/rstb.2011.0351}, 
pmid = {22371613}, 
pmcid = {PMC3282307}, 
url = {http://dx.doi.org/10.1098/rstb.2011.0351}, 
abstract = {{Multistable coordination dynamics exists at many levels, from multifunctional neural circuits in vertebrates and invertebrates to large-scale neural circuitry in humans. Moreover, multistability spans (at least) the domains of action and perception, and has been found to place constraints upon, even dictating the nature of, intentional change and the skill-learning process. This paper reviews some of the key evidence for multistability in the aforementioned areas, and illustrates how it has been measured, modelled and theoretically understood. It then suggests how multistability- when combined with essential aspects of coordination dynamics such as instability, transitions and (especially) metastability-provides a platform for understanding coupling and the creative dynamics of complex goal-directed systems, including the brain and the brain-behaviour relation. © 2012 The Royal Society.}}, 
pages = {906--918}, 
number = {1591}, 
volume = {367}
}
@article{friston1997transients, 
year = {1997}, 
title = {{Transients, metastability, and neuronal dynamics}}, 
author = {Friston, Karl J.}, 
journal = {NeuroImage}, 
doi = {10.1006/nimg.1997.0259}, 
pmid = {9345546}, 
url = {http://dx.doi.org/10.1006/nimg.1997.0259}, 
abstract = {{This paper is about neuronal dynamics and how their special complexity can be understood in terms of nonlinear dynamics. There are many aspects of neuronal interactions and connectivity that engender the complexity of brain dynamics. In this paper we consider (i) the nature of this complexity and (ii) how it depends on connections between neuronal systems (e.g., neuronal populations or cortical areas). The main conclusion is that simulated neural systems show complex behaviors, reminiscent of neuronal dynamics, when these extrinsic connections are sparse. The patterns of activity that obtain, under these conditions, show a rich form of intermittency with the recurrent and self-limiting expression of stereotyped transient-like dynamics. Despite the fact that these dynamics conform to a single (complex) attractor this metastability gives the illusion of a dynamically changing attractor manifold (i.e., a changing surface upon which the dynamics unfold). This metastability is characterized using a measure that is based on the entropy of the time series' spectral density.}}, 
pages = {164--171}, 
number = {2}, 
volume = {5}, 
keywords = {}
}
@article{roberts2019metastable, 
year = {2019}, 
rating = {5}, 
title = {{Metastable brain waves.}}, 
author = {Roberts, James A and Gollo, Leonardo L and Abeysuriya, Romesh G and Roberts, Gloria and Mitchell, Philip B and Woolrich, Mark W and Breakspear, Michael}, 
journal = {Nature Communications}, 
issn = {2041-1723}, 
doi = {10.1038/s41467-019-08999-0}, 
pmid = {30837462}, 
pmcid = {PMC6401142}, 
url = {http://www.nature.com/articles/s41467-019-08999-0}, 
abstract = {{Traveling patterns of neuronal activity-brain waves-have been observed across a breadth of neuronal recordings, states of awareness, and species, but their emergence in the human brain lacks a firm understanding. Here we analyze the complex nonlinear dynamics that emerge from modeling large-scale spontaneous neural activity on a whole-brain network derived from human tractography. We find a rich array of three-dimensional wave patterns, including traveling waves, spiral waves, sources, and sinks. These patterns are metastable, such that multiple spatiotemporal wave patterns are visited in sequence. Transitions between states correspond to reconfigurations of underlying phase flows, characterized by nonlinear instabilities. These metastable dynamics accord with empirical data from multiple imaging modalities, including electrical waves in cortical tissue, sequential spatiotemporal patterns in resting-state MEG data, and large-scale waves in human electrocorticography. By moving the study of functional networks from a spatially static to an inherently dynamic (wave-like) frame, our work unifies apparently diverse phenomena across functional neuroimaging modalities and makes specific predictions for further experimentation.}}, 
pages = {1056}, 
number = {1}, 
volume = {10}, 
keywords = {}
}
@article{hudson2014recovery, 
year = {2014}, 
title = {{Recovery of consciousness is mediated by a network of discrete metastable activity states.}}, 
author = {Hudson, Andrew E and Calderon, Diany Paola and Pfaff, Donald W and Proekt, Alex}, 
journal = {Proceedings of the National Academy of Sciences of the United States of America}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1408296111}, 
pmid = {24927558}, 
url = {http://dx.doi.org/10.1073/pnas.1408296111}, 
abstract = {{It is not clear how, after a large perturbation, the brain explores the vast space of potential neuronal activity states to recover those compatible with consciousness. Here, we analyze recovery from pharmacologically induced coma to show that neuronal activity en route to consciousness is confined to a low-dimensional subspace. In this subspace, neuronal activity forms discrete metastable states persistent on the scale of minutes. The network of transitions that links these metastable states is structured such that some states form hubs that connect groups of otherwise disconnected states. Although many paths through the network are possible, to ultimately enter the activity state compatible with consciousness, the brain must first pass through these hubs in an orderly fashion. This organization of metastable states, along with dramatic dimensionality reduction, significantly simplifies the task of sampling the parameter space to recover the state consistent with wakefulness on a physiologically relevant timescale.}}, 
pages = {9283--9288}, 
number = {25}, 
volume = {111}, 
keywords = {}
}
@article{cabral2011role, 
year = {2011}, 
title = {{Role of local network oscillations in resting-state functional connectivity.}}, 
author = {Cabral, Joana and Hugues, Etienne and Sporns, Olaf and Deco, Gustavo}, 
journal = {Neuroimage}, 
issn = {1053-8119}, 
doi = {10.1016/j.neuroimage.2011.04.010}, 
pmid = {21511044}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2011.04.010}, 
abstract = {{Spatio-temporally organized low-frequency fluctuations (<0.1 Hz), observed in BOLD fMRI signal during rest, suggest the existence of underlying network dynamics that emerge spontaneously from intrinsic brain processes. Furthermore, significant correlations between distinct anatomical regions-or functional connectivity (FC)-have led to the identification of several widely distributed resting-state networks (RSNs). This slow dynamics seems to be highly structured by anatomical connectivity but the mechanism behind it and its relationship with neural activity, particularly in the gamma frequency range, remains largely unknown. Indeed, direct measurements of neuronal activity have revealed similar large-scale correlations, particularly in slow power fluctuations of local field potential gamma frequency range oscillations. To address these questions, we investigated neural dynamics in a large-scale model of the human brain's neural activity. A key ingredient of the model was a structural brain network defined by empirically derived long-range brain connectivity together with the corresponding conduction delays. A neural population, assumed to spontaneously oscillate in the gamma frequency range, was placed at each network node. When these oscillatory units are integrated in the network, they behave as weakly coupled oscillators. The time-delayed interaction between nodes is described by the Kuramoto model of phase oscillators, a biologically-based model of coupled oscillatory systems. For a realistic setting of axonal conduction speed, we show that time-delayed network interaction leads to the emergence of slow neural activity fluctuations, whose patterns correlate significantly with the empirically measured FC. The best agreement of the simulated FC with the empirically measured FC is found for a set of parameters where subsets of nodes tend to synchronize although the network is not globally synchronized. Inside such clusters, the simulated BOLD signal between nodes is found to be correlated, instantiating the empirically observed RSNs. Between clusters, patterns of positive and negative correlations are observed, as described in experimental studies. These results are found to be robust with respect to a biologically plausible range of model parameters. In conclusion, our model suggests how resting-state neural activity can originate from the interplay between the local neural dynamics and the large-scale structure of the brain. Copyright ̧opyright 2011 Elsevier Inc. All rights reserved.}}, 
pages = {130--139}, 
number = {1}, 
volume = {57}, 
keywords = {}
}
@article{deco2017dynamics, 
year = {2017}, 
title = {{The dynamics of resting fluctuations in the brain: Metastability and its dynamical cortical core}}, 
author = {Deco, Gustavo and Kringelbach, Morten L. and Jirsa, Viktor K. and Ritter, Petra}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-017-03073-5}, 
pmid = {28596608}, 
pmcid = {PMC5465179}, 
url = {http://dx.doi.org/10.1038/s41598-017-03073-5}, 
abstract = {{In the human brain, spontaneous activity during resting state consists of rapid transitions between functional network states over time but the underlying mechanisms are not understood. We use connectome based computational brain network modeling to reveal fundamental principles of how the human brain generates large-scale activity observable by noninvasive neuroimaging. We used structural and functional neuroimaging data to construct whole-brain models. With this novel approach, we reveal that the human brain during resting state operates at maximum metastability, i.e. in a state of maximum network switching. In addition, we investigate cortical heterogeneity across areas. Optimization of the spectral characteristics of each local brain region revealed the dynamical cortical core of the human brain, which is driving the activity of the rest of the whole brain. Brain network modelling goes beyond correlational neuroimaging analysis and reveals non-trivial network mechanisms underlying non-invasive observations. Our novel findings significantly pertain to the important role of computational connectomics in understanding principles of brain function.}}, 
pages = {3095}, 
number = {1}, 
volume = {7}, 
keywords = {}
}
@article{mazzucato2019expectation, 
year = {2019}, 
title = {{Expectation-induced modulation of metastable activity underlies faster coding of sensory stimuli.}}, 
author = {Mazzucato, L and Camera, G La and Fontanini, A}, 
journal = {Nature Neuroscience}, 
issn = {1097-6256}, 
doi = {10.1038/s41593-019-0364-9}, 
pmid = {30936557}, 
pmcid = {PMC6516078}, 
url = {http://www.nature.com/articles/s41593-019-0364-9}, 
abstract = {{Sensory stimuli can be recognized more rapidly when they are expected. This phenomenon depends on expectation affecting the cortical processing of sensory information. However, the mechanisms responsible for the effects of expectation on sensory circuits remain elusive. In the present study, we report a novel computational mechanism underlying the expectation-dependent acceleration of coding observed in the gustatory cortex of alert rats. We use a recurrent spiking network model with a clustered architecture capturing essential features of cortical activity, such as its intrinsically generated metastable dynamics. Relying on network theory and computer simulations, we propose that expectation exerts its function by modulating the intrinsically generated dynamics preceding taste delivery. Our model's predictions were confirmed in the experimental data, demonstrating how the modulation of ongoing activity can shape sensory coding. Altogether, these results provide a biologically plausible theory of expectation and ascribe an alternative functional role to intrinsically generated, metastable activity.}}, 
pages = {787--796}, 
number = {5}, 
volume = {22}, 
keywords = {}
}
@article{rabinovich2012information, 
year = {2012}, 
title = {{Information flow dynamics in the brain.}}, 
author = {Rabinovich, Mikhail I and Afraimovich, Valentin S and Bick, Christian and Varona, Pablo}, 
journal = {Physics of life reviews}, 
issn = {1571-0645}, 
doi = {10.1016/j.plrev.2011.11.002}, 
pmid = {22119154}, 
url = {http://dx.doi.org/10.1016/j.plrev.2011.11.002}, 
abstract = {{Timing and dynamics of information in the brain is a hot field in modern neuroscience. The analysis of the temporal evolution of brain information is crucially important for the understanding of higher cognitive mechanisms in normal and pathological states. From the perspective of information dynamics, in this review we discuss working memory capacity, language dynamics, goal-dependent behavior programming and other functions of brain activity. In contrast with the classical description of information theory, which is mostly algebraic, brain flow information dynamics deals with problems such as the stability/instability of information flows, their quality, the timing of sequential processing, the top-down cognitive control of perceptual information, and information creation. In this framework, different types of information flow instabilities correspond to different cognitive disorders. On the other hand, the robustness of cognitive activity is related to the control of the information flow stability. We discuss these problems using both experimental and theoretical approaches, and we argue that brain activity is better understood considering information flows in the phase space of the corresponding dynamical model. In particular, we show how theory helps to understand intriguing experimental results in this matter, and how recent knowledge inspires new theoretical formalisms that can be tested with modern experimental techniques. Published by Elsevier B.V.}}, 
pages = {51--73}, 
number = {1}, 
volume = {9}, 
keywords = {}
}
@article{varela2001brainweb, 
year = {2001}, 
keywords = {Fundamental,Review,Synchronization}, 
title = {{The brainweb: phase synchronization and large-scale integration.}}, 
author = {Varela, F and Lachaux, J P and Rodriguez, E and Martinerie, J}, 
journal = {Nature Reviews. Neuroscience}, 
issn = {1471-003X}, 
doi = {10.1038/35067550}, 
pmid = {11283746}, 
url = {http://dx.doi.org/10.1038/35067550}, 
abstract = {{The emergence of a unified cognitive moment relies on the coordination of scattered mosaics of functionally specialized brain regions. Here we review the mechanisms of large-scale integration that counterbalance the distributed anatomical and functional organization of brain activity to enable the emergence of coherent behaviour and cognition. Although the mechanisms involved in large-scale integration are still largely unknown, we argue that the most plausible candidate is the formation of dynamic links mediated by synchrony over multiple frequency bands.}}, 
pages = {229--239}, 
number = {4}, 
volume = {2}
}
@article{tognoli2014metastable, 
year = {2014}, 
title = {{The Metastable Brain}}, 
author = {Tognoli, Emmanuelle and Kelso, J. A.Scott}, 
journal = {Neuron}, 
doi = {10.1016/j.neuron.2013.12.022}, 
pmid = {24411730}, 
url = {http://dx.doi.org/10.1016/j.neuron.2013.12.022}, 
abstract = {{Neural ensembles oscillate across a broad range of frequencies and are transiently coupled or "bound" together when people attend to a stimulus, perceive, think, and act. This is a dynamic, self-assembling process, with parts of the brain engaging and disengaging in time. But how is it done? The theory of Coordination Dynamics proposes a mechanism called metastability, a subtle blend of integration and segregation. Tendencies for brain regions to express their individual autonomy and specialized functions (segregation, modularity) coexist with tendencies to couple and coordinate globally for multiple functions (integration). Although metastability has garnered increasing attention, it has yet to be demonstrated and treated within a fully spatiotemporal perspective. Here, we illustrate metastability in continuous neural and behavioral recordings, and we discuss theory and experiments at multiple scales, suggesting that metastable dynamics underlie the real-time coordination necessary for the brain's dynamic cognitive, behavioral, and social functions. How does the transient coupling of neural ensembles that supports cognitive function occur? Tognoli and Kelso consider a mechanism known as metastability, discussing theory and data at multiple scales that suggest that metastable dynamics underlies the coordination necessary for the brain's dynamic functions. © 2014 Elsevier Inc.}}, 
pages = {35--48}, 
number = {1}, 
volume = {81}, 
keywords = {}
}
@book{alligood1997book, 
year = {1996}, 
title = {{Chaos: An Introduction to Dynamical Systems}}, 
author = {Alligood, Kathleen T. and Sauer, Tim D. and Yorke, James A.}, 
isbn = {978-3-540-78036-6}, 
url = {http://link.springer.com/10.1007/978-3-642-59281-2}, 
series = {Textbooks in Mathematical Sciences}, 
publisher = {Springer Berlin Heidelberg}, 
address = {Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-59281-2}
}
@book{quyen2003disentangling, 
year = {2003}, 
keywords = {Chaos,EEG,Non-gaussian statistics,Nonlinear dynamics,Phase synchronization}, 
title = {{Disentangling the dynamic core: A research program for a neurodynamics at the large scale}}, 
author = {Quyen, Michel Le Van}, 
url = {https://pubmed.ncbi.nlm.nih.gov/12795207/}, 
abstract = {{My purpose in this paper is to sketch a research direction based on Francisco Varela's pioneering work in neurodynamics (see also Rudrauf et al. 2003, in this issue). Very early on he argued that the internal coherence of every mental-cognitive state lies in the global self-organization of the brain activities at the large-scale, constituting a fundamental pole of integration called here a "dynamic core". Recent neuroimaging evidence appears to broadly support this hypothesis and suggests that a global brain dynamics emerges at the large scale level from the cooperative interactions among widely distributed neuronal populations. Despite a growing body of evidence supporting this view, our understanding of these large-scale brain processes remains hampered by the lack of a theoretical language for expressing these complex behaviors in dynamical terms. In this paper, I propose a rough cartography of a comprehensive approach that offers a conceptual and mathematical framework to analyze spatio-temporal large-scale brain phenomena. I emphasize how these nonlinear methods can be applied, what property might be inferred from neuronal signals, and where one might productively proceed for the future. This paper is dedicated, with respect and affection, to the memory of Francisco Varela.}}, 
volume = {36}, 
series = {Biological Research}, 
number = {1}, 
publisher = {Society of Biology of Chile}, 
note = {ISSN: 07169760 Publication Title: Biological Research}, 
doi = {10.4067/s0716-97602003000100006}
}
@article{Wildie2012Metastability, 
year = {2012}, 
title = {{Metastability and chimera states in modular delay and pulse-coupled oscillator networks}}, 
author = {Wildie, Mark and Shanahan, Murray}, 
journal = {Chaos}, 
doi = {10.1063/1.4766592}, 
pmid = {23278066}, 
url = {http://dx.doi.org/10.1063/1.4766592}, 
abstract = {{Modular networks of delay-coupled and pulse-coupled oscillators are presented, which display both transient (metastable) synchronization dynamics and the formation of a large number of "chimera" states characterized by coexistent synchronized and desynchronized subsystems. We consider networks based on both community and small-world topologies. It is shown through simulation that the metastable behaviour of the system is dependent in all cases on connection delay, and a critical region is found that maximizes indices of both metastability and the prevalence of chimera states. We show dependence of phase coherence in synchronous oscillation on the level and strength of external connectivity between communities, and demonstrate that synchronization dynamics are dependent on the modular structure of the network. The long-term behaviour of the system is considered and the relevance of the model briefly discussed with emphasis on biological and neurobiological systems. © 2012 American Institute of Physics.}}, 
pages = {43131}, 
number = {4}, 
volume = {22}, 
keywords = {}
}
@article{Shanahan.2010, 
year = {2010}, 
title = {{Metastable chimera states in community-structured oscillator networks}}, 
author = {Shanahan, Murray}, 
journal = {Chaos}, 
issn = {10541500}, 
doi = {10.1063/1.3305451}, 
pmid = {20370263}, 
eprint = {0908.3881}, 
url = {http://dx.doi.org/10.1063/1.3305451}, 
abstract = {{A system of symmetrically coupled identical oscillators with phase lag is presented, which is capable of generating a large repertoire of transient (metastable) "chimera" states in which synchronization and desynchronization coexist. The oscillators are organized into communities, such that each oscillator is connected to all its peers in the same community and to a subset of the oscillators in other communities. Measures are introduced for quantifying metastability, the prevalence of chimera states, and the variety of such states a system generates. By simulation, it is shown that each of these measures is maximized when the phase lag of the model is close, but not equal, to π/2. The relevance of the model to a number of fields is briefly discussed with particular emphasis on brain dynamics. © 2010 American Institute of Physics.}}, 
pages = {13108}, 
number = {1}, 
volume = {20}, 
keywords = {}
}
@article{Werner.2007, 
year = {2007}, 
keywords = {Dynamic core hypothesis,Global workspace,Metastability,Microstates,Non-linear dynamics,Operational architectonics,Phase transitions,Self-organized criticality}, 
title = {{Brain dynamics across levels of organization}}, 
author = {Werner, Gerhard}, 
journal = {Journal of Physiology Paris}, 
issn = {09284257}, 
doi = {10.1016/j.jphysparis.2007.12.001}, 
pmid = {18267356}, 
abstract = {{After initially presenting evidence that the electrical activity recorded from the brain surface can reflect metastable state transitions of neuronal configurations at the mesoscopic level, I will suggest that their patterns may correspond to the distinctive spatio-temporal activity in the dynamic core (DC) and the global neuronal workspace (GNW), respectively, in the models of the Edelman group on the one hand, and of Dehaene-Changeux, on the other. In both cases, the recursively reentrant activity flow in intra-cortical and cortical-subcortical neuron loops plays an essential and distinct role. Reasons will be given for viewing the temporal characteristics of this activity flow as signature of self-organized criticality (SOC), notably in reference to the dynamics of neuronal avalanches. This point of view enables the use of statistical physics approaches for exploring phase transitions, scaling and universality properties of DC and GNW, with relevance to the macroscopic electrical activity in EEG and EMG. © 2008 Elsevier Ltd. All rights reserved.}}, 
pages = {273--279}, 
number = {4-6}, 
volume = {101}, 
note = {Publisher: Elsevier}
}
@incollection{Kelso.1990, 
year = {1990}, 
title = {{Phase Transitions: Foundations of Behavior}}, 
author = {Kelso, J. A. S.}, 
isbn = {9783642487811}, 
url = {https://link.springer.com/chapter/10.1007/978-3-642-48779-8\_15}, 
abstract = {{Synergetic phase transitions afford a special window into the principles of behavior at several levels of desciption. The reason is that instabilities serve to demarcate behavioral patterns, thereby allowing a precise identification of collective variables or order parameters for patterns and their (nonlinear) dynamics. Once the, order parameter dynamics are known for particular experimental model systems, not only can they be derived or synthesized, but a number of steps of generalization becomes possible. Certain essential psychological functions such as the perception of dynamic visual and speech patterns, intentional behavioral change and learning a novel behavioral pattern are addressed here. All observed phenomena may be expressed in dynamical language.}}, 
pages = {249--268}, 
series = {Springer Series in Synergetics}, 
publisher = {Springer, Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-48779-8\_15}
}
@book{Kringelbach.2015, 
year = {2015}, 
keywords = {Dynamical systems,Resting-state activity,Whole-brain modeling}, 
title = {{The Rediscovery of Slowness: Exploring the Timing of Cognition}}, 
author = {Kringelbach, Morten L. and McIntosh, Anthony R. and Ritter, Petra and Jirsa, Viktor K. and Deco, Gustavo}, 
url = {http://www.cell.com/article/S1364661315001758/fulltext http://www.cell.com/article/S1364661315001758/abstract https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(15)00175-8}, 
abstract = {{Slowness of thought is not necessarily a handicap but could be a signature of optimal brain function. Emerging evidence shows that neuroanatomical and dynamical constraints of the human brain shape its functionality in optimal ways, characterized by slowness during task-based cognition in the context of spontaneous resting-state activity. This activity can be described mechanistically by whole-brain computational modeling that relates directly to optimality in the context of theories arguing for metastability in the brain. We discuss the role for optimal processing of information in the context of cognitive, task-related activity, and propose that combining multi-modal neuroimaging and explicit whole-brain models focused on the timing of functional dynamics can help to uncover fundamental rules of brain function in health and disease. The dynamics of the human brain exhibits 'slowness' during spontaneous activity and task-based cognition.Whole-brain computational modeling can account for the mechanisms underlying this slowness in terms of maximal metastability of the dynamical system.A better understanding of the balance between fast and slow brain processing could lead to fundamental new insights into the brain in health and disease.}}, 
volume = {19}, 
series = {Trends in Cognitive Sciences}, 
number = {10}, 
publisher = {Elsevier Ltd}, 
note = {ISSN: 1879307X Publication Title: Trends in Cognitive Sciences}, 
doi = {10.1016/j.tics.2015.07.011}
}
@article{rabinovich2008transientcognitive, 
year = {2008}, 
keywords = {Brain metastasis,Cognition,Decision making,Dynamical systems,Games,Metastasis,Nonlinear dynamics,System instability}, 
title = {{Transient cognitive dynamics, metastability, and decision making}}, 
author = {Rabinovich, Mikhail I. and Huerta, Ramón and Varona, Pablo and Afraimovich, Valentin S.}, 
journal = {PLoS Computational Biology}, 
doi = {10.1371/journal.pcbi.1000072}, 
pmid = {18452000}, 
pmcid = {PMC2358972}, 
url = {www.ploscompbiol.org}, 
abstract = {{The idea that cognitive activity can be understood using nonlinear dynamics has been intensively discussed at length for the last 15 years. One of the popular points of view is that metastable states play a key role in the execution of cognitive functions. Experimental and modeling studies suggest that most of these functions are the result of transient activity of large-scale brain networks in the presence of noise. Such transients may consist of a sequential switching between different metastable cognitive states. The main problem faced when using dynamical theory to describe transient cognitive processes is the fundamental contradiction between reproducibility and flexibility of transient behavior. In this paper, we propose a theoretical description of transient cognitive dynamics based on the interaction of functionally dependent metastable cognitive states. The mathematical image of such transient activity is a stable heteroclinic channel, i.e., a set of trajectories in the vicinity of a heteroclinic skeleton that consists of saddles and unstable separatrices that connect their surroundings. We suggest a basic mathematical model, a strongly dissipative dynamical system, and formulate the conditions for the robustness and reproducibility of cognitive transients that satisfy the competing requirements for stability and flexibility. Based on this approach, we describe here an effective solution for the problem of sequential decision making, represented as a fixed time game: a player takes sequential actions in a changing noisy environment so as to maximize a cumulative reward. As we predict and verify in computer simulations, noise plays an important role in optimizing the gain. © 2008 Rabinovich et al.}}, 
pages = {1000072}, 
number = {5}, 
volume = {4}, 
note = {Publisher: Public Library of Science}
}
@incollection{kelso1991an, 
year = {1991}, 
title = {{An Intermittency Mechanism for Coherent and Flexible Brain and Behavioral Function}}, 
author = {Kelso, J. A. S. and DeGuzman, G. C.}, 
booktitle = {Tutorials in Motor Neuroscience}, 
isbn = {9789401056090}, 
url = {https://link.springer.com/chapter/10.1007/978-94-011-3626-6\_25}, 
abstract = {{a little paper..}}, 
pages = {305--310}, 
publisher = {Springer Netherlands}, 
keywords = {}, 
doi = {10.1007/978-94-011-3626-6\_25}
}
@article{vasa2015effects, 
year = {2015}, 
keywords = {Connectome,Graph theory,Kuramoto model,Metastability,Neural dynamics,Stroke}, 
title = {{Effects of lesions on synchrony and metastability in cortical networks}}, 
author = {Váša, František and Shanahan, Murray and Hellyer, Peter J. and Scott, Gregory and Cabral, Joana and Leech, Robert}, 
journal = {NeuroImage}, 
doi = {10.1016/j.neuroimage.2015.05.042}, 
pmid = {26049146}, 
url = {http://dx.doi.org/10.1016/j.neuroimage.2015.05.042}, 
abstract = {{At the macroscopic scale, the human brain can be described as a complex network of white matter tracts integrating grey matter assemblies - the human connectome. The structure of the connectome, which is often described using graph theoretic approaches, can be used to model macroscopic brain function at low computational cost. Here, we use the Kuramoto model of coupled oscillators with time-delays, calibrated with respect to empirical functional MRI data, to study the relation between the structure of the connectome and two aspects of functional brain dynamics - synchrony, a measure of general coherence, and metastability, a measure of dynamical flexibility. Specifically, we investigate the relationship between the local structure of the connectome, quantified using graph theory, and the synchrony and metastability of the model's dynamics. By removing individual nodes and all of their connections from the model, we study the effect of lesions on both global and local dynamics. Of the nine nodal graph-theoretical properties tested, two were able to predict effects of node lesion on the global dynamics. The removal of nodes with high eigenvector centrality leads to decreases in global synchrony and increases in global metastability, as does the removal of hub nodes joining topologically segregated network modules. At the level of local dynamics in the neighbourhood of the lesioned node, structural properties of the lesioned nodes hold more predictive power, as five nodal graph theoretical measures are related to changes in local dynamics following node lesions. We discuss these results in the context of empirical studies of stroke and functional brain dynamics.}}, 
pages = {456--467}, 
volume = {118}, 
note = {Publisher: Academic Press Inc.}
}
@article{Fingelkurts.2006, 
year = {2006}, 
title = {{MAPPING OF BRAIN OPERATIONAL ARCHITECTONICS}}, 
author = {Fingelkurts, A. and Fingelkurts, A.}, 
journal = {undefined}, 
keywords = {}
}
@article{afraimovich2008winnerless, 
year = {2008}, 
keywords = {afra,ecology,nonlinear dynamical systems,Volterra equations}, 
title = {{Winnerless competition principle and prediction of the transient dynamics in a Lotka-Volterra model}}, 
author = {Afraimovich, Valentin and Tristan, Irma and Huerta, Ramon and Rabinovich, Mikhail I.}, 
journal = {Chaos}, 
doi = {10.1063/1.2991108}, 
pmid = {19123613}, 
url = {http://aip.scitation.org/doi/10.1063/1.2991108}, 
abstract = {{Predicting the evolution of multispecies ecological systems is an intriguing problem. A sufficiently complex model with the necessary predicting power requires solutions that are structurally stable. Small variations of the system parameters should not qualitatively perturb its solutions. When one is interested in just asymptotic results of evolution (as time goes to infinity), then the problem has a straightforward mathematical image involving simple attractors (fixed points or limit cycles) of a dynamical system. However, for an accurate prediction of evolution, the analysis of transient solutions is critical. In this paper, in the framework of the traditional Lotka-Volterra model (generalized in some sense), we show that the transient solution representing multispecies sequential competition can be reproducible and predictable with high probability. © 2008 American Institute of Physics.}}, 
pages = {043103}, 
number = {4}, 
volume = {18}, 
note = {Publisher: American Institute of Physics Inc.}
}
@article{schoner1988dynamic, 
year = {1988}, 
title = {{A dynamic pattern theory of behavioral change}}, 
author = {Schöner, G. and Kelso, J. A.S.}, 
journal = {Journal of Theoretical Biology}, 
doi = {10.1016/s0022-5193(88)80273-x}, 
abstract = {{Intentional change of behavior is an essential phenomenon that theoretical biology cannot fail to address. Often, theoretical attempts to understand the problem and experimental study of behavioral change are quite unrelated to each other. Recent progress in formulating a strictly operational dynamic theory of behavioral patterns, however, offers a link between theory and experiment. Here the understanding of intentional change of behavioral pattern in this theoretical language is shown. The general formulation provides predictions on the relation between the dynamics of behavioral patterns and the nature of the process of behavioral change. Theoretically founded measures, including switching time and first exit time, are introduced that allow a characterization of this process. A concrete system involving temporally ordered behavior is modelled explictly on two experimentally accessible levels of observation. Switching time and first passage time measures are calculated from the theory and the results compared to recent experimental observations. We discuss the potential of the switching time measures for the more general study of behavioral patterns and their dynamics. © 1988 Academic Press Limited.}}, 
pages = {501--524}, 
number = {4}, 
volume = {135}, 
note = {Publisher: Academic Press}, 
keywords = {}
}
@article{Fingelkurts.2017, 
year = {2017}, 
keywords = {Circular causality,EEG,Information,Metastability,Operational architectonics,Operational modules,Operational synchrony,Rapid transitional periods,Self-organisation}, 
title = {{Information flow in the brain: Ordered sequences of metastable states}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
journal = {Information (Switzerland)}, 
issn = {20782489}, 
doi = {10.3390/info8010022}, 
abstract = {{In this brief overview paper, we analyse information flow in the brain. Although Shannon's information concept, in its pure algebraic form, has made a number of valuable contributions to neuroscience, information dynamics within the brain is not fully captured by its classical description. These additional dynamics consist of self-organisation, interplay of stability/instability, timing of sequential processing, coordination of multiple sequential streams, circular causality between bottom-up and top-down operations, and information creation. Importantly, all of these processes are dynamic, hierarchically nested and correspond to continuous brain state change, even if the external environment remains constant. This is where metastable coordination comes into play. In a metastable regime of brain functioning, as a result of the simultaneous co-existence of tendencies for independence and cooperation, information is continuously created, preserved for some time and then dissipated through the formation of dynamical and nested spatio-temporal coalitions among simple neuronal assemblies and larger coupled conglomerates of them-so-called delocalised operational modules.}}, 
pages = {1--9}, 
number = {1}, 
volume = {8}
}
@book{Fingelkurts.2009, 
year = {2009}, 
keywords = {Brain research,Cognition,Consciousness,Isomorphism,Metastability,Multivariability,Neural networks,Operational architectonics,Self-organization}, 
title = {{Making complexity simpler: Multivariability and metastability in the brain}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
url = {https://www.tandfonline.com/doi/abs/10.1080/00207450490450046}, 
abstract = {{This article provides a retrospective, current, and prospective overview on developments in brain research and neuroscience. Both theoretical and empirical studies are considered, with emphasis in the concept of multivariability and metastability in the brain. In this new view on the human brain, the potential multivariability of the neuronal networks appears to be far from continuous in time, but confined by the dynamics of short-term local and global metastable brain states. The article closes by suggesting some of the implications of this view in future multidisciplinary brain research.}}, 
volume = {114}, 
series = {International Journal of Neuroscience}, 
number = {7}, 
publisher = {Taylor \& Francis}, 
note = {ISSN: 00207454 Publication Title: International Journal of Neuroscience}, 
doi = {10.1080/00207450490450046}
}
@incollection{kelso1995mulltistability, 
year = {1995}, 
title = {{Multistability and Metastability in Perceptual and Brain Dynamics}}, 
author = {Kelso, J. A. S. and Case, P. and Holroyd, T. and Horvath, E. and aczaszek, J. Ŗ and Tuller, B. and Ding, M.}, 
isbn = {9783642784132}, 
url = {https://link.springer.com/chapter/10.1007/978-3-642-78411-8\_9}, 
abstract = {{In this paper we demonstrate that vision, speech and language may exhibit self-organizing dynamic properties including transitions between perceptual states, multistability, instability, and hysteresis. Theses features illustrate a crucial characteristic of perpecptual organization, namely, the ability to function coherently yet retain some degree of flexibility. We propose the generic dynamical mechanism of intermittency as a way to flexibly enter and exit perceptual states, and suggest that this mechanism is exploited in coordinated perceptual and neural behavior. 1}}, 
pages = {159--184}, 
series = {Springer Series in Synergetics}, 
publisher = {Springer, Berlin, Heidelberg}, 
keywords = {}, 
doi = {10.1007/978-3-642-78411-8\_9}
}
@article{fingelkurts2001operational, 
year = {2001}, 
keywords = {Adaptive segmentation,Binding problem,Coherence,EEG microstructure,Functional integration,Metastability,Neocortical dynamics,Nonstationarity,Operational synchronization,Spatial scale}, 
title = {{Operational architectonics of the human brain biopotential field: Towards solving the mind-brain problem}}, 
author = {Fingelkurts, Andrew A. and Fingelkurts, Alexander A.}, 
journal = {Brain and Mind}, 
issn = {1389-1987}, 
doi = {10.1023/a:1014427822738}, 
url = {https://link.springer.com/article/10.1023/A:1014427822738}, 
abstract = {{The understanding of the interrelationship between brain and mind remains far from clear. It is well established that the brain's capacity to integrate information from numerous sources forms the basis for cognitive abilities. However, the core unresolved question is how information about the "objective" physical entities of the external world can be integrated, and how unified and coherent mental states (or Gestalts) can be established in the internal entities of distributed neuronal systems. The present paper offers a unified methodological and conceptual basis for a possible mechanism of how the transient synchronization of brain operations may construct the unified and relatively stable neural states, which underlie mental states. It was shown that the sequence of metastable spatial EEG mosaics does exist and probably reflects the rapid stabilization periods of the interrelation of large neuron systems. At the EEG level this is reflected in the stabilization of quasi-stationary segments on corresponding channels. Within the introduced framework, physical brain processes and psychological processes are considered as two basic aspects of a single whole informational brain state. The relations between operational process of the brain, mental states and consciousness are discussed.}}, 
pages = {261--296}, 
number = {3}, 
volume = {2}, 
note = {ISSN: 13891987 Publication Title: Brain and Mind}
}
@article{kelso2013outline, 
year = {2013}, 
keywords = {Behavior,Brain,Complementarity,Coordination dynamics,Multiscale}, 
title = {{Outline of a general theory of behavior and brain coordination}}, 
author = {Kelso, J. A.Scott and Dumas, Guillaume and Tognoli, Emmanuelle}, 
journal = {Neural Networks}, 
doi = {10.1016/j.neunet.2012.09.003}, 
pmid = {23084845}, 
abstract = {{Much evidence suggests that dynamic laws of neurobehavioral coordination are sui generis: they deal with collective properties that are repeatable from one system to another and emerge from microscopic dynamics but may not (even in principle) be deducible from them. Nevertheless, it is useful to try to understand the relationship between different levels while all the time respecting the autonomy of each. We report a program of research that uses the theoretical concepts of coordination dynamics and quantitative measurements of simple, well-defined experimental model systems to explicitly relate neural and behavioral levels of description in human beings. Our approach is both top-down and bottom-up and aims at ending up in the same place: top-down to derive behavioral patterns from neural fields, and bottom-up to generate neural field patterns from bidirectional coupling between astrocytes and neurons. Much progress can be made by recognizing that the two approaches-reductionism and emergentism-are complementary. A key to understanding is to couch the coordination of very different things-from molecules to thoughts-in the common language of coordination dynamics. © 2012 Elsevier Ltd.}}, 
pages = {120--131}, 
volume = {37}, 
note = {Publisher: Elsevier Ltd}
}
@article{poncealvarez2015restingstate, 
year = {2015}, 
keywords = {Bandpass filters,Functional magnetic resonance imaging,Kuramoto,Network analysis,Neural networks,Probability distribution,Signal filtering,Synaptic plasticity,White noise}, 
title = {{Resting-State Temporal Synchronization Networks Emerge from Connectivity Topology and Heterogeneity}}, 
author = {Ponce-Alvarez, Adrián and Deco, Gustavo and Hagmann, Patric and Romani, Gian Luca and Mantini, Dante and Corbetta, Maurizio}, 
journal = {PLOS Computational Biology}, 
issn = {1553-7358}, 
doi = {10.1371/journal.pcbi.1004100}, 
pmid = {25692996}, 
pmcid = {PMC4333573}, 
url = {https://dx.plos.org/10.1371/journal.pcbi.1004100}, 
abstract = {{Spatial patterns of coherent activity across different brain areas have been identified during the resting-state fluctuations of the brain. However, recent studies indicate that resting-state activity is not stationary, but shows complex temporal dynamics. We were interested in the spatiotemporal dynamics of the phase interactions among resting-state fMRI BOLD signals from human subjects. We found that the global phase synchrony of the BOLD signals evolves on a characteristic ultra-slow (<0.01Hz) time scale, and that its temporal variations reflect the transient formation and dissolution of multiple communities of synchronized brain regions. Synchronized communities reoccurred intermittently in time and across scanning sessions. We found that the synchronization communities relate to previously defined functional networks known to be engaged in sensory-motor or cognitive function, called resting-state networks (RSNs), including the default mode network, the somato-motor network, the visual network, the auditory network, the cognitive control networks, the self-referential network, and combinations of these and other RSNs. We studied the mechanism originating the observed spatiotemporal synchronization dynamics by using a network model of phase oscillators connected through the brain's anatomical connectivity estimated using diffusion imaging human data. The model consistently approximates the temporal and spatial synchronization patterns of the empirical data, and reveals that multiple clusters that transiently synchronize and desynchronize emerge from the complex topology of anatomical connections, provided that oscillators are heterogeneous.}}, 
editor = {["Hilgetag and C."], Claus}, 
pages = {e1004100}, 
number = {2}, 
volume = {11}
}
@article{hellyer2014control, 
year = {2014}, 
title = {{The control of global brain dynamics: Opposing actions of frontoparietal control and default mode networks on attention}}, 
author = {Hellyer, Peter J. and Shanahan, Murray and Scott, Gregory and Wise, Richard J.S. and Sharp, David J. and Leech, Robert}, 
journal = {Journal of Neuroscience}, 
doi = {10.1523/jneurosci.1853-13.2014}, 
pmid = {24403145}, 
url = {https://www.jneurosci.org/content/34/2/451 https://www.jneurosci.org/content/34/2/451.abstract}, 
abstract = {{Understanding how dynamic changes in brain activity control behavior is a major challenge of cognitive neuroscience. Here, we consider the brain as a complex dynamic system and define two measures of brain dynamics: the synchrony of brain activity, measured by the spatial coherence of the BOLD signal across regions of the brain; and metastability, which we define as the extent to which synchrony varies over time. We investigate the relationship among brain network activity, metastability, and cognitive state in humans, testing the hypothesis that global metastability is "tuned" by network interactions. We study the following two conditions: (1) an attentionally demanding choice reaction time task (CRT); and (2) an unconstrained "rest" state. Functional MRI demonstrated increased synchrony, and decreased metastability was associated with increased activity within the frontoparietal control/dorsal attention network (FPCN/DAN) activity and decreased default mode network (DMN) activity during the CRT compared with rest. Using a computational model of neural dynamics that is constrained by white matter structure to test whether simulated changes in FPCN/DAN and DMN activity produce similar effects, we demonstate that activation of the FPCN/DAN increases global synchrony and decreases metastability. DMN activation had the opposite effects. These results suggest that the balance of activity in the FPCN/DAN and DMN might control global metastability, providing a mechanistic explanation of how attentional state is shifted between an unfocused/exploratory mode characterized by high metastability, and a focused/constrained mode characterized by low metastability. © 2014 the authors.}}, 
pages = {451--461}, 
number = {2}, 
volume = {34}, 
note = {Publisher: Society for Neuroscience}, 
keywords = {}
}
@article{kelso2007toward, 
year = {2007}, 
keywords = {Brain,Consciousness,Coordination indexCoordinationbreak dynamics,Metastability,The complementary nature}, 
title = {{Toward a complementary neuroscience: Metastable coordination dynamics of the brain}}, 
author = {Kelso, J. A.Scott and Tognoli, Emmanuelle}, 
journal = {Understanding Complex Systems}, 
doi = {10.1007/978-3-540-73267-9\_3}, 
url = {https://link.springer.com/chapter/10.1007/978-3-540-73267-9\_3}, 
abstract = {{Metastability has been proposed as a new principle of behavioral and brain function and may point the way to a truly complementary neuroscience. From elementary coordination dynamics we show explicitly that metastability is a result of a symmetry breaking caused by the subtle interplay of two forces: the tendency of the components to couple together and the tendency of the components to express their intrinsic independent behavior. The metastable regime reconciles the well-known tendencies of specialized brain regions to express their autonomy (segregation) and the tendencies for those regions to work together as a synergy (integration). Integration ∼ segregation is just one of the complementary pairs (denoted by the tilde (∼) symbol) to emerge from the science of coordination dynamics. We discuss metastability in the brain by describing the favorable conditions existing for its emergence and by deriving some predictions for its empirical characterization in neurophysiological recordings. © 2007 Springer-Verlag Berlin Heidelberg.}}, 
pages = {39--59}, 
volume = {2007}, 
note = {ISBN: 3540732667 Publisher: Springer, Berlin, Heidelberg}
}
@article{datseris2018dynamical, 
year = {2018}, 
title = {{DynamicalSystems.jl: A Julia software library for chaos and nonlinear dynamics}}, 
author = {Datseris, George}, 
journal = {Journal of Open Source Software}, 
issn = {2475-9066}, 
doi = {10.21105/joss.00598}, 
url = {https://doi.org/10.21105/joss.00598}, 
pages = {598}, 
number = {23}, 
volume = {3}, 
note = {Publisher: The Open Journal}, 
keywords = {}
}
@article{kraut2002multistability, 
year = {2002}, 
title = {{Multistability, noise, and attractor hopping: The crucial role of chaotic saddles}}, 
author = {Kraut, Suso and Feudel, Ulrike}, 
journal = {Physical Review E - Statistical Physics, Plasmas, Fluids, and Related Interdisciplinary Topics}, 
doi = {10.1103/physreve.66.015207}, 
pmid = {12241417}, 
url = {https://journals.aps.org/pre/abstract/10.1103/PhysRevE.66.015207}, 
abstract = {{We investigate the hopping dynamics between different attractors in a multistable system under the influence of noise. Using symbolic dynamics we find a sudden increase of dynamical entropies, when a system parameter is varied. This effect is explained by a bifurcation involving two chaotic saddles. We also demonstrate that the transient lifetimes on the saddle obey a scaling law in analogy to crisis. © 2002 The American Physical Society.}}, 
pages = {015207}, 
number = {1}, 
volume = {66}, 
note = {Publisher: American Physical Society \_eprint: 0309015}, 
keywords = {}
}
@article{Graben.2013, 
year = {2013}, 
title = {{Detecting Recurrence Domains of Dynamical Systems by Symbolic Dynamics}}, 
author = {Graben, Peter beim and Hutt, Axel}, 
journal = {Physical Review Letters}, 
issn = {0031-9007}, 
doi = {10.1103/physrevlett.110.154101}, 
pmid = {25167271}, 
eprint = {1211.5906}, 
abstract = {{We propose an algorithm for the detection of recurrence domains of complex dynamical systems from time series. Our approach exploits the characteristic checkerboard texture of recurrence domains exhibited in recurrence plots. In phase space, recurrence plots yield intersecting balls around sampling points that could be merged into cells of a phase space partition. We construct this partition by a rewriting grammar applied to the symbolic dynamics of time indices. A maximum entropy principle defines the optimal size of intersecting balls. The final application to high-dimensional brain signals yields an optimal symbolic recurrence plot revealing functional components of the signal.}}, 
pages = {154101}, 
number = {15}, 
volume = {110}, 
keywords = {}
}
@article{Shanahan.2008, 
year = {2008}, 
title = {{Dynamical complexity in small-world networks of spiking neurons}}, 
author = {Shanahan, Murray}, 
journal = {Physical Review E}, 
issn = {1539-3755}, 
doi = {10.1103/physreve.78.041924}, 
pmid = {18999472}, 
eprint = {0808.0088}, 
abstract = {{A computer model is described which is used to assess the dynamical complexity of a class of networks of spiking neurons with small-world properties. Networks are constructed by forming an initially segregated set of highly intraconnected clusters and then applying a probabilistic rewiring method reminiscent of the Watts-Strogatz procedure to make intercluster connections. Causal density, which counts the number of independent significant interactions among a system’s components, is used to assess dynamical complexity. This measure was chosen because it employs lagged observations, and is therefore more sensitive to temporally smeared evidence of segregation and integration than its alternatives. The results broadly support the hypothesis that small-world topology promotes dynamical complexity, but reveal a narrow parameter range within which this occurs for the network topology under investigation, and suggest an inverse correlation with phase synchrony inside this range.}}, 
pages = {041924}, 
number = {4}, 
volume = {78}, 
keywords = {}
}
@article{kaneko2003chaotic, 
year = {2003}, 
title = {{Chaotic itinerancy}}, 
author = {Kaneko, Kunihiko and Tsuda, Ichiro}, 
journal = {Chaos}, 
issn = {1054-1500}, 
doi = {10.1063/1.1607783}, 
pmid = {12946185}, 
url = {https://doi.org/10.1063/1.1607783}, 
abstract = {{Chaotic itinerancy is universal dynamics in high-dimensional dynamical systems, showing itinerant motion among varieties of low-dimensional ordered states through high-dimensional chaos. Discovery, basic features, characterization, examples, and significance of chaotic itinerancy are surveyed.}}, 
pages = {926}, 
number = {3}, 
volume = {13}, 
keywords = {}
}
@article{Tsuda.2003, 
year = {2003}, 
keywords = {chaos,convergence,fluctuations,Lyapunov methods,random processes}, 
title = {{Chaotic itinerancy generated by coupling of Milnor attractors}}, 
author = {Tsuda, Ichiro and Umemura, Toshiya}, 
journal = {Chaos}, 
issn = {10541500}, 
doi = {10.1063/1.1599131}, 
pmid = {12946186}, 
url = {http://aip.scitation.org/doi/10.1063/1.1599131}, 
abstract = {{We report the existence of chaotic itinerancy in a coupled Milnor attractor system. The attractor ruins consist of tori or local chaos generated from the original Milnor attractors. The chaotic behavior exhibited by a single orbit can be considered a "nonstationary" state, due to the extremely slow convergence of the Lyapunov exponents, but the behavior averaged over randomly chosen initial conditions is consistent with the limit theorem. We present as a possibly new indication of chaotic itinerancy the presence of slow decay of large fluctuations of the largest Lyapunov exponent.}}, 
pages = {937--946}, 
number = {3}, 
volume = {13}, 
note = {Publisher: American Institute of Physics Inc.}
}
@article{gross2021not, 
year = {2021}, 
title = {{Not One, but Many Critical States: A Dynamical Systems Perspective}}, 
author = {Gross, Thilo}, 
journal = {Frontiers in Neural Circuits}, 
doi = {10.3389/fncir.2021.614268}, 
pmid = {33737868}, 
abstract = {{The past decade has seen growing support for the critical brain hypothesis, i.e., the possibility that the brain could operate at or very near a critical state between two different dynamical regimes. Such critical states are well-studied in different disciplines, therefore there is potential for a continued transfer of knowledge. Here, I revisit foundations of bifurcation theory, the mathematical theory of transitions. While the mathematics is well-known it's transfer to neural dynamics leads to new insights and hypothesis.}}, 
pages = {614268}, 
volume = {15}, 
keywords = {}
}
@article{Tomasz.1999, 
year = {1999}, 
title = {{Blowout bifurcation of chaotic saddles}}, 
author = {Tomasz, Kapitaniak, and Ying-Cheng, Lai, and Celso, Grebogi,}, 
journal = {Discrete Dynamics in Nature and Society}, 
issn = {1026-0226}, 
doi = {10.1155/s1026022699000023}, 
abstract = {{Chaotic saddles are nonattracting dynamical invariant sets that can lead to a variety of physical phenomena. We describe the blowout bifurcation of chaotic saddles located in the symmetric invariant manifold of coupled systems and discuss dynamical phenomena associated with this bifurcation.}}, 
pages = {9--13}, 
number = {1}, 
volume = {3}, 
keywords = {}
}
@article{ansmann2016selfinduced, 
year = {2016}, 
keywords = {Complex Systems,Nonlinear Dynamics,Subject Areas}, 
title = {{Self-induced switchings between multiple space-time patterns on complex networks of excitable units}}, 
author = {Ansmann, Gerrit and Lehnertz, Klaus and Feudel, Ulrike}, 
journal = {Physical Review X}, 
doi = {10.1103/physrevx.6.011030}, 
eprint = {1602.02177}, 
url = {https://journals.aps.org/prx/abstract/10.1103/PhysRevX.6.011030}, 
abstract = {{We report on self-induced switchings between multiple distinct space-time patterns in the dynamics of a spatially extended excitable system. These switchings between low-amplitude oscillations, nonlinear waves, and extreme events strongly resemble a random process, although the system is deterministic. We show that a chaotic saddle-which contains all the patterns as well as channel-like structures that mediate the transitions between them-is the backbone of such a pattern-switching dynamics. Our analyses indicate that essential ingredients for the observed phenomena are that the system behaves like an inhomogeneous oscillatory medium that is capable of self-generating spatially localized excitations and that is dominated by short-range connections but also features long-range connections. With our findings, we present an alternative to the well-known ways to obtain self-induced pattern switching, namely, noise-induced attractor hopping, heteroclinic orbits, and adaptation to an external signal. This alternative way can be expected to improve our understanding of pattern switchings in spatially extended natural dynamical systems like the brain and the heart.}}, 
pages = {011030}, 
number = {1}, 
volume = {6}, 
note = {Publisher: American Physical Society \_eprint: 1602.02177}
}
@article{brunton2016discovering, 
year = {2016}, 
title = {{Discovering governing equations from data by sparse identification of nonlinear dynamical systems}}, 
author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan}, 
journal = {Proceedings of the National Academy of Sciences}, 
issn = {0027-8424}, 
doi = {10.1073/pnas.1517384113}, 
pmid = {27035946}, 
pmcid = {PMC4839439}, 
eprint = {1509.03580}, 
abstract = {{Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.}}, 
pages = {3932--3937}, 
number = {15}, 
volume = {113}, 
keywords = {}
}
@book{lai2009transient, 
year = {2009}, 
title = {{Transient Chaos: Complex Dynamics on Finite-TIme Scales}}, 
author = {Lai, Ying-Cheng and Tél, Tamás}, 
isbn = {978-1-4614-2816-9}, 
series = {Applied Mathematical Sciences}, 
publisher = {Springer New York, NY}, 
keywords = {}, 
doi = {https://doi.org/10.1007/978-1-4419-6987-3}
}
@article{Brinkman.2021, 
year = {2021}, 
title = {{Metastable dynamics of neural circuits and networks}}, 
author = {Brinkman, Braden A W and Yan, Han and Maffei, Arianna and Park, Il Memming and Fontanini, Alfredo and Wang, Jin and Camera, Giancarlo La}, 
journal = {arXiv}, 
eprint = {2110.03025}, 
abstract = {{Cortical neurons emit seemingly erratic trains of action potentials, or "spikes", and neural network dynamics emerge from the coordinated spiking activity within neural circuits. These rich dynamics manifest themselves in a variety of patterns which emerge spontaneously or in response to incoming activity produced by sensory inputs. In this review, we focus on neural dynamics that is best understood as a sequence of repeated activations of a number of discrete hidden states. These transiently occupied states are termed "metastable" and have been linked to important sensory and cognitive functions. In the rodent gustatory cortex, for instance, metastable dynamics have been associated with stimulus coding, with states of expectation, and with decision making. In frontal, parietal and motor areas of macaques, metastable activity has been related to behavioral performance, choice behavior, task difficulty, and attention. In this article, we review the experimental evidence for neural metastable dynamics together with theoretical approaches to the study of metastable activity in neural circuits. These approaches include: (i) a theoretical framework based on non-equilibrium statistical physics for network dynamics; (ii) statistical approaches to extract information about metastable states from a variety of neural signals, and (iii) recent neural network approaches, informed by experimental results, to model the emergence of metastable dynamics. By discussing these topics, we aim to provide a cohesive view of how transitions between different states of activity may provide the neural underpinnings for essential functions such as perception, memory, expectation or decision making, and more generally, how the study of metastable neural activity may advance our understanding of neural circuit function in health and disease.}}, 
keywords = {}
}
@article{recanatesi2021metastable, 
year = {2021}, 
title = {{Metastable attractors explain the variable timing of stable behavioral action sequences}}, 
author = {Recanatesi, Stefano and Pereira-Obilinovic, Ulises and Murakami, Masayoshi and Mainen, Zachary and Mazzucato, Luca}, 
journal = {Neuron}, 
issn = {0896-6273}, 
doi = {10.1016/j.neuron.2021.10.011}, 
abstract = {{The timing of self-initiated actions shows large variability even when they are executed in stable, well-learned sequences. Could this mix of reliability and stochasticity arise within the same neural circuit? We trained rats to perform a stereotyped sequence of self-initiated actions and recorded neural ensemble activity in secondary motor cortex (M2), which is known to reflect trial-by-trial action-timing fluctuations. Using hidden Markov models, we established a dictionary between activity patterns and actions. We then showed that metastable attractors, representing activity patterns with a reliable sequential structure and large transition timing variability, could be produced by reciprocally coupling a high-dimensional recurrent network and a low-dimensional feedforward one. Transitions between attractors relied on correlated variability in this mesoscale feedback loop, predicting a specific structure of low-dimensional correlations that were empirically verified in M2 recordings. Our results suggest a novel mesoscale network motif based on correlated variability supporting naturalistic animal behavior.}}, 
keywords = {}
}
